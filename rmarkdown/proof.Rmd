---
title: "Proof"
author: "Zark Zijian Wang"
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: reference.bib
biblio-style: apalike
header-includes: 
  \usepackage{setspace}
  \usepackage{amsmath}
  \usepackage{array}
  \usepackage{caption}
  \usepackage{longtable}
  \usepackage{booktabs}
  \usepackage{enumitem}
  \renewcommand{\arraystretch}{1}
  \captionsetup[table]{skip=5pt}
  \setstretch{1.5} 
fontsize: 12pt
geometry: margin=1in
editor_options: 
  markdown: 
    wrap: 72
output:
  #word_document:
    #number_sections: true
  pdf_document:
    #number_sections: true
    citation_package: natbib
    keep_tex: true
  html_document:
    toc: true
    number_sections: true
---

We define $s_{0\rightarrow T}=[s_0,s_1,...,s_T]$ as a sequence of
rewards, starting at period 0 and ending at period $T$. For any integer
$t$ such that $0<t<T$, we define $s_{0\rightarrow t}=[s_0,…,s_t]$ as a
sub-sequence of $s_{0\rightarrow T}$. Let $\mathcal{W}=[w_0,...,w_T]$ be
the attention weights for all rewards in sequence $s_{0\rightarrow T}$,
where $W\in[0,1]^{T+1}$. Let $C(\mathcal{W})$ denote the information
cost function.

The decision maker's preference for sequences, denoted by $\succsim$,
has a optimal discounting representation if
$s_{0\rightarrow T} \succsim s'_{0\rightarrow T'}$ implies
$\sum_{t=0}^T w_t\cdot s_t \succsim \sum_{t=0}^{T'} w'_t \cdot s'_t$,
where $\{w_t\}_{t=0}^T$ is determined by the following optimization
problem$$
\begin{aligned}
&\max_{\mathcal{W}}\;&&\sum_{t=0}^T w_tu(s_t) - C(\mathcal{W}) \\
&s.t.\; &&\sum_{t=0}^Tw_t =M \\
&&& w_t >0 \text{ for all } t\in \{0,1,...,T\}
\end{aligned}
$$

We assume $C(\mathcal{W})$ is constituted by time-separable costs, that
is, $C(\mathcal{W})=\sum_{t=0}^Tf_t(w_t)$, where $f_t(.)$ is twice
differentiable and strictly convex.

Axiom 1 $\succsim$ is complete, transitive, continuous and
state-independent.

(state independence) $s_t \succsim s'_t$ implies that for any
$\alpha \in (0,1)$ and reward $c$,
$\alpha \cdot s_t + (1-\alpha)\cdot c \succsim \alpha \cdot s'_t + (1-\alpha)\cdot c$.

According to expected utility theorem, Axiom 1 holds if and only if
$s_{0\rightarrow T} \succsim s_{0\rightarrow T'}$ implies
$\sum_{t=0}^T w_tv(s_t) \geq \sum_{t=0}^{T'} w'_tv(s'_t)$.

Axiom 2 (sequential outcome betweenness) For any $s_{0\rightarrow T}$,
there exists a $\alpha\in(0,1)$ such that
$s_{0\rightarrow T} \sim \alpha\cdot s_{0\rightarrow T-1}+(1-\alpha) \cdot s_T$.

Axiom 3 (sequential bracket-independence) For any $s_{0\rightarrow T}$,
and $T\geq 2$ if there exists non-negative real numbers $\alpha_1$,
$\alpha_2$, $\beta_0$, $\beta_1$, $\beta_2$, such that
$s_{0\rightarrow T}\sim \alpha_1 \cdot s_{0\rightarrow T-1} + \alpha_2 \cdot s_{T}$,
and
$s_{0\rightarrow T}\sim \beta_0 \cdot s_{0\rightarrow T-2}+\beta_1 \cdot s_{T-1}+\beta_2 \cdot s_{T}$,
then we must have $\alpha_2 = \beta_2$.

Proposition: $\succsim$ has an ADU representation if it has an optimal
discounting representation and satisfies Axiom 1-3.

**Proof.**

*Lemma 1*. If Axiom 1-2 holds, for any $s_{0\rightarrow T}$, there exist
non-negative real numbers $w_0$, $w_1$,..., $w_T$ such that
$s_{0\rightarrow T} \sim w_0 \cdot s_0 +w_1\cdot s_1 + ...+w_T\cdot s_T$
where $\sum_{t=0}^T w_t=1$.

When $T=1$, the lemma is a direct application of Axiom 2.

When $T\geq 2$, according to Axiom 1-2, for any $2\leq t\leq T$, there
should exist a real number $\alpha_t\in(0,1)$ such that
$s_{0\rightarrow t}\sim \alpha_t\cdot s_{0\rightarrow t-1}+(1-\alpha_t)\cdot s_{t}$.
For sequence $s_{0\rightarrow T}$, we can recursively apply these
preference relations as follows:

$$
\begin{aligned}
s_{0\rightarrow T} &\sim \alpha_{T-1}\cdot s_{0\rightarrow T-1} + (1-\alpha_{T-1})\cdot s_T \\
&\sim  \alpha_{T-1}\alpha_{T-2}\cdot s_{0\rightarrow T-2} + \alpha_{T-1}(1-\alpha_{T-2})\cdot s_{T-1} + (1-\alpha_{T-1})\cdot s_T \\
& \sim ...\\
& \sim w_0 \cdot s_0 + w_1\cdot s_1 +... +w_T\cdot s_T
\end{aligned}
$$

where $w_0=\prod_{t=0}^{T-1}\alpha_t$, $w_T = 1-\alpha_{T-1}$, and for
$0<t<T$, $w_t=(1-\alpha_{t-1})\prod_{\tau=t}^{T-1}\alpha_{\tau}$. It is
easy to show the sum of all these weights, denoted by $w_t$
($0\leq t\leq T$), equals 1.

Therefore, if Axiom 1-2 holds, for any sequence $s_{0\rightarrow T}$, we
can always find a convex combination of all elements in it, such that
the decision maker is indifferent between the sequence and the convex
combination of its elements. By Lemma 2, I show this convex combination
is unique.

*Lemma 2*. If Axiom 1-3 holds, suppose
$s_{0\rightarrow T}\sim \sum_{t=0}^T w_t \cdot s_t$ and
$s_{0\rightarrow T+1} \sim \sum_{t=0}^{T-1} w'_t\cdot s_t$, where
$w_t >0$, $w'_t>0$, $\sum_{t=0}^Tw_t=1$, $\sum_{t=0}^{T+1}w'_t=1$, we
must have $\frac{w'_0}{w_0}=\frac{w'_1}{w_1}=…=\frac{w'_T}{w_T}$.

According to Axiom 2, there exist $\alpha,\zeta \in (0,1)$ such that
$s_{0 \rightarrow T}\sim\alpha\cdot s_{0 \rightarrow T-1} + (1-\alpha)\cdot s_T$,
$s_{0\rightarrow T+1} \sim \zeta\cdot s_{0\rightarrow T} + (1-\zeta)\cdot s_{T+1}$.
Meanwhile, we set
$s_{0\rightarrow T+1} \sim \beta_0\cdot s_{0 \rightarrow T-1} + \beta_1\cdot s_T + (1-\beta_0-\beta_1)\cdot s_{T+1}$,
where $\beta_0, \beta_1 > 0$.

According to Axiom 3, we must have $1-\zeta=1-\beta_0-\beta_1$. So,
$\beta_1=\zeta-\beta_0$.

According to state independence, it can be derived that
$s_{0\rightarrow T} \sim \frac{\beta_0}{\zeta}\cdot s_{0 \rightarrow T-1} + (1-\frac{\beta_0}{\zeta})\cdot s_1$.

Given that
$s_{0\rightarrow T}\sim\alpha\cdot s_{0\rightarrow T-1} + (1-\alpha)\cdot s_T$,
suppose $\alpha > \frac{w'_0}{\zeta}$, we can rewrite this preference
relation as
$s_{0\rightarrow T}\sim(\alpha-\frac{\beta_0}{\zeta})\cdot s_{0\rightarrow T-1} +(1-\alpha)\cdot s_T + \frac{\beta_0}{\zeta}\cdot s_{T-1}$.

If $s_{0 \rightarrow T-1} \succ s_T$, by applying state independence, we
can derive that
$(\alpha-\frac{\beta_0}{\zeta})\cdot s_{0\rightarrow T-1} +(1-\alpha)\cdot s_T + \frac{\beta_0}{\zeta}\cdot s_{0\rightarrow T-1} \succ (\alpha-\frac{\beta_0}{\zeta})\cdot s_T +(1-\alpha)\cdot s_T + \frac{\beta_0}{\zeta}\cdot s_{0\rightarrow T-1}$,
where the right-hand side, according to the above preference relation,
is indifferent from $s_{0\rightarrow T}$. Thus, we get a contradiction.

Similarly, suppose $\alpha < \frac{\beta_0}{\zeta}$, we will also get a
contradiction.

Thus, $\alpha = \frac{\beta_0}{\zeta}$, which indicates
$\frac{\beta_0}{\alpha}=\frac{\beta_1}{1-\alpha}=\zeta$.

We can recursively apply this conclusion to any $T$. Then, we can obtain
the lemma.

Corollary 1. every sequence has a unique decomposition.

We can finish the proof by mathematical induction.

When $T=1$, we have
$s_{0 \rightarrow T}\sim\alpha\cdot s_0 + (1-\alpha)\cdot s_1$ and
$\alpha$ must be unique (otherwise there will be a contradiction).

When $T\geq 2$, we have
$s_{0\rightarrow T+1} \sim \zeta\alpha\cdot s_{0\rightarrow T-1} + \zeta(1-\alpha)\cdot s_T + (1-\zeta)\cdot s_{T+1}$
and we know that $\alpha$ is fixed.
$s_{0\rightarrow T+1} \sim \sum_{t=0}^{T+1} w'_t\cdot s_t$, where
$w_t >0$, $w'_t>0$, $\sum_{t=0}^Tw_t=1$, and $\sum_{t=0}^{T+1}w'_t=1$,
we must have $\frac{w_0}{w'_0}=\frac{w_1}{w'_1}=…=\frac{w_T}{w'_T}$.

Then, $\zeta$ must be unique too.

Proposition.

The FOC condition of the optimal discounting problem is:

$$
f_t'(w_t)=u(s_t)+\theta,\; \forall t\in\{0,1,...,T\}
$$

where $\theta$ is the Lagrangian multiplier. Given that $C$ is strictly
convex, $w_t$ is increasing with $u(s_t)+\theta$. Define the solution as
$w_t \equiv \phi_t(u(s_t)+\theta)$.

Lemma 1 indicates $M=1$.

First, note that adding a new reward $s_{T+1}$ to the end of the
sequence will only change $\theta$. Suppose this changes $\theta$ to
$\theta-\Delta \theta$.

Lemma 2 indicates that

$$
w_t = \frac{\phi_t(u(s_t)+\theta-\Delta \theta)}{\sum_{\tau=0}^{T}\phi_\tau(u(s_\tau)+\theta-\Delta \theta)}
$$

Second, note that $\Delta \theta$ is strictly increasing with $s_{T+1}$.

If $u(s_{T+1})$ increases, then $w_{T+1}$ must increase.

Suppose $\Delta \theta$ is unchanged, then $w_0,…,w_T$ will be
unchanged.

So, $\Delta \theta$ should increase as well.

We have to derive the range of $\Delta \theta$ and show that the any
$\Delta \theta$ within this range can be reached through an appropriate
$s_{T+1}$.

Third, note that if we change $s_t$ to $s'_t$ such that
$u(s'_t)=u(s_t)+\Delta u$, then $\theta$ must be moved to
$\theta - \Delta u$.

So, what actually matters is the differences between utilities.
Subtracting or adding a number to $u(.)$ has no impact on
$\{w_t\}_{t=0}^T$.

Suppose at some appropriately chosen $s_{T+1}$ and some appropriately
defined $u(.)$ such that $\theta-\Delta \theta=0$, we can represent
$w_t$ by

$$
w_t = \frac{\phi_t(u(s_t))}{\sum_{\tau=0}^{T}\phi_\tau(u(s_\tau))}
$$ where $\phi_t$ is the inverse of the derivative of $f_t$ on $w_t$.

Then, we move to any other $s_{T+1}$. Suppose that the attention weight
for period $t$ in this case will become $\phi_t(u(s_t)+\theta')$.

$$
\frac{\phi_t(u(s_t))}{\sum_{\tau=0}^{T}\phi_\tau(u(s_\tau))} = \frac{\phi_t(u(s_t)+\theta')}{\sum_{\tau=0}^{T}\phi_\tau(u(s_\tau)+\theta')}
$$ We can rewrite this as

$$
\frac{e^{\ln\phi_t(u(s_t))}}{\sum_{\tau=0}^{T}e^{\ln\phi_\tau(u(s_\tau))}} = \frac{e^{\ln\phi_t(u(s_t)+\theta')}}{\sum_{\tau=0}^{T}e^{\ln\phi_\tau(u(s_\tau)+\theta')}}
$$

Suppose
$\ln \phi_t (u(s_t)+\theta') = \ln \phi_t (u(s_t))+\lambda_t\theta'$

we must have

$$
\sum_{\tau=0}^T (1-e^{(\lambda_\tau-\lambda_t)\theta'})\phi_\tau(u(s_\tau))=0
$$

for any $t$.

When $\tau=t$, $\lambda_\tau - \lambda_t=0$. Note if $T=1$, $t$ can only
take 0 or 1, and there is only one period other than $t$ in the
summation equation. Thus, we must have $\lambda_0=\lambda_1$.

Similarly, we have $\lambda_0=\lambda_1=…=\lambda$.

So, we can write $\ln \phi_t (u(s_t))$ as
$\ln \phi_t(u(0))+\lambda u(s_t)$

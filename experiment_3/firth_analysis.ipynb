{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from lib import utils\n",
    "from lib import firth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_choice = pd.read_csv('choice_data.csv',sep=',',index_col=0)\n",
    "df_rabbit = pd.read_csv('rabbit_data.csv',sep=',',index_col=0)\n",
    "\n",
    "df_qid = df_choice.groupby(['front_ratio','single_amount'])['choice_value'].count().reset_index().reset_index().rename(columns={'index':'qid'}).iloc[:,:3]\n",
    "df_choice = pd.merge(df_choice,df_qid,on=['front_ratio','single_amount'])\n",
    "\n",
    "df_choice['part_control'] = (df_choice['group_value'] == False)*df_choice['part_value']\n",
    "df_choice['part_treatment'] = (df_choice['group_value'] == True)*df_choice['part_value']\n",
    "df_rabbit['part_control'] = (df_rabbit['group_value'] == False)*df_rabbit['part_value']\n",
    "df_rabbit['part_treatment'] = (df_rabbit['group_value'] == True)*df_rabbit['part_value']\n",
    "\n",
    "# Identify the obs with no change in choice\n",
    "sum_choice_seq = df_choice.groupby('worker_id')['choice_value'].sum().to_frame()\n",
    "analysis_workers = sum_choice_seq[(sum_choice_seq['choice_value'] != 24) & (sum_choice_seq['choice_value'] != 0)].index\n",
    "all_seq_workers = sum_choice_seq[(sum_choice_seq['choice_value'] == 24)].index\n",
    "all_single_workers = sum_choice_seq[(sum_choice_seq['choice_value'] == 0)].index\n",
    "\n",
    "# Adjust worker_id\n",
    "# Always choosing sequence: -88\n",
    "# ALways choosing single: -99\n",
    "df_choice['all_single'] = df_choice['worker_id'].isin(all_single_workers)\n",
    "df_choice['all_seq'] = df_choice['worker_id'].isin(all_seq_workers)\n",
    "df_choice['adj_worker_id'] = df_choice['worker_id'].isin(analysis_workers) * df_choice['worker_id'] + \\\n",
    "                                df_choice['worker_id'].isin(all_single_workers) * (-99) + \\\n",
    "                                df_choice['worker_id'].isin(all_seq_workers) * (-88)\n",
    "\n",
    "# Create dummies\n",
    "qid_dummies = pd.get_dummies(df_choice['qid'], prefix='qid')\n",
    "worker_dummies = pd.get_dummies(df_choice['worker_id'], prefix='worker')\n",
    "front_ratio_dummies = pd.get_dummies(df_choice['front_ratio'], prefix='front_ratio')\n",
    "single_amount_dummies = pd.get_dummies(df_choice['single_amount'], prefix='single_amount')\n",
    "df_choice = pd.concat([df_choice,qid_dummies,worker_dummies,front_ratio_dummies,single_amount_dummies],axis=1)\n",
    "\n",
    "cols_qid = [i for i in qid_dummies if i!= qid_dummies.columns[0]]\n",
    "cols_worker = [i for i in worker_dummies if i!= worker_dummies.columns[0]]\n",
    "cols_front_ratio = [i for i in front_ratio_dummies if i!= front_ratio_dummies.columns[0]]\n",
    "cols_single_amount = [i for i in single_amount_dummies if i!= single_amount_dummies.columns[0]]\n",
    "\n",
    "# Covert boolean vairables to numerical variables\n",
    "bool_cols = df_choice.select_dtypes(include=['bool']).columns\n",
    "df_choice[bool_cols] = df_choice[bool_cols].astype(int)\n",
    "\n",
    "df_analysis = df_choice[df_choice['worker_id'].isin(analysis_workers)]\n",
    "\n",
    "x_cols = ['group_value','part_control','part_treatment']\n",
    "cols_worker_analysis = [c for c in cols_worker if int(c.split('_')[1]) in analysis_workers]\n",
    "\n",
    "wrong_workers = df_rabbit['worker_id'][df_rabbit['choice_correct'] == 0].unique()\n",
    "cols_worker_wrong = [c for c in cols_worker if int(c.split('_')[1]) in wrong_workers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349.386"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_choice['response_time'].max()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Part</th>\n",
       "      <th>Intertemporal Choice</th>\n",
       "      <th>Count-the-Rabbits</th>\n",
       "      <th>$\\Chi^2$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>limit-exposure</td>\n",
       "      <td>question</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.024 ($p$=0.878)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>limit-exposure</td>\n",
       "      <td>no question</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.050 ($p$=0.823)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>full-exposure</td>\n",
       "      <td>question</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.515</td>\n",
       "      <td>2.923 ($p$=0.087)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full-exposure</td>\n",
       "      <td>no question</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.424 ($p$=0.515)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Group         Part  Intertemporal Choice  Count-the-Rabbits  \\\n",
       "0  limit-exposure     question                 0.523              0.463   \n",
       "1  limit-exposure  no question                 0.468              0.474   \n",
       "2   full-exposure     question                 0.469              0.515   \n",
       "3   full-exposure  no question                 0.448              0.476   \n",
       "\n",
       "            $\\Chi^2$  \n",
       "0  0.024 ($p$=0.878)  \n",
       "1  0.050 ($p$=0.823)  \n",
       "2  2.923 ($p$=0.087)  \n",
       "3  0.424 ($p$=0.515)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_compare_choice = pd.DataFrame({key: [] for key in ['Group','Part','Intertemporal Choice','Count-the-Rabbits',r'$\\Chi^2$']})\n",
    "\n",
    "for g in df_choice['group'].unique():\n",
    "    for p in df_choice['part'].unique():\n",
    "        _rabbit = df_rabbit[(df_rabbit['group']==g)&(df_rabbit['part']==p)]['choice_value']\n",
    "        _choice = df_choice[(df_choice['group']==g)&(df_choice['part']==p)]['choice_value']\n",
    "\n",
    "        mean_rabbit = round(_rabbit.mean(),3)\n",
    "        mean_choice = round(_choice.mean(),3)\n",
    "        _chi = stats.chi2_contingency(pd.crosstab(_rabbit,_choice))\n",
    "        chi_stat = f'{_chi.statistic:.3f} ($p$={_chi.pvalue:.3f})'\n",
    "        \n",
    "        new_row = [g,p,mean_choice,mean_rabbit,chi_stat]\n",
    "        \n",
    "        tab_compare_choice.loc[len(tab_compare_choice)] = new_row\n",
    "\n",
    "tab_compare_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_compare_choice = pd.DataFrame({key:[] for key in ['task','group','question','no question','chi']})\n",
    "tab_compare_choice.columns = pd.MultiIndex.from_tuples([('Task', ''), ('Group',''),('Part', 'question'), ('Part', 'no question'),('$chi^2$','')])\n",
    "\n",
    "task_list = ['Intertemporal Choice', 'Count-the-Rabbits']\n",
    "group_list = df_choice['group'].unique()\n",
    "\n",
    "for t in task_list:\n",
    "    for g in group_list:\n",
    "        if t == task_list[0]:\n",
    "            _df = df_choice[df_choice['group']==g]\n",
    "        else:\n",
    "            _df = df_rabbit[df_rabbit['group']==g]\n",
    "\n",
    "        mean_q = _df[_df['part_value']==True]['choice_value'].mean()\n",
    "        mean_no_q = _df[_df['part_value']==False]['choice_value'].mean()\n",
    "    \n",
    "        _chi = stats.chi2_contingency(pd.crosstab(_df['choice_value'],_df['part_value']))\n",
    "        chi_stat = f'{_chi.statistic:.3f} ($p$={_chi.pvalue:.3f})'\n",
    "        \n",
    "        new_row = [t,g,f'{mean_q:.3f}',f'{mean_no_q:.3f}',chi_stat]\n",
    "        \n",
    "        tab_compare_choice.loc[len(tab_compare_choice)] = new_row\n",
    "\n",
    "\n",
    "tab_compare_choice.index = np.repeat('',len(tab_compare_choice))\n",
    "utils.make_table(tab_compare_choice,'tables/chi_test_choice.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Group</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Part</th>\n",
       "      <th>$chi^2$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>no question</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Intertemporal Choice</td>\n",
       "      <td>limit-exposure</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.468</td>\n",
       "      <td>10.303 ($p$=0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Intertemporal Choice</td>\n",
       "      <td>full-exposure</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.448</td>\n",
       "      <td>1.470 ($p$=0.225)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Count-the-Rabbits</td>\n",
       "      <td>limit-exposure</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.037 ($p$=0.847)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Count-the-Rabbits</td>\n",
       "      <td>full-exposure</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.770 ($p$=0.380)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Task           Group     Part              \\\n",
       "                                       question no question   \n",
       "  Intertemporal Choice  limit-exposure    0.523       0.468   \n",
       "  Intertemporal Choice   full-exposure    0.469       0.448   \n",
       "     Count-the-Rabbits  limit-exposure    0.470       0.464   \n",
       "     Count-the-Rabbits   full-exposure    0.508       0.486   \n",
       "\n",
       "             $chi^2$  \n",
       "                      \n",
       "  10.303 ($p$=0.001)  \n",
       "   1.470 ($p$=0.225)  \n",
       "   0.037 ($p$=0.847)  \n",
       "   0.770 ($p$=0.380)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_compare_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680128\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:127: ValueWarning: unknown kwargs ['data']\n",
      "  warnings.warn(msg, ValueWarning)\n",
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:127: ValueWarning: unknown kwargs ['data']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>choice_value</td>   <th>  No. Observations:  </th>  <td>  7056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  7044</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 01 May 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.01727</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>07:35:03</td>     <th>  Log-Likelihood:    </th> <td> -4799.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4883.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>cluster</td>     <th>  LLR p-value:       </th> <td>2.230e-30</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>   -0.2907</td> <td>    0.149</td> <td>   -1.947</td> <td> 0.051</td> <td>   -0.583</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group_value</th>       <td>    0.0817</td> <td>    0.189</td> <td>    0.432</td> <td> 0.666</td> <td>   -0.289</td> <td>    0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_control</th>      <td>    0.0845</td> <td>    0.059</td> <td>    1.434</td> <td> 0.152</td> <td>   -0.031</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_treatment</th>    <td>    0.2226</td> <td>    0.067</td> <td>    3.305</td> <td> 0.001</td> <td>    0.091</td> <td>    0.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_ratio_0.2</th>   <td>   -0.2758</td> <td>    0.051</td> <td>   -5.383</td> <td> 0.000</td> <td>   -0.376</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_ratio_0.3</th>   <td>   -0.3331</td> <td>    0.059</td> <td>   -5.623</td> <td> 0.000</td> <td>   -0.449</td> <td>   -0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_ratio_0.4</th>   <td>   -0.2536</td> <td>    0.061</td> <td>   -4.158</td> <td> 0.000</td> <td>   -0.373</td> <td>   -0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_ratio_0.5</th>   <td>   -0.1929</td> <td>    0.071</td> <td>   -2.708</td> <td> 0.007</td> <td>   -0.332</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_ratio_0.6</th>   <td>   -0.4677</td> <td>    0.081</td> <td>   -5.763</td> <td> 0.000</td> <td>   -0.627</td> <td>   -0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single_amount_240</th> <td>    0.1906</td> <td>    0.044</td> <td>    4.373</td> <td> 0.000</td> <td>    0.105</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single_amount_280</th> <td>    0.6654</td> <td>    0.058</td> <td>   11.474</td> <td> 0.000</td> <td>    0.552</td> <td>    0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single_amount_320</th> <td>    0.4753</td> <td>    0.053</td> <td>    8.954</td> <td> 0.000</td> <td>    0.371</td> <td>    0.579</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           choice_value   No. Observations:                 7056\n",
       "Model:                          Logit   Df Residuals:                     7044\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Wed, 01 May 2024   Pseudo R-squ.:                 0.01727\n",
       "Time:                        07:35:03   Log-Likelihood:                -4799.0\n",
       "converged:                       True   LL-Null:                       -4883.3\n",
       "Covariance Type:              cluster   LLR p-value:                 2.230e-30\n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                -0.2907      0.149     -1.947      0.051      -0.583       0.002\n",
       "group_value           0.0817      0.189      0.432      0.666      -0.289       0.453\n",
       "part_control          0.0845      0.059      1.434      0.152      -0.031       0.200\n",
       "part_treatment        0.2226      0.067      3.305      0.001       0.091       0.355\n",
       "front_ratio_0.2      -0.2758      0.051     -5.383      0.000      -0.376      -0.175\n",
       "front_ratio_0.3      -0.3331      0.059     -5.623      0.000      -0.449      -0.217\n",
       "front_ratio_0.4      -0.2536      0.061     -4.158      0.000      -0.373      -0.134\n",
       "front_ratio_0.5      -0.1929      0.071     -2.708      0.007      -0.332      -0.053\n",
       "front_ratio_0.6      -0.4677      0.081     -5.763      0.000      -0.627      -0.309\n",
       "single_amount_240     0.1906      0.044      4.373      0.000       0.105       0.276\n",
       "single_amount_280     0.6654      0.058     11.474      0.000       0.552       0.779\n",
       "single_amount_320     0.4753      0.053      8.954      0.000       0.371       0.579\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pooled regression\n",
    "y = df_choice['choice_value']\n",
    "X = sm.add_constant(df_choice[x_cols + cols_front_ratio + cols_single_amount])\n",
    "mod = sm.Logit(y,X, data=df_choice)\n",
    "result_1 = mod.fit(cov_type='cluster',cov_kwds={'groups':df_choice['worker_id']})\n",
    "result_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678242\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:127: ValueWarning: unknown kwargs ['data']\n",
      "  warnings.warn(msg, ValueWarning)\n",
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:127: ValueWarning: unknown kwargs ['data']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>choice_value</td>   <th>  No. Observations:  </th>  <td>  7056</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  7029</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    26</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 01 May 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.01999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>07:35:03</td>     <th>  Log-Likelihood:    </th> <td> -4785.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -4883.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>cluster</td>     <th>  LLR p-value:       </th> <td>7.038e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>   -0.3317</td> <td>    0.158</td> <td>   -2.103</td> <td> 0.035</td> <td>   -0.641</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group_value</th>    <td>    0.0848</td> <td>    0.190</td> <td>    0.446</td> <td> 0.655</td> <td>   -0.288</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_control</th>   <td>    0.0852</td> <td>    0.059</td> <td>    1.438</td> <td> 0.150</td> <td>   -0.031</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_treatment</th> <td>    0.2183</td> <td>    0.067</td> <td>    3.254</td> <td> 0.001</td> <td>    0.087</td> <td>    0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_1</th>          <td>    0.3461</td> <td>    0.090</td> <td>    3.842</td> <td> 0.000</td> <td>    0.170</td> <td>    0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_2</th>          <td>    0.5239</td> <td>    0.091</td> <td>    5.761</td> <td> 0.000</td> <td>    0.346</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_3</th>          <td>    0.6188</td> <td>    0.106</td> <td>    5.860</td> <td> 0.000</td> <td>    0.412</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_4</th>          <td>   -0.2341</td> <td>    0.092</td> <td>   -2.557</td> <td> 0.011</td> <td>   -0.413</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_5</th>          <td>   -0.1578</td> <td>    0.084</td> <td>   -1.890</td> <td> 0.059</td> <td>   -0.322</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_6</th>          <td>    0.6275</td> <td>    0.099</td> <td>    6.331</td> <td> 0.000</td> <td>    0.433</td> <td>    0.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_7</th>          <td>    0.1559</td> <td>    0.086</td> <td>    1.813</td> <td> 0.070</td> <td>   -0.013</td> <td>    0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_8</th>          <td>   -0.2484</td> <td>    0.092</td> <td>   -2.715</td> <td> 0.007</td> <td>   -0.428</td> <td>   -0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_9</th>          <td>    0.0566</td> <td>    0.093</td> <td>    0.607</td> <td> 0.544</td> <td>   -0.126</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_10</th>         <td>    0.1317</td> <td>    0.094</td> <td>    1.406</td> <td> 0.160</td> <td>   -0.052</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_11</th>         <td>    0.2250</td> <td>    0.098</td> <td>    2.294</td> <td> 0.022</td> <td>    0.033</td> <td>    0.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_12</th>         <td>   -0.2530</td> <td>    0.099</td> <td>   -2.546</td> <td> 0.011</td> <td>   -0.448</td> <td>   -0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_13</th>         <td>   -0.1372</td> <td>    0.095</td> <td>   -1.447</td> <td> 0.148</td> <td>   -0.323</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_14</th>         <td>    0.5877</td> <td>    0.112</td> <td>    5.262</td> <td> 0.000</td> <td>    0.369</td> <td>    0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_15</th>         <td>    0.2795</td> <td>    0.105</td> <td>    2.651</td> <td> 0.008</td> <td>    0.073</td> <td>    0.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_16</th>         <td>   -0.1258</td> <td>    0.116</td> <td>   -1.088</td> <td> 0.276</td> <td>   -0.352</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_17</th>         <td>    0.0829</td> <td>    0.102</td> <td>    0.813</td> <td> 0.416</td> <td>   -0.117</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_18</th>         <td>    0.6866</td> <td>    0.111</td> <td>    6.205</td> <td> 0.000</td> <td>    0.470</td> <td>    0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_19</th>         <td>    0.0846</td> <td>    0.108</td> <td>    0.786</td> <td> 0.432</td> <td>   -0.126</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_20</th>         <td>   -0.4175</td> <td>    0.118</td> <td>   -3.529</td> <td> 0.000</td> <td>   -0.649</td> <td>   -0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_21</th>         <td>   -0.3367</td> <td>    0.118</td> <td>   -2.851</td> <td> 0.004</td> <td>   -0.568</td> <td>   -0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_22</th>         <td>    0.1611</td> <td>    0.111</td> <td>    1.453</td> <td> 0.146</td> <td>   -0.056</td> <td>    0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_23</th>         <td>    0.2100</td> <td>    0.103</td> <td>    2.034</td> <td> 0.042</td> <td>    0.008</td> <td>    0.412</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           choice_value   No. Observations:                 7056\n",
       "Model:                          Logit   Df Residuals:                     7029\n",
       "Method:                           MLE   Df Model:                           26\n",
       "Date:                Wed, 01 May 2024   Pseudo R-squ.:                 0.01999\n",
       "Time:                        07:35:03   Log-Likelihood:                -4785.7\n",
       "converged:                       True   LL-Null:                       -4883.3\n",
       "Covariance Type:              cluster   LLR p-value:                 7.038e-28\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const             -0.3317      0.158     -2.103      0.035      -0.641      -0.023\n",
       "group_value        0.0848      0.190      0.446      0.655      -0.288       0.457\n",
       "part_control       0.0852      0.059      1.438      0.150      -0.031       0.201\n",
       "part_treatment     0.2183      0.067      3.254      0.001       0.087       0.350\n",
       "qid_1              0.3461      0.090      3.842      0.000       0.170       0.523\n",
       "qid_2              0.5239      0.091      5.761      0.000       0.346       0.702\n",
       "qid_3              0.6188      0.106      5.860      0.000       0.412       0.826\n",
       "qid_4             -0.2341      0.092     -2.557      0.011      -0.413      -0.055\n",
       "qid_5             -0.1578      0.084     -1.890      0.059      -0.322       0.006\n",
       "qid_6              0.6275      0.099      6.331      0.000       0.433       0.822\n",
       "qid_7              0.1559      0.086      1.813      0.070      -0.013       0.324\n",
       "qid_8             -0.2484      0.092     -2.715      0.007      -0.428      -0.069\n",
       "qid_9              0.0566      0.093      0.607      0.544      -0.126       0.239\n",
       "qid_10             0.1317      0.094      1.406      0.160      -0.052       0.315\n",
       "qid_11             0.2250      0.098      2.294      0.022       0.033       0.417\n",
       "qid_12            -0.2530      0.099     -2.546      0.011      -0.448      -0.058\n",
       "qid_13            -0.1372      0.095     -1.447      0.148      -0.323       0.049\n",
       "qid_14             0.5877      0.112      5.262      0.000       0.369       0.807\n",
       "qid_15             0.2795      0.105      2.651      0.008       0.073       0.486\n",
       "qid_16            -0.1258      0.116     -1.088      0.276      -0.352       0.101\n",
       "qid_17             0.0829      0.102      0.813      0.416      -0.117       0.283\n",
       "qid_18             0.6866      0.111      6.205      0.000       0.470       0.903\n",
       "qid_19             0.0846      0.108      0.786      0.432      -0.126       0.295\n",
       "qid_20            -0.4175      0.118     -3.529      0.000      -0.649      -0.186\n",
       "qid_21            -0.3367      0.118     -2.851      0.004      -0.568      -0.105\n",
       "qid_22             0.1611      0.111      1.453      0.146      -0.056       0.378\n",
       "qid_23             0.2100      0.103      2.034      0.042       0.008       0.412\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pooled regression\n",
    "y = df_choice['choice_value']\n",
    "X = sm.add_constant(df_choice[x_cols + cols_qid])\n",
    "mod = sm.Logit(y,X, data=df_choice)\n",
    "result_1 = mod.fit(cov_type='cluster',cov_kwds={'groups':df_choice['worker_id']})\n",
    "result_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.434276\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "# Fixed-effect regression\n",
    "y = df_analysis['choice_value']\n",
    "X = sm.add_constant(df_analysis[x_cols + cols_qid + cols_worker_analysis])\n",
    "mod = sm.Logit(y,X)\n",
    "result_2 = mod.fit(cov_type='cluster',cov_kwds={'groups':df_analysis['worker_id']})\n",
    "# result_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.271792\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "# Fixed-effect regression\n",
    "y = df_choice['choice_value']\n",
    "X = sm.add_constant(df_choice[x_cols + cols_qid + cols_worker_analysis + ['all_single','all_seq']])\n",
    "mod = sm.Logit(y,X)\n",
    "result_3 = mod.fit(cov_type='cluster',cov_kwds={'groups':df_choice['adj_worker_id']})\n",
    "# result_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 , LL= nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 , LL= nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2 , LL= nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 3 , LL= nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 4 , LL= nan\n",
      "iteration: 5 , LL= 1883.5240110830414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 6 , LL= 1882.2520165338678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 7 , LL= nan\n",
      "iteration: 8 , LL= 1882.9608691697076\n",
      "iteration: 9 , LL= 1882.339835323914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:14: RuntimeWarning: invalid value encountered in log\n",
      "  return -(logit.loglike(beta) + 0.5*np.log(np.linalg.det(-logit.hessian(beta))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10 , LL= 1882.1751226731328\n"
     ]
    }
   ],
   "source": [
    "# Firth regression\n",
    "y = df_choice['choice_value']\n",
    "X = sm.add_constant(df_choice[x_cols + cols_qid + cols_worker])\n",
    "firth_reg_1 = firth.firthLogit(y,X)\n",
    "firth_reg_1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence level:  0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zarkwang\\OneDrive\\Discounting_Experiment_ZWang\\experiment_3\\lib\\firth.py:194: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self.cluster_se = np.sqrt(np.diag(V_inv))\n"
     ]
    }
   ],
   "source": [
    "firth_reg_1.clusterSE(cluster_var=df_choice['adj_worker_id'])\n",
    "wald_result_1 = firth_reg_1.wald(use_cluster=True)\n",
    "wald_coef_result_1 = wald_result_1[wald_result_1['var_name'].isin(['const'] + x_cols + cols_front_ratio + cols_single_amount)]\n",
    "wald_coef_result_1.to_csv('firth_reg_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(1) Pooled</th>\n",
       "      <th>(2) FE</th>\n",
       "      <th>(3) FE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b_group_value</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_group_value</th>\n",
       "      <td>(0.19)</td>\n",
       "      <td>(0.533)</td>\n",
       "      <td>(0.154)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_part_control</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_part_control</th>\n",
       "      <td>(0.059)</td>\n",
       "      <td>(0.189)</td>\n",
       "      <td>(0.187)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_part_treatment</th>\n",
       "      <td>0.218$^{***}$</td>\n",
       "      <td>0.53$^{***}$</td>\n",
       "      <td>0.53$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_part_treatment</th>\n",
       "      <td>(0.067)</td>\n",
       "      <td>(0.164)</td>\n",
       "      <td>(0.163)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobs</th>\n",
       "      <td>7056</td>\n",
       "      <td>4416</td>\n",
       "      <td>7056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aic</th>\n",
       "      <td>9625.349</td>\n",
       "      <td>4253.529</td>\n",
       "      <td>4259.531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      (1) Pooled        (2) FE        (3) FE\n",
       "b_group_value              0.085         0.047        -0.096\n",
       "se_group_value            (0.19)       (0.533)       (0.154)\n",
       "b_part_control             0.085         0.301         0.301\n",
       "se_part_control          (0.059)       (0.189)       (0.187)\n",
       "b_part_treatment   0.218$^{***}$  0.53$^{***}$  0.53$^{***}$\n",
       "se_part_treatment        (0.067)       (0.164)       (0.163)\n",
       "nobs                        7056          4416          7056\n",
       "aic                     9625.349      4253.529      4259.531"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_reg_col(result,col_name,var_names=None,digit=3):\n",
    "    \n",
    "    if var_names is None:\n",
    "        var_names = result.params.index\n",
    "    \n",
    "    col_result = pd.DataFrame(columns=[col_name])\n",
    "\n",
    "    for r in range(len(var_names)):\n",
    "        _var = var_names[r]\n",
    "        _param = str(round(result.params.loc[_var],digit)) + utils.get_star(result.pvalues.loc[_var])\n",
    "        _se = '(' + str(round(result.bse.loc[_var],digit)) +')'\n",
    "        col_result.loc['b_'+_var] = _param\n",
    "        col_result.loc['se_'+_var] = _se\n",
    "\n",
    "    col_result.loc['nobs'] = int(result.nobs)\n",
    "    col_result.loc['aic'] = str(round(result.aic,digit))\n",
    "\n",
    "    return col_result\n",
    "\n",
    "def draw_reg_firth(result,col_name,var_names=None,digit=3):\n",
    "    \n",
    "    if var_names is None:\n",
    "        var_names = result.index\n",
    "    \n",
    "    col_result = pd.DataFrame(columns=[col_name])\n",
    "\n",
    "    for r in range(len(var_names)):\n",
    "        _var = var_names[r]\n",
    "        _param = str(round(result.coef.loc[_var],digit)) + utils.get_star(result.p_value.loc[_var])\n",
    "        _se = '(' + str(round(result.bse.loc[_var],digit)) + ')'\n",
    "        col_result.loc['b_'+_var] = _param\n",
    "        col_result.loc['se_'+_var] = _se\n",
    "\n",
    "    return col_result\n",
    "\n",
    "\n",
    "\n",
    "# Draw regression tables\n",
    "# var_name_list = result_1.params.index[1:]\n",
    "var_name_list = x_cols\n",
    "reg_col_1 = draw_reg_col(result_1,col_name='(1) Pooled',var_names=var_name_list)\n",
    "reg_col_2 = draw_reg_col(result_2,col_name='(2) FE',var_names=var_name_list)\n",
    "reg_col_3 = draw_reg_col(result_3,col_name='(3) FE',var_names=var_name_list)\n",
    "\n",
    "# firth_result = wald_result_1.set_index('var_name')\n",
    "# reg_col_firth = draw_reg_firth(firth_result,col_name='(3) Firth',var_names=result_1.params.index)\n",
    "\n",
    "# reg_cols = reg_col_1.join([reg_col_2, reg_col_3])\n",
    "# reg_cols.at['nobs','(3) Firth'] = len(y)\n",
    "reg_cols = reg_col_1.join([reg_col_2,reg_col_3], how='outer')\n",
    "reg_cols = reg_cols.reindex(reg_col_3.index).fillna('')\n",
    "reg_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_list = ['Group',\n",
    "#             '',\n",
    "#             r'Question$\\cdot1\\{\\text{Group}=0\\}$',\n",
    "#             '',\n",
    "#             r'Question$\\cdot1\\{\\text{Group}=1\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\rho=0.2\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\rho=0.3\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\rho=0.4\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\rho=0.5\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\rho=0.6\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\eta=240\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\eta=280\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{\\eta=320\\}$',\n",
    "#             '',\n",
    "#             'observations',\n",
    "#             'aic']\n",
    "\n",
    "\n",
    "param_list = ['Group',\n",
    "            '',\n",
    "            r'Question$\\cdot1\\{\\text{Group}=0\\}$',\n",
    "            '',\n",
    "            r'Question$\\cdot1\\{\\text{Group}=1\\}$',\n",
    "            '',\n",
    "            'observations',\n",
    "            'aic']\n",
    "\n",
    "reg_cols.index = param_list\n",
    "utils.make_table(reg_cols,'tables/reg_choice.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis = df_choice[df_choice['worker_id'].isin(analysis_workers)]\n",
    "\n",
    "df_qid_rabbit = df_rabbit.groupby(['front_amount','single_amount','diff_amount'])['choice_value'].count().reset_index().reset_index().rename(columns={'index':'qid'}).iloc[:,:-1]\n",
    "df_rabbit = pd.merge(df_rabbit,df_qid_rabbit,on=['front_amount','single_amount','diff_amount'])\n",
    "\n",
    "# Create dummy variables for rabbit data\n",
    "qid_rabbit_dummies = pd.get_dummies(df_rabbit['qid'], prefix='qid')\n",
    "worker_dummies = pd.get_dummies(df_rabbit['worker_id'], prefix='worker')\n",
    "front_amount_dummies = pd.get_dummies(df_rabbit['front_amount'], prefix='front_amount')\n",
    "single_amount_dummies = pd.get_dummies(df_rabbit['single_amount'], prefix='single_amount')\n",
    "diff_amount_dummies = pd.get_dummies(df_rabbit['diff_amount'], prefix='diff_amount')\n",
    "df_rabbit = pd.concat([df_rabbit,qid_rabbit_dummies,worker_dummies,front_amount_dummies,single_amount_dummies,diff_amount_dummies],axis=1)\n",
    "\n",
    "cols_qid_rabbit = [i for i in qid_rabbit_dummies if i!= qid_rabbit_dummies.columns[0]]\n",
    "cols_worker = [i for i in worker_dummies if i!= worker_dummies.columns[0]]\n",
    "cols_front_rabbit = [i for i in front_amount_dummies if i!= front_amount_dummies.columns[0]]\n",
    "cols_single_rabbit = [i for i in single_amount_dummies if i!= single_amount_dummies.columns[0]]\n",
    "cols_diff_rabbit = [i for i in diff_amount_dummies if i!= diff_amount_dummies.columns[0]]\n",
    "\n",
    "# Covert boolean vairables to numerical variables\n",
    "bool_cols = df_rabbit.select_dtypes(include=['bool']).columns\n",
    "df_rabbit[bool_cols] = df_rabbit[bool_cols].astype(int)\n",
    "\n",
    "# Create regression sample\n",
    "df_rabbit_analysis = df_rabbit[df_rabbit['worker_id'].isin(analysis_workers)]\n",
    "df_rabbit_wrong = df_rabbit[df_rabbit['worker_id'].isin(wrong_workers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.123110\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>choice_value</td>   <th>  No. Observations:  </th>  <td>  3504</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3496</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 01 May 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.8222</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>07:35:27</td>     <th>  Log-Likelihood:    </th> <td> -431.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2426.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>cluster</td>     <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -4.3312</td> <td>    0.309</td> <td>  -14.026</td> <td> 0.000</td> <td>   -4.936</td> <td>   -3.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group_value</th>     <td>   -0.7296</td> <td>    0.330</td> <td>   -2.208</td> <td> 0.027</td> <td>   -1.377</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_control</th>    <td>    0.5738</td> <td>    0.226</td> <td>    2.539</td> <td> 0.011</td> <td>    0.131</td> <td>    1.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_treatment</th>  <td>    0.0624</td> <td>    0.318</td> <td>    0.196</td> <td> 0.844</td> <td>   -0.561</td> <td>    0.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>diff_amount_1</th>   <td>    7.7970</td> <td>    0.377</td> <td>   20.681</td> <td> 0.000</td> <td>    7.058</td> <td>    8.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_amount_2</th>  <td>    0.1060</td> <td>    0.274</td> <td>    0.387</td> <td> 0.699</td> <td>   -0.431</td> <td>    0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>front_amount_3</th>  <td>   -0.6546</td> <td>    0.228</td> <td>   -2.876</td> <td> 0.004</td> <td>   -1.101</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>single_amount_8</th> <td>    0.1451</td> <td>    0.166</td> <td>    0.876</td> <td> 0.381</td> <td>   -0.180</td> <td>    0.470</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           choice_value   No. Observations:                 3504\n",
       "Model:                          Logit   Df Residuals:                     3496\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Wed, 01 May 2024   Pseudo R-squ.:                  0.8222\n",
       "Time:                        07:35:27   Log-Likelihood:                -431.38\n",
       "converged:                       True   LL-Null:                       -2426.5\n",
       "Covariance Type:              cluster   LLR p-value:                     0.000\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -4.3312      0.309    -14.026      0.000      -4.936      -3.726\n",
       "group_value        -0.7296      0.330     -2.208      0.027      -1.377      -0.082\n",
       "part_control        0.5738      0.226      2.539      0.011       0.131       1.017\n",
       "part_treatment      0.0624      0.318      0.196      0.844      -0.561       0.686\n",
       "diff_amount_1       7.7970      0.377     20.681      0.000       7.058       8.536\n",
       "front_amount_2      0.1060      0.274      0.387      0.699      -0.431       0.643\n",
       "front_amount_3     -0.6546      0.228     -2.876      0.004      -1.101      -0.209\n",
       "single_amount_8     0.1451      0.166      0.876      0.381      -0.180       0.470\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_rabbit['choice_value']\n",
    "X = sm.add_constant(df_rabbit[x_cols + cols_diff_rabbit + cols_front_rabbit + cols_single_rabbit])\n",
    "reg_rabbit_1 = sm.Logit(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_rabbit['worker_id']})\n",
    "reg_rabbit_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.121831\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>choice_value</td>   <th>  No. Observations:  </th>  <td>  3504</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3489</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    14</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 01 May 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.8241</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>07:35:28</td>     <th>  Log-Likelihood:    </th> <td> -426.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2426.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>cluster</td>     <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>   -5.6187</td> <td>    1.020</td> <td>   -5.506</td> <td> 0.000</td> <td>   -7.619</td> <td>   -3.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group_value</th>    <td>   -0.7318</td> <td>    0.331</td> <td>   -2.211</td> <td> 0.027</td> <td>   -1.380</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_control</th>   <td>    0.5810</td> <td>    0.228</td> <td>    2.551</td> <td> 0.011</td> <td>    0.135</td> <td>    1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>part_treatment</th> <td>    0.0704</td> <td>    0.319</td> <td>    0.220</td> <td> 0.826</td> <td>   -0.555</td> <td>    0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_1</th>          <td>    9.5170</td> <td>    1.097</td> <td>    8.673</td> <td> 0.000</td> <td>    7.366</td> <td>   11.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_2</th>          <td>    1.1295</td> <td>    1.168</td> <td>    0.967</td> <td> 0.333</td> <td>   -1.159</td> <td>    3.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_3</th>          <td>    9.1749</td> <td>    1.081</td> <td>    8.488</td> <td> 0.000</td> <td>    7.056</td> <td>   11.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_4</th>          <td>    1.3982</td> <td>    1.129</td> <td>    1.238</td> <td> 0.216</td> <td>   -0.815</td> <td>    3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_5</th>          <td>    9.0060</td> <td>    1.147</td> <td>    7.849</td> <td> 0.000</td> <td>    6.757</td> <td>   11.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_6</th>          <td>    2.1339</td> <td>    0.943</td> <td>    2.263</td> <td> 0.024</td> <td>    0.286</td> <td>    3.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_7</th>          <td>    9.1814</td> <td>    1.077</td> <td>    8.523</td> <td> 0.000</td> <td>    7.070</td> <td>   11.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_8</th>          <td>    1.1201</td> <td>    1.165</td> <td>    0.961</td> <td> 0.336</td> <td>   -1.164</td> <td>    3.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_9</th>          <td>    8.3949</td> <td>    1.055</td> <td>    7.959</td> <td> 0.000</td> <td>    6.328</td> <td>   10.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_10</th>         <td>    0.0160</td> <td>    1.425</td> <td>    0.011</td> <td> 0.991</td> <td>   -2.777</td> <td>    2.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qid_11</th>         <td>    8.6095</td> <td>    1.061</td> <td>    8.117</td> <td> 0.000</td> <td>    6.531</td> <td>   10.688</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           choice_value   No. Observations:                 3504\n",
       "Model:                          Logit   Df Residuals:                     3489\n",
       "Method:                           MLE   Df Model:                           14\n",
       "Date:                Wed, 01 May 2024   Pseudo R-squ.:                  0.8241\n",
       "Time:                        07:35:28   Log-Likelihood:                -426.89\n",
       "converged:                       True   LL-Null:                       -2426.5\n",
       "Covariance Type:              cluster   LLR p-value:                     0.000\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const             -5.6187      1.020     -5.506      0.000      -7.619      -3.619\n",
       "group_value       -0.7318      0.331     -2.211      0.027      -1.380      -0.083\n",
       "part_control       0.5810      0.228      2.551      0.011       0.135       1.027\n",
       "part_treatment     0.0704      0.319      0.220      0.826      -0.555       0.696\n",
       "qid_1              9.5170      1.097      8.673      0.000       7.366      11.668\n",
       "qid_2              1.1295      1.168      0.967      0.333      -1.159       3.418\n",
       "qid_3              9.1749      1.081      8.488      0.000       7.056      11.293\n",
       "qid_4              1.3982      1.129      1.238      0.216      -0.815       3.612\n",
       "qid_5              9.0060      1.147      7.849      0.000       6.757      11.255\n",
       "qid_6              2.1339      0.943      2.263      0.024       0.286       3.982\n",
       "qid_7              9.1814      1.077      8.523      0.000       7.070      11.293\n",
       "qid_8              1.1201      1.165      0.961      0.336      -1.164       3.404\n",
       "qid_9              8.3949      1.055      7.959      0.000       6.328      10.462\n",
       "qid_10             0.0160      1.425      0.011      0.991      -2.777       2.809\n",
       "qid_11             8.6095      1.061      8.117      0.000       6.531      10.688\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_rabbit['choice_value']\n",
    "X = sm.add_constant(df_rabbit[x_cols + cols_qid_rabbit])\n",
    "reg_rabbit_1 = sm.Logit(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_rabbit['worker_id']})\n",
    "reg_rabbit_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.069891\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "y = df_rabbit['choice_value']\n",
    "X = sm.add_constant(df_rabbit[x_cols + cols_qid_rabbit + cols_worker])\n",
    "reg_rabbit_2 = sm.Logit(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_rabbit['worker_id']})\n",
    "# reg_rabbit_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.081914\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "y = df_rabbit_analysis['choice_value']\n",
    "X = sm.add_constant(df_rabbit_analysis[x_cols + cols_qid_rabbit + cols_worker_analysis])\n",
    "reg_rabbit_3 = sm.Logit(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_rabbit_analysis['worker_id']})\n",
    "# reg_rabbit_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.262088\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "y = df_rabbit_wrong['choice_value']\n",
    "X = sm.add_constant(df_rabbit_wrong[x_cols + cols_qid_rabbit + cols_worker_wrong])\n",
    "reg_rabbit_4 = sm.Logit(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_rabbit_wrong['worker_id']})\n",
    "# reg_rabbit_4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(1) Pooled</th>\n",
       "      <th>(2) FE</th>\n",
       "      <th>(3) FE</th>\n",
       "      <th>(4) FE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b_group_value</th>\n",
       "      <td>-0.732$^{*}$</td>\n",
       "      <td>-4.466$^{*}$</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.964$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_group_value</th>\n",
       "      <td>(0.331)</td>\n",
       "      <td>(1.789)</td>\n",
       "      <td>(1.771)</td>\n",
       "      <td>(0.312)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_part_control</th>\n",
       "      <td>0.581$^{*}$</td>\n",
       "      <td>1.357$^{*}$</td>\n",
       "      <td>1.618$^{*}$</td>\n",
       "      <td>2.032$^{**}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_part_control</th>\n",
       "      <td>(0.228)</td>\n",
       "      <td>(0.606)</td>\n",
       "      <td>(0.681)</td>\n",
       "      <td>(0.778)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_part_treatment</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_part_treatment</th>\n",
       "      <td>(0.319)</td>\n",
       "      <td>(0.376)</td>\n",
       "      <td>(0.444)</td>\n",
       "      <td>(0.352)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobs</th>\n",
       "      <td>3504</td>\n",
       "      <td>3504</td>\n",
       "      <td>2190</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aic</th>\n",
       "      <td>883.789</td>\n",
       "      <td>1103.793</td>\n",
       "      <td>752.785</td>\n",
       "      <td>586.582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     (1) Pooled        (2) FE       (3) FE          (4) FE\n",
       "b_group_value      -0.732$^{*}$  -4.466$^{*}$        -0.21  -0.964$^{***}$\n",
       "se_group_value          (0.331)       (1.789)      (1.771)         (0.312)\n",
       "b_part_control      0.581$^{*}$   1.357$^{*}$  1.618$^{*}$    2.032$^{**}$\n",
       "se_part_control         (0.228)       (0.606)      (0.681)         (0.778)\n",
       "b_part_treatment           0.07         0.225        0.466           0.214\n",
       "se_part_treatment       (0.319)       (0.376)      (0.444)         (0.352)\n",
       "nobs                       3504          3504         2190             810\n",
       "aic                     883.789      1103.793      752.785         586.582"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# var_rabbit_list = reg_rabbit_1.params.index[1:]\n",
    "var_rabbit_list = x_cols\n",
    "rabbit_col_1 = draw_reg_col(reg_rabbit_1,col_name='(1) Pooled',var_names=var_rabbit_list)\n",
    "rabbit_col_2 = draw_reg_col(reg_rabbit_2,col_name='(2) FE',var_names=var_rabbit_list)\n",
    "rabbit_col_3 = draw_reg_col(reg_rabbit_3,col_name='(3) FE',var_names=var_rabbit_list)\n",
    "rabbit_col_4 = draw_reg_col(reg_rabbit_4,col_name='(4) FE',var_names=var_rabbit_list)\n",
    "\n",
    "rabbit_cols = rabbit_col_1.join([rabbit_col_2,rabbit_col_3,rabbit_col_4], how='outer')\n",
    "rabbit_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_list = ['Group',\n",
    "#             '',\n",
    "#             r'Question$\\cdot1\\{\\text{Group}=0\\}$',\n",
    "#             '',\n",
    "#             r'Questsion$\\cdot1\\{\\text{Group}=1\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{r_2 + r_3 > r_1\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{r_2 =2\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{r_2=3\\}$',\n",
    "#             '',\n",
    "#             r'$1\\{r_1=8\\}$',\n",
    "#             '',\n",
    "#             'observations',\n",
    "#             'aic']\n",
    "\n",
    "\n",
    "param_list = ['Group',\n",
    "            '',\n",
    "            r'Question$\\cdot1\\{\\text{Group}=0\\}$',\n",
    "            '',\n",
    "            r'Questsion$\\cdot1\\{\\text{Group}=1\\}$',\n",
    "            '',\n",
    "            'observations',\n",
    "            'aic']\n",
    "\n",
    "rabbit_cols.index = param_list\n",
    "utils.make_table(rabbit_cols,'tables/reg_rabbit.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_analysis['predict_choice'] = (result_2.predict() > 0.5).astype(int)\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_analysis['predict_choice'] = (result_2.predict() > 0.5).astype(int)\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response['i_choice_group'] = df_response['predict_choice']*df_response['group_value']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response['i_choice_group'] = df_response['predict_choice']*df_response['group_value']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response['i_choice_control'] = df_response['predict_choice']*df_response['part_control']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response['i_choice_control'] = df_response['predict_choice']*df_response['part_control']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response['i_choice_treat'] = df_response['predict_choice']*df_response['part_treatment']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response['i_choice_treat'] = df_response['predict_choice']*df_response['part_treatment']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\1944561696.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n"
     ]
    }
   ],
   "source": [
    "df_analysis['predict_choice'] = (result_2.predict() > 0.5).astype(int)\n",
    "# df_analysis['predict_choice'] = firth_reg_1.predict()\n",
    "outlier_threshold = df_analysis['response_time'].quantile(0.995)\n",
    "df_response = df_analysis[df_analysis['response_time'] < outlier_threshold]\n",
    "\n",
    "# create interactions\n",
    "df_response['i_choice_group'] = df_response['predict_choice']*df_response['group_value']\n",
    "df_response['i_choice_control'] = df_response['predict_choice']*df_response['part_control']\n",
    "df_response['i_choice_treat'] = df_response['predict_choice']*df_response['part_treatment']\n",
    "\n",
    "\n",
    "cols_i_front_ratio = []\n",
    "cols_i_single_amount = []\n",
    "cols_i_qid = []\n",
    "\n",
    "for r in range(len(cols_front_ratio)):\n",
    "    new_col = 'i_choice_'+ cols_front_ratio[r]\n",
    "    df_response[new_col] = df_response['predict_choice'] * df_response[cols_front_ratio[r]]\n",
    "    cols_i_front_ratio += [new_col]\n",
    "\n",
    "for r in range(len(cols_single_amount)):\n",
    "    new_col = 'i_choice_'+ cols_single_amount[r]\n",
    "    df_response[new_col] = df_response['predict_choice'] * df_response[cols_single_amount[r]]\n",
    "    cols_i_single_amount += [new_col]\n",
    "\n",
    "for r in range(len(cols_qid)):\n",
    "    new_col = 'i_choice_'+ cols_qid[r]\n",
    "    df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid[r]]\n",
    "    cols_i_qid += [new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_rabbit_analysis['predict_choice'] = (reg_rabbit_3.predict() > 0.5).astype(int)\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rabbit_analysis['predict_choice'] = (reg_rabbit_3.predict() > 0.5).astype(int)\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response_rabbit['i_choice_group'] = df_response_rabbit['predict_choice']*df_response_rabbit['group_value']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit['i_choice_group'] = df_response_rabbit['predict_choice']*df_response_rabbit['group_value']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response_rabbit['i_choice_control'] = df_response_rabbit['predict_choice']*df_response_rabbit['part_control']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit['i_choice_control'] = df_response_rabbit['predict_choice']*df_response_rabbit['part_control']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response_rabbit['i_choice_treat'] = df_response_rabbit['predict_choice']*df_response_rabbit['part_treatment']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit['i_choice_treat'] = df_response_rabbit['predict_choice']*df_response_rabbit['part_treatment']\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_front_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_front_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_front_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_front_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_single_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_diff_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_diff_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
      "C:\\Users\\zarkwang\\AppData\\Local\\Temp\\ipykernel_17004\\2827543525.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n"
     ]
    }
   ],
   "source": [
    "df_rabbit_analysis['predict_choice'] = (reg_rabbit_3.predict() > 0.5).astype(int)\n",
    "# df_analysis['predict_choice'] = firth_reg_1.predict()\n",
    "outlier_threshold = df_rabbit_analysis['response_time'].quantile(0.995)\n",
    "df_response_rabbit = df_rabbit_analysis[df_rabbit_analysis['response_time'] < outlier_threshold]\n",
    "\n",
    "# create interactions\n",
    "df_response_rabbit['i_choice_group'] = df_response_rabbit['predict_choice']*df_response_rabbit['group_value']\n",
    "df_response_rabbit['i_choice_control'] = df_response_rabbit['predict_choice']*df_response_rabbit['part_control']\n",
    "df_response_rabbit['i_choice_treat'] = df_response_rabbit['predict_choice']*df_response_rabbit['part_treatment']\n",
    "\n",
    "\n",
    "cols_i_front_rabbit = []\n",
    "cols_i_single_rabbit = []\n",
    "cols_i_diff_rabbit = []\n",
    "cols_i_qid_rabbit = []\n",
    "\n",
    "for r in range(len(cols_front_rabbit)):\n",
    "    new_col = 'i_choice_'+ cols_front_rabbit[r]\n",
    "    df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_front_rabbit[r]]\n",
    "    cols_i_front_rabbit += [new_col]\n",
    "\n",
    "for r in range(len(cols_single_rabbit)):\n",
    "    new_col = 'i_choice_'+ cols_front_rabbit[r]\n",
    "    df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_single_rabbit[r]]\n",
    "    cols_i_single_rabbit += [new_col]\n",
    "\n",
    "for r in range(len(cols_diff_rabbit)):\n",
    "    new_col = 'i_choice_'+ cols_diff_rabbit[r]\n",
    "    df_response_rabbit[new_col] = df_response_rabbit['predict_choice'] * df_response_rabbit[cols_diff_rabbit[r]]\n",
    "    cols_i_diff_rabbit += [new_col]\n",
    "\n",
    "for r in range(len(cols_qid_rabbit)):\n",
    "    new_col = 'i_choice_'+ cols_qid_rabbit[r]\n",
    "    df_response[new_col] = df_response['predict_choice'] * df_response[cols_qid_rabbit[r]]\n",
    "    cols_i_qid += [new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_response['response_time']/1000\n",
    "x_cols_new = x_cols + ['predict_choice','i_choice_group','i_choice_control','i_choice_treat']\n",
    "# X = sm.add_constant(df_response[x_cols_new + cols_single_amount + cols_i_single_amount + \\\n",
    "#                                 cols_front_ratio + cols_i_front_ratio + \\\n",
    "#                                 cols_worker_analysis])\n",
    "\n",
    "X = sm.add_constant(df_response[x_cols_new + cols_qid + cols_i_qid + \\\n",
    "                                cols_worker_analysis])\n",
    "\n",
    "mod_2nd = sm.OLS(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_response['worker_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_response_rabbit['response_time']/1000\n",
    "x_cols_new = x_cols + ['predict_choice','i_choice_group','i_choice_control','i_choice_treat']\n",
    "# X = sm.add_constant(df_response_rabbit[x_cols_new + cols_diff_rabbit + cols_i_diff_rabbit + \\\n",
    "#                                 cols_front_rabbit + cols_i_front_rabbit + \\\n",
    "#                                 cols_single_rabbit + cols_i_single_rabbit + \\\n",
    "#                                 cols_worker_analysis])\n",
    "\n",
    "X = sm.add_constant(df_response_rabbit[x_cols_new + cols_qid_rabbit + cols_i_qid_rabbit + \\\n",
    "                                cols_worker_analysis])\n",
    "\n",
    "mod_2nd_rabbit = sm.OLS(y,X).fit(cov_type='cluster',cov_kwds={'groups':df_response_rabbit['worker_id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const              2.514669e-50\n",
       "group_value        1.305139e-06\n",
       "part_control       3.419067e-01\n",
       "part_treatment     6.782951e-06\n",
       "predict_choice     1.670285e-02\n",
       "                      ...      \n",
       "worker_481844     6.889921e-181\n",
       "worker_481845     2.001886e-169\n",
       "worker_481852      2.513898e-15\n",
       "worker_481904      0.000000e+00\n",
       "worker_481905      1.088595e-32\n",
       "Length: 249, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_2nd.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choice_value\n",
       "0    3797.419611\n",
       "1    4881.824260\n",
       "Name: response_time, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_response_rabbit.groupby(['choice_value'])['response_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=739393.5, pvalue=1.4664862408519333e-23)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(df_response_rabbit.response_time[df_response_rabbit['choice_value']==True]/1000,df_response_rabbit.response_time[df_response_rabbit['choice_value']==False]/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=2528314.5, pvalue=0.0026604016728641665)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(df_response.response_time[df_response['choice_value']==True]/1000,df_response.response_time[df_response['choice_value']==False]/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intertemporal Choice</th>\n",
       "      <th>Rabbit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b_group_value</th>\n",
       "      <td>-0.684$^{***}$</td>\n",
       "      <td>-0.792$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_group_value</th>\n",
       "      <td>(0.141)</td>\n",
       "      <td>(0.144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_part_control</th>\n",
       "      <td>-0.165</td>\n",
       "      <td>0.912$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_part_control</th>\n",
       "      <td>(0.174)</td>\n",
       "      <td>(0.199)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_part_treatment</th>\n",
       "      <td>0.457$^{***}$</td>\n",
       "      <td>0.849$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_part_treatment</th>\n",
       "      <td>(0.101)</td>\n",
       "      <td>(0.132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_predict_choice</th>\n",
       "      <td>0.954$^{*}$</td>\n",
       "      <td>1.291$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_predict_choice</th>\n",
       "      <td>(0.399)</td>\n",
       "      <td>(0.456)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_i_choice_group</th>\n",
       "      <td>-0.762$^{*}$</td>\n",
       "      <td>-1.265$^{***}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_i_choice_group</th>\n",
       "      <td>(0.304)</td>\n",
       "      <td>(0.229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_i_choice_control</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_i_choice_control</th>\n",
       "      <td>(0.257)</td>\n",
       "      <td>(0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_i_choice_treat</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se_i_choice_treat</th>\n",
       "      <td>(0.195)</td>\n",
       "      <td>(0.175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobs</th>\n",
       "      <td>4393</td>\n",
       "      <td>2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aic</th>\n",
       "      <td>18560.034</td>\n",
       "      <td>8711.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adj_r</th>\n",
       "      <td>0.381</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Intertemporal Choice          Rabbit\n",
       "b_group_value             -0.684$^{***}$  -0.792$^{***}$\n",
       "se_group_value                   (0.141)         (0.144)\n",
       "b_part_control                    -0.165   0.912$^{***}$\n",
       "se_part_control                  (0.174)         (0.199)\n",
       "b_part_treatment           0.457$^{***}$   0.849$^{***}$\n",
       "se_part_treatment                (0.101)         (0.132)\n",
       "b_predict_choice             0.954$^{*}$   1.291$^{***}$\n",
       "se_predict_choice                (0.399)         (0.456)\n",
       "b_i_choice_group            -0.762$^{*}$  -1.265$^{***}$\n",
       "se_i_choice_group                (0.304)         (0.229)\n",
       "b_i_choice_control                 0.001          -0.138\n",
       "se_i_choice_control              (0.257)          (0.23)\n",
       "b_i_choice_treat                   -0.12           0.263\n",
       "se_i_choice_treat                (0.195)         (0.175)\n",
       "nobs                                4393            2179\n",
       "aic                            18560.034        8711.872\n",
       "adj_r                              0.381            0.55"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_reg_col2(result,col_name,var_names=None,digit=3):\n",
    "    \n",
    "    if var_names is None:\n",
    "        var_names = result.params.index\n",
    "    \n",
    "    col_result = pd.DataFrame(columns=[col_name])\n",
    "\n",
    "    for r in range(len(var_names)):\n",
    "        _var = var_names[r]\n",
    "        _param = str(round(result.params.loc[_var],digit)) + utils.get_star(result.pvalues.loc[_var])\n",
    "        _se = '(' + str(round(result.bse.loc[_var],digit)) +')'\n",
    "        col_result.loc['b_'+_var] = _param\n",
    "        col_result.loc['se_'+_var] = _se\n",
    "\n",
    "    col_result.loc['nobs'] = int(result.nobs)\n",
    "    col_result.loc['aic'] = str(round(result.aic,digit))\n",
    "    col_result.loc['adj_r'] = str(round(result.rsquared_adj,digit))\n",
    "\n",
    "    return col_result\n",
    "\n",
    "response_col_choice = draw_reg_col2(mod_2nd,col_name='Intertemporal Choice',var_names=x_cols_new)\n",
    "response_col_rabbit = draw_reg_col2(mod_2nd_rabbit,col_name='Rabbit',var_names=x_cols_new)\n",
    "response_cols = response_col_choice.join([response_col_rabbit], how='outer')\n",
    "response_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = ['Group',\n",
    "            '',\n",
    "            r'Question$\\cdot1\\{\\text{Group}=0\\}$',\n",
    "            '',\n",
    "            r'Question$\\cdot1\\{\\text{Group}=1\\}$',\n",
    "            '',\n",
    "            'Choice',\n",
    "            '',\n",
    "            r'Choice$\\times$Group',\n",
    "            '',\n",
    "            r'Choice$\\times$Question$\\cdot1\\{\\text{Group}=0\\}$',\n",
    "            '',\n",
    "            r'Choice$\\times$Question$\\cdot1\\{\\text{Group}=1\\}$',\n",
    "            '',\n",
    "            'observations',\n",
    "            'aic',\n",
    "            r'adj-$R^2$']\n",
    "\n",
    "\n",
    "response_cols.index = param_list\n",
    "utils.make_table(response_cols,'tables/reg_response_time.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248.06867969212553"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rabbit.mouseY[df_rabbit['choice_value']==True].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.00845377692937"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_choice.mouseY[df_choice['choice_value']==False].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=2122489.0, pvalue=2.7735038407532964e-90)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(df_rabbit.mouseY[df_rabbit['choice_value']==True],df_rabbit.mouseY[df_rabbit['choice_value']==False],nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=9397658.5, pvalue=0.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(df_choice.mouseY[df_choice['choice_value']==True],df_choice.mouseY[df_choice['choice_value']==False],nan_policy='omit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

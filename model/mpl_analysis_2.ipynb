{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from mpl import cross_valid\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from Chavez, et al. (2017)\n",
    "chavez_dt = pd.read_csv('data/chavez_data.csv')\n",
    "\n",
    "# questionnaire design\n",
    "pregunta = np.array([54,0,55,117,55,0,75,61,19,0,25,53,31,0,85,7,\n",
    "                     14,0,25,19,47,0,50,160,15,0,35,13,25,0,60,14,\n",
    "                     78,0,80,162,40,0,55,62,11,0,30,7,67,0,75,119,\n",
    "                     34,0,35,186,27,0,50,21,69,0,85,91,49,0,60,89,\n",
    "                     80,0,85,157,24,0,35,29,33,0,80,14,28,0,30,179,\n",
    "                     34,0,50,30,25,0,30,80,41,0,75,20,54,0,60,111,\n",
    "                     54,0,80,30,22,0,25,136,20,0,55,7]).reshape(27, 4)\n",
    "\n",
    "condition_col = np.array(['DT'+str(i) for i in range(1, 28)]).reshape(-1,1)\n",
    "pregunta = np.hstack((condition_col,pregunta))\n",
    "pregunta = pd.DataFrame(pregunta)\n",
    "condition_col_name = ['ss_x','ss_t','ll_x','ll_t']\n",
    "pregunta.columns = ['condition'] + condition_col_name\n",
    "\n",
    "# object containing participants' choices: '0' is choice of SS, '1' is choice of 'LL'\n",
    "chavez_dt = pd.melt(chavez_dt, id_vars=['ID','School'], var_name='condition', value_name='choice')\n",
    "chavez_dt = pd.merge(chavez_dt,pregunta,on='condition')\n",
    "chavez_dt[condition_col_name] = chavez_dt[condition_col_name].apply(pd.to_numeric)\n",
    "chavez_dt.columns = ['person_id','school','condition','choice'] + condition_col_name\n",
    "\n",
    "# Define features, label, and group variable\n",
    "features = ['ss_x', 'll_x', 'll_t',\n",
    "            'abs_diff_x', 'rel_diff_x', 'growth_x']\n",
    "label = 'choice'\n",
    "group = 'person_id'\n",
    "\n",
    "data_prepare = cross_valid.data_prepare(data=chavez_dt,feature=features,label=label,group=group)\n",
    "data_prepare.generate_features()\n",
    "dataset = data_prepare._data\n",
    "\n",
    "# Split the data into train sample and test sample\n",
    "# Train sample containts 80% of the participants, test sample contains the rest \n",
    "X_train,X_test,y_train,y_test = data_prepare.split_sample(test_size=0.2)\n",
    "groups = data_prepare.train_sample[group]\n",
    "\n",
    "# Split the train sample into K folds (K=10) for cross-validation\n",
    "sgkf = model_selection.StratifiedGroupKFold(n_splits=10,shuffle=True,random_state=2023)\n",
    "cv = list(sgkf.split(X=X_train,y=y_train,groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset['person_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=[(array([    1,     2,     3, ..., 27613, 27614, 27615]),\n",
       "                  array([    0,     8,    27, ..., 27606, 27611, 27616])),\n",
       "                 (array([    0,     1,     2, ..., 27613, 27615, 27616]),\n",
       "                  array([    7,    12,    17, ..., 27559, 27581, 27614])),\n",
       "                 (array([    0,     1,     2, ..., 27614, 27615, 27616]),\n",
       "                  array([   20,    24,    30, ..., 27593, 27595, 27608])),\n",
       "                 (array([    0,     1,     2, ..., 27614, 27615, 27616]),\n",
       "                  array([    3,    21,    25, ..., 27579, 27603, 27604])),\n",
       "                 (array([    0,     1,     2, ..., 276...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=[(array([    1,     2,     3, ..., 27613, 27614, 27615]),\n",
       "                  array([    0,     8,    27, ..., 27606, 27611, 27616])),\n",
       "                 (array([    0,     1,     2, ..., 27613, 27615, 27616]),\n",
       "                  array([    7,    12,    17, ..., 27559, 27581, 27614])),\n",
       "                 (array([    0,     1,     2, ..., 27614, 27615, 27616]),\n",
       "                  array([   20,    24,    30, ..., 27593, 27595, 27608])),\n",
       "                 (array([    0,     1,     2, ..., 27614, 27615, 27616]),\n",
       "                  array([    3,    21,    25, ..., 27579, 27603, 27604])),\n",
       "                 (array([    0,     1,     2, ..., 276...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=[(array([    1,     2,     3, ..., 27613, 27614, 27615]),\n",
       "                  array([    0,     8,    27, ..., 27606, 27611, 27616])),\n",
       "                 (array([    0,     1,     2, ..., 27613, 27615, 27616]),\n",
       "                  array([    7,    12,    17, ..., 27559, 27581, 27614])),\n",
       "                 (array([    0,     1,     2, ..., 27614, 27615, 27616]),\n",
       "                  array([   20,    24,    30, ..., 27593, 27595, 27608])),\n",
       "                 (array([    0,     1,     2, ..., 27614, 27615, 27616]),\n",
       "                  array([    3,    21,    25, ..., 27579, 27603, 27604])),\n",
       "                 (array([    0,     1,     2, ..., 276...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [1.0], 'gamma': [0.3],\n",
       "                         'learning_rate': [0.1], 'max_depth': [3],\n",
       "                         'n_estimators': [40], 'reg_lambda': [0.7],\n",
       "                         'subsample': [0.55]},\n",
       "             refit='neg_log_loss',\n",
       "             scoring=['accuracy', 'neg_log_loss', 'neg_mean_absolute_error',\n",
       "                      'neg_mean_squared_error'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost to fit the data\n",
    "# Tune the hyer-parameters by grid search \n",
    "# The following dictionary directly shows the tuning results \n",
    "param_grid = {'n_estimators': [40],\n",
    "              'max_depth': [3],\n",
    "              'learning_rate': [.1],\n",
    "              'gamma': [.3],\n",
    "              'reg_lambda': [.7],\n",
    "              'subsample': [.55],\n",
    "              'colsample_bytree': [1.0]\n",
    "            }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(model, param_grid, \n",
    "                                           cv=cv, \n",
    "                                           scoring=[\"accuracy\",\"neg_log_loss\",'neg_mean_absolute_error','neg_mean_squared_error'], \n",
    "                                           refit=\"neg_log_loss\",\n",
    "                                           n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search.fit(X=X_train,y=y_train,groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the XGBoost model and check the feature importance\n",
    "bst_model = grid_search.best_estimator_\n",
    "\n",
    "with open('my_model_2.pkl', 'wb') as f:\n",
    "    pickle.dump(bst_model, f)\n",
    "\n",
    "\n",
    "heuristic_kf_dict = {'dstyle': 'heuristic',\n",
    "            'ustyle': '--',\n",
    "            'params': None,\n",
    "            'accuracy': grid_search.cv_results_['mean_test_accuracy'][0],\n",
    "            'log_loss': -grid_search.cv_results_['mean_test_neg_log_loss'][0],\n",
    "            'mse':-grid_search.cv_results_['mean_test_neg_mean_squared_error'][0],\n",
    "            'mae':-grid_search.cv_results_['mean_test_neg_mean_absolute_error'][0]\n",
    "            }\n",
    "\n",
    "xgb.plot_importance(bst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a decision tree\n",
    "# To check structure of different trees, change num_trees \n",
    "#xgb.to_graphviz(bst_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [1:51:29<00:00, 30.41s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Fit data by distounted utility model and trade-off model\n",
    "style_list = cross_valid.estimation.gen_style_list()\n",
    "train_sample = data_prepare.train_sample\n",
    "\n",
    "kf = cross_valid.KFvalidation(style=style_list,data=train_sample,cv=cv,n_jobs=4)\n",
    "kf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if some of the fits fail to converge \n",
    "np.where(kf.success==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>params</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heuristic</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>0.220935</td>\n",
       "      <td>0.220935</td>\n",
       "      <td>0.479879</td>\n",
       "      <td>0.779065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>[5.434, 2.114, 0.011, 3.195, 0.285, 0.381]</td>\n",
       "      <td>0.156967</td>\n",
       "      <td>0.313629</td>\n",
       "      <td>0.483268</td>\n",
       "      <td>0.782422</td>\n",
       "      <td>0.278818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.325, 0.002, 0.008, 0.004]</td>\n",
       "      <td>0.157673</td>\n",
       "      <td>0.314628</td>\n",
       "      <td>0.484930</td>\n",
       "      <td>0.774997</td>\n",
       "      <td>0.320255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.697, 0.792, 0.552, 0.111, 0.123]</td>\n",
       "      <td>0.157703</td>\n",
       "      <td>0.314873</td>\n",
       "      <td>0.485127</td>\n",
       "      <td>0.779791</td>\n",
       "      <td>0.292838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.984, 1.333, 0.464, 1.933]</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0.316694</td>\n",
       "      <td>0.485639</td>\n",
       "      <td>0.782422</td>\n",
       "      <td>0.278818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>[25.374, 0.376, 0.999]</td>\n",
       "      <td>0.157962</td>\n",
       "      <td>0.316662</td>\n",
       "      <td>0.485871</td>\n",
       "      <td>0.774002</td>\n",
       "      <td>0.325232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.992, 0.997, 1.553, 0.144, 1.033]</td>\n",
       "      <td>0.158154</td>\n",
       "      <td>0.316816</td>\n",
       "      <td>0.486723</td>\n",
       "      <td>0.780988</td>\n",
       "      <td>0.287652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>[7.242, 4.947, 11.968, 12.744, 0.298, 0.21]</td>\n",
       "      <td>0.158583</td>\n",
       "      <td>0.316764</td>\n",
       "      <td>0.486850</td>\n",
       "      <td>0.771887</td>\n",
       "      <td>0.250664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.806, 0.335, 0.821]</td>\n",
       "      <td>0.158307</td>\n",
       "      <td>0.317836</td>\n",
       "      <td>0.488037</td>\n",
       "      <td>0.782422</td>\n",
       "      <td>0.278818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.006, 0.25, 0.476]</td>\n",
       "      <td>0.159293</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.489188</td>\n",
       "      <td>0.774002</td>\n",
       "      <td>0.325232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>[93.837, 0.023, 0.2]</td>\n",
       "      <td>0.159013</td>\n",
       "      <td>0.318515</td>\n",
       "      <td>0.489447</td>\n",
       "      <td>0.774002</td>\n",
       "      <td>0.325232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.962, 0.993, 0.4, 2.522]</td>\n",
       "      <td>0.159438</td>\n",
       "      <td>0.320644</td>\n",
       "      <td>0.490838</td>\n",
       "      <td>0.776839</td>\n",
       "      <td>0.310672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.995, 0.264, 0.579]</td>\n",
       "      <td>0.159964</td>\n",
       "      <td>0.321974</td>\n",
       "      <td>0.490953</td>\n",
       "      <td>0.774002</td>\n",
       "      <td>0.325232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.995, 2.133, 0.178, 0.579]</td>\n",
       "      <td>0.159964</td>\n",
       "      <td>0.321974</td>\n",
       "      <td>0.490953</td>\n",
       "      <td>0.774002</td>\n",
       "      <td>0.325232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.979, 0.164, 0.371, 0.272]</td>\n",
       "      <td>0.162144</td>\n",
       "      <td>0.323886</td>\n",
       "      <td>0.494394</td>\n",
       "      <td>0.746029</td>\n",
       "      <td>0.194461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.142, 0.412, 0.103]</td>\n",
       "      <td>0.165609</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>0.729838</td>\n",
       "      <td>0.145584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.011, 0.377, 0.174]</td>\n",
       "      <td>0.165123</td>\n",
       "      <td>0.331467</td>\n",
       "      <td>0.502648</td>\n",
       "      <td>0.747141</td>\n",
       "      <td>0.240845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.89, 0.995, 0.677, 0.165]</td>\n",
       "      <td>0.166594</td>\n",
       "      <td>0.332118</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.741157</td>\n",
       "      <td>0.226847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.95, 0.994, 0.852, 0.521, 0.201]</td>\n",
       "      <td>0.168270</td>\n",
       "      <td>0.337375</td>\n",
       "      <td>0.508985</td>\n",
       "      <td>0.731637</td>\n",
       "      <td>0.195565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.994, 50.712, 0.983, 0.132]</td>\n",
       "      <td>0.169437</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.510827</td>\n",
       "      <td>0.721283</td>\n",
       "      <td>0.163307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.996, 0.837, 0.09]</td>\n",
       "      <td>0.172029</td>\n",
       "      <td>0.345359</td>\n",
       "      <td>0.515992</td>\n",
       "      <td>0.701044</td>\n",
       "      <td>0.102051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.002, 0.989, 0.772, 0.084]</td>\n",
       "      <td>0.173843</td>\n",
       "      <td>0.347951</td>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.688793</td>\n",
       "      <td>0.064940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.829, 0.998, 0.426, 0.856, 0.089]</td>\n",
       "      <td>0.174933</td>\n",
       "      <td>0.348446</td>\n",
       "      <td>0.521527</td>\n",
       "      <td>0.683135</td>\n",
       "      <td>0.037675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle                                       params   \n",
       "99      heuristic     --                                         None  \\\n",
       "21          trade  power   [5.434, 2.114, 0.011, 3.195, 0.285, 0.381]   \n",
       "11            hb2  power                 [0.325, 0.002, 0.008, 0.004]   \n",
       "7           expo2  power          [0.697, 0.792, 0.552, 0.111, 0.123]   \n",
       "1       attention  power                 [0.984, 1.333, 0.464, 1.933]   \n",
       "13           hbmd  power                       [25.374, 0.376, 0.999]   \n",
       "19     quasihb_fc  power          [0.992, 0.997, 1.553, 0.144, 1.033]   \n",
       "20          trade   cara  [7.242, 4.947, 11.968, 12.744, 0.298, 0.21]   \n",
       "3   attention_uni  power                        [0.806, 0.335, 0.821]   \n",
       "9              hb  power                         [0.006, 0.25, 0.476]   \n",
       "12           hbmd   cara                         [93.837, 0.023, 0.2]   \n",
       "17        quasihb  power                   [0.962, 0.993, 0.4, 2.522]   \n",
       "5            expo  power                        [0.995, 0.264, 0.579]   \n",
       "15            hce  power                 [0.995, 2.133, 0.178, 0.579]   \n",
       "0       attention   cara                 [0.979, 0.164, 0.371, 0.272]   \n",
       "2   attention_uni   cara                        [0.142, 0.412, 0.103]   \n",
       "8              hb   cara                        [0.011, 0.377, 0.174]   \n",
       "16        quasihb   cara                  [0.89, 0.995, 0.677, 0.165]   \n",
       "18     quasihb_fc   cara           [0.95, 0.994, 0.852, 0.521, 0.201]   \n",
       "14            hce   cara                [0.994, 50.712, 0.983, 0.132]   \n",
       "4            expo   cara                         [0.996, 0.837, 0.09]   \n",
       "10            hb2   cara                 [0.002, 0.989, 0.772, 0.084]   \n",
       "6           expo2   cara          [0.829, 0.998, 0.426, 0.856, 0.089]   \n",
       "\n",
       "         mse       mae  log_loss  accuracy   pred_ll  \n",
       "99  0.220935  0.220935  0.479879  0.779065       NaN  \n",
       "21  0.156967  0.313629  0.483268  0.782422  0.278818  \n",
       "11  0.157673  0.314628  0.484930  0.774997  0.320255  \n",
       "7   0.157703  0.314873  0.485127  0.779791  0.292838  \n",
       "1   0.157818  0.316694  0.485639  0.782422  0.278818  \n",
       "13  0.157962  0.316662  0.485871  0.774002  0.325232  \n",
       "19  0.158154  0.316816  0.486723  0.780988  0.287652  \n",
       "20  0.158583  0.316764  0.486850  0.771887  0.250664  \n",
       "3   0.158307  0.317836  0.488037  0.782422  0.278818  \n",
       "9   0.159293  0.320000  0.489188  0.774002  0.325232  \n",
       "12  0.159013  0.318515  0.489447  0.774002  0.325232  \n",
       "17  0.159438  0.320644  0.490838  0.776839  0.310672  \n",
       "5   0.159964  0.321974  0.490953  0.774002  0.325232  \n",
       "15  0.159964  0.321974  0.490953  0.774002  0.325232  \n",
       "0   0.162144  0.323886  0.494394  0.746029  0.194461  \n",
       "2   0.165609  0.331361  0.501456  0.729838  0.145584  \n",
       "8   0.165123  0.331467  0.502648  0.747141  0.240845  \n",
       "16  0.166594  0.332118  0.506250  0.741157  0.226847  \n",
       "18  0.168270  0.337375  0.508985  0.731637  0.195565  \n",
       "14  0.169437  0.339238  0.510827  0.721283  0.163307  \n",
       "4   0.172029  0.345359  0.515992  0.701044  0.102051  \n",
       "10  0.173843  0.347951  0.519417  0.688793  0.064940  \n",
       "6   0.174933  0.348446  0.521527  0.683135  0.037675  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Cross-validation result\n",
    "kf_result_df = kf.summary()\n",
    "kf_result = kf_result_df.drop('style',axis=1)\n",
    "kf_result = pd.concat([kf_result,pd.DataFrame(heuristic_kf_dict,index=[99])]).sort_values('log_loss')\n",
    "kf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.163483</td>\n",
       "      <td>0.322077</td>\n",
       "      <td>0.499615</td>\n",
       "      <td>0.767469</td>\n",
       "      <td>0.295303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.164880</td>\n",
       "      <td>0.316253</td>\n",
       "      <td>0.504387</td>\n",
       "      <td>0.766309</td>\n",
       "      <td>0.258191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.165340</td>\n",
       "      <td>0.326326</td>\n",
       "      <td>0.504837</td>\n",
       "      <td>0.763410</td>\n",
       "      <td>0.332125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.165079</td>\n",
       "      <td>0.324718</td>\n",
       "      <td>0.506047</td>\n",
       "      <td>0.763410</td>\n",
       "      <td>0.332125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.166515</td>\n",
       "      <td>0.326945</td>\n",
       "      <td>0.508271</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.206302</td>\n",
       "      <td>0.447583</td>\n",
       "      <td>0.603855</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.179942</td>\n",
       "      <td>0.397427</td>\n",
       "      <td>0.543460</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.167339</td>\n",
       "      <td>0.334905</td>\n",
       "      <td>0.509620</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.165489</td>\n",
       "      <td>0.327454</td>\n",
       "      <td>0.504947</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.166941</td>\n",
       "      <td>0.329414</td>\n",
       "      <td>0.508917</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.166994</td>\n",
       "      <td>0.340980</td>\n",
       "      <td>0.509163</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.333915</td>\n",
       "      <td>0.509748</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>0.332415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.247817</td>\n",
       "      <td>0.497719</td>\n",
       "      <td>0.688778</td>\n",
       "      <td>0.699623</td>\n",
       "      <td>0.221658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.179092</td>\n",
       "      <td>0.355677</td>\n",
       "      <td>0.535220</td>\n",
       "      <td>0.685271</td>\n",
       "      <td>0.037112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.190699</td>\n",
       "      <td>0.414307</td>\n",
       "      <td>0.566741</td>\n",
       "      <td>0.685271</td>\n",
       "      <td>0.037112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.344148</td>\n",
       "      <td>0.544828</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.207350</td>\n",
       "      <td>0.322360</td>\n",
       "      <td>0.621632</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.333268</td>\n",
       "      <td>0.333283</td>\n",
       "      <td>3.764304</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.325735</td>\n",
       "      <td>0.332502</td>\n",
       "      <td>1.604978</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.202217</td>\n",
       "      <td>0.315851</td>\n",
       "      <td>0.633939</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.221840</td>\n",
       "      <td>0.333068</td>\n",
       "      <td>0.650183</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.202737</td>\n",
       "      <td>0.313619</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.198357</td>\n",
       "      <td>0.336246</td>\n",
       "      <td>0.581765</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy   pred_ll\n",
       "99       heurstic     --  0.163483  0.322077  0.499615  0.767469  0.295303\n",
       "21          trade  power  0.164880  0.316253  0.504387  0.766309  0.258191\n",
       "1       attention  power  0.165340  0.326326  0.504837  0.763410  0.332125\n",
       "3   attention_uni  power  0.165079  0.324718  0.506047  0.763410  0.332125\n",
       "9              hb  power  0.166515  0.326945  0.508271  0.757321  0.332415\n",
       "19     quasihb_fc  power  0.206302  0.447583  0.603855  0.757321  0.332415\n",
       "17        quasihb  power  0.179942  0.397427  0.543460  0.757321  0.332415\n",
       "15            hce  power  0.167339  0.334905  0.509620  0.757321  0.332415\n",
       "13           hbmd  power  0.165489  0.327454  0.504947  0.757321  0.332415\n",
       "12           hbmd   cara  0.166941  0.329414  0.508917  0.757321  0.332415\n",
       "11            hb2  power  0.166994  0.340980  0.509163  0.757321  0.332415\n",
       "5            expo  power  0.167349  0.333915  0.509748  0.757321  0.332415\n",
       "20          trade   cara  0.247817  0.497719  0.688778  0.699623  0.221658\n",
       "0       attention   cara  0.179092  0.355677  0.535220  0.685271  0.037112\n",
       "2   attention_uni   cara  0.190699  0.414307  0.566741  0.685271  0.037112\n",
       "10            hb2   cara  0.183667  0.344148  0.544828  0.666715  0.000000\n",
       "8              hb   cara  0.207350  0.322360  0.621632  0.666715  0.000000\n",
       "7           expo2  power  0.333268  0.333283  3.764304  0.666715  0.000000\n",
       "6           expo2   cara  0.325735  0.332502  1.604978  0.666715  0.000000\n",
       "14            hce   cara  0.202217  0.315851  0.633939  0.666715  0.000000\n",
       "16        quasihb   cara  0.221840  0.333068  0.650183  0.666715  0.000000\n",
       "4            expo   cara  0.202737  0.313619  0.652671  0.666715  0.000000\n",
       "18     quasihb_fc   cara  0.198357  0.336246  0.581765  0.666715  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Out-of-sample performance\n",
    "test_sample = data_prepare.test_sample\n",
    "test_result = cross_valid.get_result_tab(kf_result_df,test_sample)\n",
    "\n",
    "with open('my_model_2.pkl', 'rb') as f:\n",
    "    heuristic_model = pickle.load(f)\n",
    "\n",
    "heuristic_test_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,X_test=X_test,y_test=y_test)\n",
    "\n",
    "test_result = pd.concat([test_result,pd.DataFrame(heuristic_test_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.257742</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.071507</td>\n",
       "      <td>0.228161</td>\n",
       "      <td>0.276739</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.075320</td>\n",
       "      <td>0.233626</td>\n",
       "      <td>0.285608</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.079988</td>\n",
       "      <td>0.239121</td>\n",
       "      <td>0.294649</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.183242</td>\n",
       "      <td>0.424194</td>\n",
       "      <td>0.556901</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.132157</td>\n",
       "      <td>0.348823</td>\n",
       "      <td>0.441415</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.253642</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.076004</td>\n",
       "      <td>0.236831</td>\n",
       "      <td>0.288813</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>0.237375</td>\n",
       "      <td>0.288453</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.078729</td>\n",
       "      <td>0.252597</td>\n",
       "      <td>0.306240</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>0.252004</td>\n",
       "      <td>0.312848</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.246874</td>\n",
       "      <td>0.496785</td>\n",
       "      <td>0.686889</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.156479</td>\n",
       "      <td>0.378978</td>\n",
       "      <td>0.493498</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.123483</td>\n",
       "      <td>0.296772</td>\n",
       "      <td>0.389661</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.118475</td>\n",
       "      <td>0.275776</td>\n",
       "      <td>0.370133</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.127903</td>\n",
       "      <td>0.239248</td>\n",
       "      <td>0.362968</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.263983</td>\n",
       "      <td>0.263996</td>\n",
       "      <td>2.868483</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.256078</td>\n",
       "      <td>0.262391</td>\n",
       "      <td>1.150718</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.120111</td>\n",
       "      <td>0.229928</td>\n",
       "      <td>0.339754</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.151459</td>\n",
       "      <td>0.259614</td>\n",
       "      <td>0.421016</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.119475</td>\n",
       "      <td>0.226495</td>\n",
       "      <td>0.335667</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.128695</td>\n",
       "      <td>0.263323</td>\n",
       "      <td>0.379111</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "21          trade  power  0.064503  0.214233  0.257742     0.962    0.226\n",
       "3   attention_uni  power  0.071507  0.228161  0.276739     0.959    0.305\n",
       "1       attention  power  0.075320  0.233626  0.285608     0.959    0.305\n",
       "9              hb  power  0.079988  0.239121  0.294649     0.955    0.309\n",
       "19     quasihb_fc  power  0.183242  0.424194  0.556901     0.955    0.309\n",
       "17        quasihb  power  0.132157  0.348823  0.441415     0.955    0.309\n",
       "15            hce  power  0.087533  0.253642  0.314921     0.955    0.309\n",
       "13           hbmd  power  0.076004  0.236831  0.288813     0.955    0.309\n",
       "12           hbmd   cara  0.074824  0.237375  0.288453     0.955    0.309\n",
       "11            hb2  power  0.078729  0.252597  0.306240     0.955    0.309\n",
       "5            expo  power  0.086866  0.252004  0.312848     0.955    0.309\n",
       "20          trade   cara  0.246874  0.496785  0.686889     0.769    0.203\n",
       "2   attention_uni   cara  0.156479  0.378978  0.493498     0.767    0.031\n",
       "0       attention   cara  0.123483  0.296772  0.389661     0.767    0.031\n",
       "10            hb2   cara  0.118475  0.275776  0.370133     0.736    0.000\n",
       "8              hb   cara  0.127903  0.239248  0.362968     0.736    0.000\n",
       "7           expo2  power  0.263983  0.263996  2.868483     0.736    0.000\n",
       "6           expo2   cara  0.256078  0.262391  1.150718     0.736    0.000\n",
       "14            hce   cara  0.120111  0.229928  0.339754     0.736    0.000\n",
       "16        quasihb   cara  0.151459  0.259614  0.421016     0.736    0.000\n",
       "4            expo   cara  0.119475  0.226495  0.335667     0.736    0.000\n",
       "18     quasihb_fc   cara  0.128695  0.263323  0.379111     0.736    0.000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly draw 1000 questions from the dataset \n",
    "# Use the prediction value by XGBoost as the label\n",
    "# Examine which model can explain the XGBoost's prediction the best\n",
    "rda_sample = chavez_dt[chavez_dt.index.isin(np.random.choice(chavez_dt.index,size=1000,replace=False))][['ss_x','ss_t','ll_x','ll_t']]\n",
    "rda_prepare = cross_valid.data_prepare(data=rda_sample)\n",
    "rda_prepare.generate_features()\n",
    "rda_sample = rda_prepare._data[features]\n",
    "rda_sample['ss_t'] = 0\n",
    "rda_sample[label] = heuristic_model.predict(rda_sample[features])\n",
    "\n",
    "rda_result = cross_valid.get_result_tab(kf_result_df,rda_sample)\n",
    "rda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.104826</td>\n",
       "      <td>0.302410</td>\n",
       "      <td>0.374942</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.115726</td>\n",
       "      <td>0.321769</td>\n",
       "      <td>0.402108</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.129027</td>\n",
       "      <td>0.342133</td>\n",
       "      <td>0.433830</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.134387</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.447140</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.316495</td>\n",
       "      <td>0.396258</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125218</td>\n",
       "      <td>0.338202</td>\n",
       "      <td>0.426023</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.133404</td>\n",
       "      <td>0.349697</td>\n",
       "      <td>0.444744</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.140181</td>\n",
       "      <td>0.351367</td>\n",
       "      <td>0.454956</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.153357</td>\n",
       "      <td>0.368871</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.148722</td>\n",
       "      <td>0.364771</td>\n",
       "      <td>0.478470</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.183939</td>\n",
       "      <td>0.409698</td>\n",
       "      <td>0.556043</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>0.402753</td>\n",
       "      <td>0.550342</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.180499</td>\n",
       "      <td>0.387235</td>\n",
       "      <td>0.544633</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186238</td>\n",
       "      <td>0.414052</td>\n",
       "      <td>0.560951</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>0.413659</td>\n",
       "      <td>0.560368</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187047</td>\n",
       "      <td>0.415099</td>\n",
       "      <td>0.562722</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187047</td>\n",
       "      <td>0.415099</td>\n",
       "      <td>0.562722</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187570</td>\n",
       "      <td>0.415849</td>\n",
       "      <td>0.563754</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187473</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>0.563692</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.415504</td>\n",
       "      <td>0.563531</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.227380</td>\n",
       "      <td>0.227837</td>\n",
       "      <td>2.549454</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.227925</td>\n",
       "      <td>0.227980</td>\n",
       "      <td>3.519176</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "99       heurstic     --  0.104826  0.302410  0.374942     0.957    0.245\n",
       "13           hbmd  power  0.115726  0.321769  0.402108     0.943    0.203\n",
       "9              hb  power  0.129027  0.342133  0.433830     0.928    0.224\n",
       "15            hce  power  0.134387  0.351601  0.447140     0.928    0.224\n",
       "19     quasihb_fc  power  0.113634  0.316495  0.396258     0.921    0.209\n",
       "17        quasihb  power  0.125218  0.338202  0.426023     0.921    0.209\n",
       "5            expo  power  0.133404  0.349697  0.444744     0.907    0.253\n",
       "3   attention_uni  power  0.140181  0.351367  0.454956     0.879    0.137\n",
       "1       attention  power  0.153357  0.368871  0.482425     0.864    0.126\n",
       "20          trade   cara  0.148722  0.364771  0.478470     0.860    0.102\n",
       "0       attention   cara  0.183939  0.409698  0.556043     0.794    0.074\n",
       "10            hb2   cara  0.181764  0.402753  0.550342     0.792    0.036\n",
       "6           expo2   cara  0.180499  0.387235  0.544633     0.789    0.017\n",
       "12           hbmd   cara  0.186238  0.414052  0.560951     0.785    0.069\n",
       "2   attention_uni   cara  0.185945  0.413659  0.560368     0.784    0.070\n",
       "16        quasihb   cara  0.187047  0.415099  0.562722     0.780    0.068\n",
       "18     quasihb_fc   cara  0.187047  0.415099  0.562722     0.780    0.068\n",
       "8              hb   cara  0.187570  0.415849  0.563754     0.776    0.070\n",
       "14            hce   cara  0.187473  0.415640  0.563692     0.775    0.073\n",
       "4            expo   cara  0.187400  0.415504  0.563531     0.775    0.073\n",
       "7           expo2  power  0.227380  0.227837  2.549454     0.772    0.000\n",
       "11            hb2  power  0.227925  0.227980  3.519176     0.772    0.000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the prediction value by magnitude-dependent hyperbolic (hbmd) with power utillity as the label\n",
    "# Examine which model can explain the hbmd's prediction the best\n",
    "target_kf_row = kf_result_df[(kf_result_df['dstyle']=='trade') & (kf_result_df['ustyle']=='power')]\n",
    "target_style = target_kf_row['style'].values[0]\n",
    "target_params = target_kf_row['params'].values[0]\n",
    "\n",
    "choice_prob = cross_valid.test_model(style=target_style,params=target_params,test_sample=rda_sample,output='predict_proba')\n",
    "rda_sample[label] = (choice_prob >.5)\n",
    "\n",
    "rda_result_2 = cross_valid.get_result_tab(kf_result_df,rda_sample).iloc[1:,:]\n",
    "heuristic_rda_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,test_sample=rda_sample)\n",
    "rda_result_2 = pd.concat([rda_result_2,pd.DataFrame(heuristic_rda_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "rda_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "kf_result.to_csv(\"chavez_result_kf.csv\",index=False)\n",
    "test_result.to_csv(\"chavez_result_test.csv\",index=False)\n",
    "rda_result.to_csv(\"chavez_result_rda.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46fba6b68402cb55252e824db9465f0cedb227d89143b61a1fd7d4d5ad283ec3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

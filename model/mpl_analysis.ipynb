{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from mel import cross_valid\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "itch_dt = pd.read_csv('data/ericson_data.csv')\n",
    "itch_dt = itch_dt.rename(columns={\"Subject\":\"person_id\",\n",
    "                                \"Condition\":\"condition\",\n",
    "                                \"Question\":\"question_id\",\n",
    "                                \"X1\":\"ss_x\",\n",
    "                                \"T1\":\"ss_t\",\n",
    "                                \"X2\":\"ll_x\",\n",
    "                                \"T2\":\"ll_t\",\n",
    "                                \"LaterOptionChosen\": \"choice\"}).\\\n",
    "                drop(['R','G','D'],axis=1)\n",
    "\n",
    "\n",
    "# Define features, label, and group variable\n",
    "features = ['ss_x', 'ss_t', 'll_x', 'll_t',\n",
    "            'abs_diff_x', 'abs_diff_t', 'rel_diff_x','rel_diff_t',\n",
    "            'growth_x']\n",
    "label = 'choice'\n",
    "group = 'person_id'\n",
    "\n",
    "data_prepare = cross_valid.data_prepare(data=itch_dt,feature=features,label=label,group=group)\n",
    "data_prepare.generate_features()\n",
    "dataset = data_prepare._data\n",
    "\n",
    "# Split the data into train sample and test sample\n",
    "# Train sample containts 80% of the participants, test sample contains the rest \n",
    "X_train,X_test,y_train,y_test = data_prepare.split_sample(test_size=0.2)\n",
    "groups = data_prepare.train_sample[group]\n",
    "\n",
    "# Split the train sample into K folds (K=10) for cross-validation\n",
    "sgkf = model_selection.StratifiedGroupKFold(n_splits=10,shuffle=True,random_state=2023)\n",
    "cv = list(sgkf.split(X=X_train,y=y_train,groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset['person_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15114893617021277"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itch_dt[itch_dt['ss_x']>1000])/len(itch_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([  298,   299,   300, ..., 18229, 18230, 18231])),\n",
       "                 (array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([   99,   100,   101, ..., 18352, 18353, 18354])),\n",
       "                 (array([   25,    26,    27, ..., 18524, 18525, 18526]),\n",
       "                  array([    0,     1,     2, ..., 18402, 18403, 18404])),\n",
       "                 (array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([  496,   497,   498, ..., 18499, 18500, 18501])),\n",
       "                 (array([    0...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([  298,   299,   300, ..., 18229, 18230, 18231])),\n",
       "                 (array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([   99,   100,   101, ..., 18352, 18353, 18354])),\n",
       "                 (array([   25,    26,    27, ..., 18524, 18525, 18526]),\n",
       "                  array([    0,     1,     2, ..., 18402, 18403, 18404])),\n",
       "                 (array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([  496,   497,   498, ..., 18499, 18500, 18501])),\n",
       "                 (array([    0...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=[(array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([  298,   299,   300, ..., 18229, 18230, 18231])),\n",
       "                 (array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([   99,   100,   101, ..., 18352, 18353, 18354])),\n",
       "                 (array([   25,    26,    27, ..., 18524, 18525, 18526]),\n",
       "                  array([    0,     1,     2, ..., 18402, 18403, 18404])),\n",
       "                 (array([    0,     1,     2, ..., 18524, 18525, 18526]),\n",
       "                  array([  496,   497,   498, ..., 18499, 18500, 18501])),\n",
       "                 (array([    0...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [1.0], 'gamma': [0.3],\n",
       "                         'learning_rate': [0.1], 'max_depth': [3],\n",
       "                         'n_estimators': [40], 'reg_lambda': [0.7],\n",
       "                         'subsample': [0.55]},\n",
       "             refit='neg_log_loss',\n",
       "             scoring=['accuracy', 'neg_log_loss', 'neg_mean_absolute_error',\n",
       "                      'neg_mean_squared_error'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost to fit the data\n",
    "# Tune the hyer-parameters by grid search \n",
    "# The following dictionary directly shows the tuning results \n",
    "param_grid = {'n_estimators': [40],\n",
    "              'max_depth': [3],\n",
    "              'learning_rate': [.1],\n",
    "              'gamma': [.3],\n",
    "              'reg_lambda': [.7],\n",
    "              'subsample': [.55],\n",
    "              'colsample_bytree': [1.0]\n",
    "            }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(model, param_grid, \n",
    "                                           cv=cv, \n",
    "                                           scoring=[\"accuracy\",\"neg_log_loss\",'neg_mean_absolute_error','neg_mean_squared_error'], \n",
    "                                           refit=\"neg_log_loss\",\n",
    "                                           n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search.fit(X=X_train,y=y_train,groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the XGBoost model and check the feature importance\n",
    "bst_model = grid_search.best_estimator_\n",
    "\n",
    "with open('my_model.pkl', 'wb') as f:\n",
    "    pickle.dump(bst_model, f)\n",
    "\n",
    "\n",
    "heuristic_kf_dict = {'dstyle': 'heuristic',\n",
    "            'ustyle': '--',\n",
    "            'params': None,\n",
    "            'accuracy': grid_search.cv_results_['mean_test_accuracy'][0],\n",
    "            'log_loss': -grid_search.cv_results_['mean_test_neg_log_loss'][0],\n",
    "            'mse':-grid_search.cv_results_['mean_test_neg_mean_squared_error'][0],\n",
    "            'mae':-grid_search.cv_results_['mean_test_neg_mean_absolute_error'][0]\n",
    "            }\n",
    "\n",
    "xgb.plot_importance(bst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a decision tree\n",
    "# To check structure of different trees, change num_trees \n",
    "#xgb.to_graphviz(bst_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [59:52<00:00, 16.33s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Fit data by distounted utility model and trade-off model\n",
    "style_list = cross_valid.estimation.gen_style_list()\n",
    "train_sample = data_prepare.train_sample\n",
    "\n",
    "kf = cross_valid.KFvalidation(style=style_list,data=train_sample,cv=cv,n_jobs=4)\n",
    "kf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if some of the fits fail to converge \n",
    "np.where(kf.success==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>params</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heuristic</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>0.297701</td>\n",
       "      <td>0.297701</td>\n",
       "      <td>0.580450</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.801, 1.167, 8.033, 0.432, 0.087, 0.073]</td>\n",
       "      <td>0.203538</td>\n",
       "      <td>0.406876</td>\n",
       "      <td>0.595084</td>\n",
       "      <td>0.692727</td>\n",
       "      <td>0.236626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>[7.507, 0.144, 0.173]</td>\n",
       "      <td>0.206008</td>\n",
       "      <td>0.412764</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.691576</td>\n",
       "      <td>0.232034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.997, 1.065, 0.008, 0.006]</td>\n",
       "      <td>0.208440</td>\n",
       "      <td>0.417471</td>\n",
       "      <td>0.606193</td>\n",
       "      <td>0.685403</td>\n",
       "      <td>0.243938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.997, 0.008, 0.007]</td>\n",
       "      <td>0.208532</td>\n",
       "      <td>0.417024</td>\n",
       "      <td>0.606492</td>\n",
       "      <td>0.687241</td>\n",
       "      <td>0.240460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.969, 0.813, 0.648, 0.012, 0.01]</td>\n",
       "      <td>0.209698</td>\n",
       "      <td>0.419987</td>\n",
       "      <td>0.608994</td>\n",
       "      <td>0.685327</td>\n",
       "      <td>0.253611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>[1.423, 0.186, 0.362]</td>\n",
       "      <td>0.210643</td>\n",
       "      <td>0.421846</td>\n",
       "      <td>0.610948</td>\n",
       "      <td>0.679325</td>\n",
       "      <td>0.152402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.079, 2.661, 0.017, 0.014]</td>\n",
       "      <td>0.210637</td>\n",
       "      <td>0.421841</td>\n",
       "      <td>0.611214</td>\n",
       "      <td>0.681571</td>\n",
       "      <td>0.251588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.01, 0.024, 0.021]</td>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.422069</td>\n",
       "      <td>0.611717</td>\n",
       "      <td>0.681110</td>\n",
       "      <td>0.249051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.995, 0.013, 0.011]</td>\n",
       "      <td>0.211082</td>\n",
       "      <td>0.422421</td>\n",
       "      <td>0.612090</td>\n",
       "      <td>0.681110</td>\n",
       "      <td>0.249051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.995, 2.048, 0.008, 0.011]</td>\n",
       "      <td>0.211082</td>\n",
       "      <td>0.422421</td>\n",
       "      <td>0.612090</td>\n",
       "      <td>0.681110</td>\n",
       "      <td>0.249051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.996, 5.215, 0.307, 1.036]</td>\n",
       "      <td>0.214804</td>\n",
       "      <td>0.431046</td>\n",
       "      <td>0.620832</td>\n",
       "      <td>0.672736</td>\n",
       "      <td>0.165351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.693, 2.219, 89.518, 5.384, 0.003, 0.184]</td>\n",
       "      <td>0.218405</td>\n",
       "      <td>0.436704</td>\n",
       "      <td>0.628259</td>\n",
       "      <td>0.665584</td>\n",
       "      <td>0.121893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.839, 0.654, 1.843, 0.424]</td>\n",
       "      <td>0.227929</td>\n",
       "      <td>0.456367</td>\n",
       "      <td>0.647989</td>\n",
       "      <td>0.638314</td>\n",
       "      <td>0.103138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.741, 2.713, 0.392]</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.457895</td>\n",
       "      <td>0.650230</td>\n",
       "      <td>0.630819</td>\n",
       "      <td>0.084416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>[3.529, 2.566, 0.408]</td>\n",
       "      <td>0.229026</td>\n",
       "      <td>0.457951</td>\n",
       "      <td>0.650284</td>\n",
       "      <td>0.630936</td>\n",
       "      <td>0.084494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.936, 0.794, 2.357, 0.48]</td>\n",
       "      <td>0.229337</td>\n",
       "      <td>0.458473</td>\n",
       "      <td>0.650913</td>\n",
       "      <td>0.629953</td>\n",
       "      <td>0.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.936, 0.794, 1.454, 2.357, 0.48]</td>\n",
       "      <td>0.229337</td>\n",
       "      <td>0.458473</td>\n",
       "      <td>0.650913</td>\n",
       "      <td>0.629953</td>\n",
       "      <td>0.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.325, 0.481, 0.408, 2.36, 0.479]</td>\n",
       "      <td>0.229356</td>\n",
       "      <td>0.458443</td>\n",
       "      <td>0.650956</td>\n",
       "      <td>0.629882</td>\n",
       "      <td>0.076695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.746, 2.084, 0.536]</td>\n",
       "      <td>0.229376</td>\n",
       "      <td>0.458587</td>\n",
       "      <td>0.650977</td>\n",
       "      <td>0.629326</td>\n",
       "      <td>0.076183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.746, 96.942, 2.108, 0.537]</td>\n",
       "      <td>0.229380</td>\n",
       "      <td>0.458596</td>\n",
       "      <td>0.650986</td>\n",
       "      <td>0.629391</td>\n",
       "      <td>0.075724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.075, 5.399, 2.283, 0.495]</td>\n",
       "      <td>0.229417</td>\n",
       "      <td>0.458611</td>\n",
       "      <td>0.651072</td>\n",
       "      <td>0.629325</td>\n",
       "      <td>0.077125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.291, 2.913, 0.418]</td>\n",
       "      <td>0.229445</td>\n",
       "      <td>0.458778</td>\n",
       "      <td>0.651142</td>\n",
       "      <td>0.628949</td>\n",
       "      <td>0.080638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle                                       params   \n",
       "99      heuristic     --                                         None  \\\n",
       "21          trade  power   [0.801, 1.167, 8.033, 0.432, 0.087, 0.073]   \n",
       "13           hbmd  power                        [7.507, 0.144, 0.173]   \n",
       "19     quasihb_fc  power          [0.997, 0.997, 1.065, 0.008, 0.006]   \n",
       "17        quasihb  power                 [0.997, 0.997, 0.008, 0.007]   \n",
       "7           expo2  power           [0.969, 0.813, 0.648, 0.012, 0.01]   \n",
       "3   attention_uni  power                        [1.423, 0.186, 0.362]   \n",
       "11            hb2  power                 [0.079, 2.661, 0.017, 0.014]   \n",
       "9              hb  power                         [0.01, 0.024, 0.021]   \n",
       "5            expo  power                        [0.995, 0.013, 0.011]   \n",
       "15            hce  power                 [0.995, 2.048, 0.008, 0.011]   \n",
       "1       attention  power                 [0.996, 5.215, 0.307, 1.036]   \n",
       "20          trade   cara  [0.693, 2.219, 89.518, 5.384, 0.003, 0.184]   \n",
       "0       attention   cara                 [0.839, 0.654, 1.843, 0.424]   \n",
       "2   attention_uni   cara                        [0.741, 2.713, 0.392]   \n",
       "12           hbmd   cara                        [3.529, 2.566, 0.408]   \n",
       "16        quasihb   cara                  [0.936, 0.794, 2.357, 0.48]   \n",
       "18     quasihb_fc   cara           [0.936, 0.794, 1.454, 2.357, 0.48]   \n",
       "6           expo2   cara           [0.325, 0.481, 0.408, 2.36, 0.479]   \n",
       "4            expo   cara                        [0.746, 2.084, 0.536]   \n",
       "14            hce   cara                [0.746, 96.942, 2.108, 0.537]   \n",
       "10            hb2   cara                 [0.075, 5.399, 2.283, 0.495]   \n",
       "8              hb   cara                        [0.291, 2.913, 0.418]   \n",
       "\n",
       "         mse       mae  log_loss  accuracy   pred_ll  \n",
       "99  0.297701  0.297701  0.580450  0.702299       NaN  \n",
       "21  0.203538  0.406876  0.595084  0.692727  0.236626  \n",
       "13  0.206008  0.412764  0.601453  0.691576  0.232034  \n",
       "19  0.208440  0.417471  0.606193  0.685403  0.243938  \n",
       "17  0.208532  0.417024  0.606492  0.687241  0.240460  \n",
       "7   0.209698  0.419987  0.608994  0.685327  0.253611  \n",
       "3   0.210643  0.421846  0.610948  0.679325  0.152402  \n",
       "11  0.210637  0.421841  0.611214  0.681571  0.251588  \n",
       "9   0.210859  0.422069  0.611717  0.681110  0.249051  \n",
       "5   0.211082  0.422421  0.612090  0.681110  0.249051  \n",
       "15  0.211082  0.422421  0.612090  0.681110  0.249051  \n",
       "1   0.214804  0.431046  0.620832  0.672736  0.165351  \n",
       "20  0.218405  0.436704  0.628259  0.665584  0.121893  \n",
       "0   0.227929  0.456367  0.647989  0.638314  0.103138  \n",
       "2   0.229008  0.457895  0.650230  0.630819  0.084416  \n",
       "12  0.229026  0.457951  0.650284  0.630936  0.084494  \n",
       "16  0.229337  0.458473  0.650913  0.629953  0.076900  \n",
       "18  0.229337  0.458473  0.650913  0.629953  0.076900  \n",
       "6   0.229356  0.458443  0.650956  0.629882  0.076695  \n",
       "4   0.229376  0.458587  0.650977  0.629326  0.076183  \n",
       "14  0.229380  0.458596  0.650986  0.629391  0.075724  \n",
       "10  0.229417  0.458611  0.651072  0.629325  0.077125  \n",
       "8   0.229445  0.458778  0.651142  0.628949  0.080638  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Cross-validation result\n",
    "kf_result_df = kf.summary()\n",
    "kf_result = kf_result_df.drop('style',axis=1)\n",
    "kf_result = pd.concat([kf_result,pd.DataFrame(heuristic_kf_dict,index=[99])]).sort_values('log_loss')\n",
    "kf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.199584</td>\n",
       "      <td>0.399751</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.701781</td>\n",
       "      <td>0.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.203571</td>\n",
       "      <td>0.410726</td>\n",
       "      <td>0.595768</td>\n",
       "      <td>0.696351</td>\n",
       "      <td>0.236751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.201927</td>\n",
       "      <td>0.405074</td>\n",
       "      <td>0.591320</td>\n",
       "      <td>0.695048</td>\n",
       "      <td>0.249348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.411951</td>\n",
       "      <td>0.602772</td>\n",
       "      <td>0.693527</td>\n",
       "      <td>0.248262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.207318</td>\n",
       "      <td>0.422127</td>\n",
       "      <td>0.603657</td>\n",
       "      <td>0.693527</td>\n",
       "      <td>0.248262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.209738</td>\n",
       "      <td>0.427269</td>\n",
       "      <td>0.609090</td>\n",
       "      <td>0.689835</td>\n",
       "      <td>0.306255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.209680</td>\n",
       "      <td>0.428482</td>\n",
       "      <td>0.608991</td>\n",
       "      <td>0.685925</td>\n",
       "      <td>0.260209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.208980</td>\n",
       "      <td>0.423751</td>\n",
       "      <td>0.607495</td>\n",
       "      <td>0.685925</td>\n",
       "      <td>0.260209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.421783</td>\n",
       "      <td>0.611195</td>\n",
       "      <td>0.678323</td>\n",
       "      <td>0.157037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.215437</td>\n",
       "      <td>0.430909</td>\n",
       "      <td>0.623362</td>\n",
       "      <td>0.672893</td>\n",
       "      <td>0.141616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.217419</td>\n",
       "      <td>0.433961</td>\n",
       "      <td>0.625944</td>\n",
       "      <td>0.668115</td>\n",
       "      <td>0.120330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230670</td>\n",
       "      <td>0.457275</td>\n",
       "      <td>0.653657</td>\n",
       "      <td>0.629018</td>\n",
       "      <td>0.090791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230824</td>\n",
       "      <td>0.459209</td>\n",
       "      <td>0.653935</td>\n",
       "      <td>0.624023</td>\n",
       "      <td>0.086664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230879</td>\n",
       "      <td>0.459340</td>\n",
       "      <td>0.654061</td>\n",
       "      <td>0.622719</td>\n",
       "      <td>0.085361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.232542</td>\n",
       "      <td>0.454265</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>0.619679</td>\n",
       "      <td>0.045830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231474</td>\n",
       "      <td>0.460323</td>\n",
       "      <td>0.655266</td>\n",
       "      <td>0.617724</td>\n",
       "      <td>0.082103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231405</td>\n",
       "      <td>0.460274</td>\n",
       "      <td>0.655105</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.079713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231288</td>\n",
       "      <td>0.459983</td>\n",
       "      <td>0.654878</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.078410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231288</td>\n",
       "      <td>0.459983</td>\n",
       "      <td>0.654878</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.078410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231402</td>\n",
       "      <td>0.460212</td>\n",
       "      <td>0.655101</td>\n",
       "      <td>0.617507</td>\n",
       "      <td>0.079713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.239805</td>\n",
       "      <td>0.446834</td>\n",
       "      <td>0.679050</td>\n",
       "      <td>0.615552</td>\n",
       "      <td>0.012598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.385177</td>\n",
       "      <td>0.385650</td>\n",
       "      <td>4.767475</td>\n",
       "      <td>0.614248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.385682</td>\n",
       "      <td>0.385739</td>\n",
       "      <td>6.562389</td>\n",
       "      <td>0.614248</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy   pred_ll\n",
       "99       heurstic     --  0.199584  0.399751  0.586111  0.701781  0.290400\n",
       "13           hbmd  power  0.203571  0.410726  0.595768  0.696351  0.236751\n",
       "21          trade  power  0.201927  0.405074  0.591320  0.695048  0.249348\n",
       "19     quasihb_fc  power  0.206754  0.411951  0.602772  0.693527  0.248262\n",
       "17        quasihb  power  0.207318  0.422127  0.603657  0.693527  0.248262\n",
       "5            expo  power  0.209738  0.427269  0.609090  0.689835  0.306255\n",
       "15            hce  power  0.209680  0.428482  0.608991  0.685925  0.260209\n",
       "9              hb  power  0.208980  0.423751  0.607495  0.685925  0.260209\n",
       "3   attention_uni  power  0.210744  0.421783  0.611195  0.678323  0.157037\n",
       "1       attention  power  0.215437  0.430909  0.623362  0.672893  0.141616\n",
       "20          trade   cara  0.217419  0.433961  0.625944  0.668115  0.120330\n",
       "0       attention   cara  0.230670  0.457275  0.653657  0.629018  0.090791\n",
       "2   attention_uni   cara  0.230824  0.459209  0.653935  0.624023  0.086664\n",
       "12           hbmd   cara  0.230879  0.459340  0.654061  0.622719  0.085361\n",
       "10            hb2   cara  0.232542  0.454265  0.657899  0.619679  0.045830\n",
       "8              hb   cara  0.231474  0.460323  0.655266  0.617724  0.082103\n",
       "14            hce   cara  0.231405  0.460274  0.655105  0.617507  0.079713\n",
       "16        quasihb   cara  0.231288  0.459983  0.654878  0.617507  0.078410\n",
       "18     quasihb_fc   cara  0.231288  0.459983  0.654878  0.617507  0.078410\n",
       "4            expo   cara  0.231402  0.460212  0.655101  0.617507  0.079713\n",
       "6           expo2   cara  0.239805  0.446834  0.679050  0.615552  0.012598\n",
       "7           expo2  power  0.385177  0.385650  4.767475  0.614248  0.000000\n",
       "11            hb2  power  0.385682  0.385739  6.562389  0.614248  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Out-of-sample performance\n",
    "test_sample = data_prepare.test_sample\n",
    "test_result = cross_valid.get_result_tab(kf_result_df,test_sample)\n",
    "\n",
    "with open('my_model.pkl', 'rb') as f:\n",
    "    heuristic_model = pickle.load(f)\n",
    "\n",
    "heuristic_test_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,X_test=X_test,y_test=y_test)\n",
    "\n",
    "test_result = pd.concat([test_result,pd.DataFrame(heuristic_test_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.102988</td>\n",
       "      <td>0.304444</td>\n",
       "      <td>0.374555</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.115094</td>\n",
       "      <td>0.321138</td>\n",
       "      <td>0.400894</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.113381</td>\n",
       "      <td>0.316242</td>\n",
       "      <td>0.395907</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125017</td>\n",
       "      <td>0.338001</td>\n",
       "      <td>0.425722</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.133961</td>\n",
       "      <td>0.351174</td>\n",
       "      <td>0.446390</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.128639</td>\n",
       "      <td>0.341746</td>\n",
       "      <td>0.433188</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.132665</td>\n",
       "      <td>0.348959</td>\n",
       "      <td>0.443324</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.138541</td>\n",
       "      <td>0.349727</td>\n",
       "      <td>0.451288</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.152987</td>\n",
       "      <td>0.368502</td>\n",
       "      <td>0.481647</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.151692</td>\n",
       "      <td>0.367740</td>\n",
       "      <td>0.484493</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.183247</td>\n",
       "      <td>0.409006</td>\n",
       "      <td>0.554277</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185350</td>\n",
       "      <td>0.413164</td>\n",
       "      <td>0.558857</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.412750</td>\n",
       "      <td>0.558224</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.182235</td>\n",
       "      <td>0.403223</td>\n",
       "      <td>0.550820</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186643</td>\n",
       "      <td>0.414696</td>\n",
       "      <td>0.561603</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186643</td>\n",
       "      <td>0.414696</td>\n",
       "      <td>0.561603</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187032</td>\n",
       "      <td>0.415310</td>\n",
       "      <td>0.562375</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187330</td>\n",
       "      <td>0.415497</td>\n",
       "      <td>0.563083</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187265</td>\n",
       "      <td>0.415368</td>\n",
       "      <td>0.562935</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.182586</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>0.548291</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.244347</td>\n",
       "      <td>0.244804</td>\n",
       "      <td>2.655793</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.244921</td>\n",
       "      <td>0.244976</td>\n",
       "      <td>3.676614</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "21          trade  power  0.102988  0.304444  0.374555     0.957    0.228\n",
       "13           hbmd  power  0.115094  0.321138  0.400894     0.950    0.203\n",
       "19     quasihb_fc  power  0.113381  0.316242  0.395907     0.934    0.209\n",
       "17        quasihb  power  0.125017  0.338001  0.425722     0.934    0.209\n",
       "15            hce  power  0.133961  0.351174  0.446390     0.927    0.224\n",
       "9              hb  power  0.128639  0.341746  0.433188     0.927    0.224\n",
       "5            expo  power  0.132665  0.348959  0.443324     0.918    0.253\n",
       "3   attention_uni  power  0.138541  0.349727  0.451288     0.878    0.137\n",
       "1       attention  power  0.152987  0.368502  0.481647     0.859    0.126\n",
       "20          trade   cara  0.151692  0.367740  0.484493     0.843    0.102\n",
       "0       attention   cara  0.183247  0.409006  0.554277     0.793    0.074\n",
       "12           hbmd   cara  0.185350  0.413164  0.558857     0.784    0.069\n",
       "2   attention_uni   cara  0.185035  0.412750  0.558224     0.783    0.070\n",
       "10            hb2   cara  0.182235  0.403223  0.550820     0.779    0.036\n",
       "16        quasihb   cara  0.186643  0.414696  0.561603     0.779    0.068\n",
       "18     quasihb_fc   cara  0.186643  0.414696  0.561603     0.779    0.068\n",
       "8              hb   cara  0.187032  0.415310  0.562375     0.777    0.070\n",
       "14            hce   cara  0.187330  0.415497  0.563083     0.774    0.073\n",
       "4            expo   cara  0.187265  0.415368  0.562935     0.774    0.073\n",
       "6           expo2   cara  0.182586  0.389322  0.548291     0.772    0.017\n",
       "7           expo2  power  0.244347  0.244804  2.655793     0.755    0.000\n",
       "11            hb2  power  0.244921  0.244976  3.676614     0.755    0.000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly draw 1000 questions from the dataset \n",
    "# Use the prediction value by XGBoost as the label\n",
    "# Examine which model can explain the XGBoost's prediction the best\n",
    "rda_sample = itch_dt[itch_dt.index.isin(np.random.choice(itch_dt.index,size=1000,replace=False))][['ss_x','ss_t','ll_x','ll_t']]\n",
    "rda_prepare = cross_valid.data_prepare(data=rda_sample)\n",
    "rda_prepare.generate_features()\n",
    "rda_sample = rda_prepare._data[features]\n",
    "rda_sample[label] = heuristic_model.predict(rda_sample[features])\n",
    "\n",
    "rda_result = cross_valid.get_result_tab(kf_result_df,rda_sample)\n",
    "rda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.104826</td>\n",
       "      <td>0.302410</td>\n",
       "      <td>0.374942</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.115726</td>\n",
       "      <td>0.321769</td>\n",
       "      <td>0.402108</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.129027</td>\n",
       "      <td>0.342133</td>\n",
       "      <td>0.433830</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.134387</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.447140</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.316495</td>\n",
       "      <td>0.396258</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.125218</td>\n",
       "      <td>0.338202</td>\n",
       "      <td>0.426023</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.133404</td>\n",
       "      <td>0.349697</td>\n",
       "      <td>0.444744</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.140181</td>\n",
       "      <td>0.351367</td>\n",
       "      <td>0.454956</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.153357</td>\n",
       "      <td>0.368871</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.148722</td>\n",
       "      <td>0.364771</td>\n",
       "      <td>0.478470</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.183939</td>\n",
       "      <td>0.409698</td>\n",
       "      <td>0.556043</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.181764</td>\n",
       "      <td>0.402753</td>\n",
       "      <td>0.550342</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.180499</td>\n",
       "      <td>0.387235</td>\n",
       "      <td>0.544633</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186238</td>\n",
       "      <td>0.414052</td>\n",
       "      <td>0.560951</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185945</td>\n",
       "      <td>0.413659</td>\n",
       "      <td>0.560368</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187047</td>\n",
       "      <td>0.415099</td>\n",
       "      <td>0.562722</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187047</td>\n",
       "      <td>0.415099</td>\n",
       "      <td>0.562722</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187570</td>\n",
       "      <td>0.415849</td>\n",
       "      <td>0.563754</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187473</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>0.563692</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.415504</td>\n",
       "      <td>0.563531</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.227380</td>\n",
       "      <td>0.227837</td>\n",
       "      <td>2.549454</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.227925</td>\n",
       "      <td>0.227980</td>\n",
       "      <td>3.519176</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "99       heurstic     --  0.104826  0.302410  0.374942     0.957    0.245\n",
       "13           hbmd  power  0.115726  0.321769  0.402108     0.943    0.203\n",
       "9              hb  power  0.129027  0.342133  0.433830     0.928    0.224\n",
       "15            hce  power  0.134387  0.351601  0.447140     0.928    0.224\n",
       "19     quasihb_fc  power  0.113634  0.316495  0.396258     0.921    0.209\n",
       "17        quasihb  power  0.125218  0.338202  0.426023     0.921    0.209\n",
       "5            expo  power  0.133404  0.349697  0.444744     0.907    0.253\n",
       "3   attention_uni  power  0.140181  0.351367  0.454956     0.879    0.137\n",
       "1       attention  power  0.153357  0.368871  0.482425     0.864    0.126\n",
       "20          trade   cara  0.148722  0.364771  0.478470     0.860    0.102\n",
       "0       attention   cara  0.183939  0.409698  0.556043     0.794    0.074\n",
       "10            hb2   cara  0.181764  0.402753  0.550342     0.792    0.036\n",
       "6           expo2   cara  0.180499  0.387235  0.544633     0.789    0.017\n",
       "12           hbmd   cara  0.186238  0.414052  0.560951     0.785    0.069\n",
       "2   attention_uni   cara  0.185945  0.413659  0.560368     0.784    0.070\n",
       "16        quasihb   cara  0.187047  0.415099  0.562722     0.780    0.068\n",
       "18     quasihb_fc   cara  0.187047  0.415099  0.562722     0.780    0.068\n",
       "8              hb   cara  0.187570  0.415849  0.563754     0.776    0.070\n",
       "14            hce   cara  0.187473  0.415640  0.563692     0.775    0.073\n",
       "4            expo   cara  0.187400  0.415504  0.563531     0.775    0.073\n",
       "7           expo2  power  0.227380  0.227837  2.549454     0.772    0.000\n",
       "11            hb2  power  0.227925  0.227980  3.519176     0.772    0.000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the prediction value by magnitude-dependent hyperbolic (hbmd) with power utillity as the label\n",
    "# Examine which model can explain the hbmd's prediction the best\n",
    "target_kf_row = kf_result_df[(kf_result_df['dstyle']=='trade') & (kf_result_df['ustyle']=='power')]\n",
    "target_style = target_kf_row['style'].values[0]\n",
    "target_params = target_kf_row['params'].values[0]\n",
    "\n",
    "choice_prob = cross_valid.test_model(style=target_style,params=target_params,test_sample=rda_sample,output='predict_proba')\n",
    "rda_sample[label] = (choice_prob >.5)\n",
    "\n",
    "rda_result_2 = cross_valid.get_result_tab(kf_result_df,rda_sample).iloc[1:,:]\n",
    "heuristic_rda_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,test_sample=rda_sample)\n",
    "rda_result_2 = pd.concat([rda_result_2,pd.DataFrame(heuristic_rda_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "rda_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "kf_result.to_csv(\"table/itch_result_kf.csv\",index=False)\n",
    "test_result.to_csv(\"table/itch_result_test.csv\",index=False)\n",
    "rda_result.to_csv(\"table/itch_result_rda.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10251063829787234"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(itch_dt['ll_x']>5000).sum()/(itch_dt['ll_x']).shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

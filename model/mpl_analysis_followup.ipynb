{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from mpl import cross_valid\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "itch_dt = pd.read_csv('data/ericson_data.csv')\n",
    "itch_dt = itch_dt.rename(columns={\"Subject\":\"person_id\",\n",
    "                                \"Condition\":\"condition\",\n",
    "                                \"Question\":\"question_id\",\n",
    "                                \"X1\":\"ss_x\",\n",
    "                                \"T1\":\"ss_t\",\n",
    "                                \"X2\":\"ll_x\",\n",
    "                                \"T2\":\"ll_t\",\n",
    "                                \"LaterOptionChosen\": \"choice\"}).\\\n",
    "                drop(['R','G','D'],axis=1)\n",
    "\n",
    "\n",
    "# Define features, label, and group variable\n",
    "features = ['ss_x', 'ss_t', 'll_x', 'll_t',\n",
    "            'abs_diff_x', 'abs_diff_t', 'rel_diff_x','rel_diff_t',\n",
    "            'growth_x']\n",
    "label = 'choice'\n",
    "group = 'person_id'\n",
    "\n",
    "# Omit the choice questions of which ss_x <= 5\n",
    "# After omission, 9 persons that answers less than 10 questions (maximum is 23 questions)\n",
    "# Removew these persons from the dataset\n",
    "dataset = itch_dt[itch_dt['ss_x'] > 5]\n",
    "count_indvd_choice = dataset.groupby('person_id').choice.count()\n",
    "person_id_omit = list(count_indvd_choice[count_indvd_choice <= 10].index)\n",
    "dataset = dataset[~dataset['person_id'].isin(person_id_omit)]\n",
    "\n",
    "data_prepare = cross_valid.data_prepare(data=dataset,feature=features,label=label,group=group)\n",
    "data_prepare.generate_features()\n",
    "dataset = data_prepare._data\n",
    "\n",
    "# Split the data into train sample and test sample\n",
    "# Train sample containts 80% of the participants, test sample contains the rest \n",
    "X_train,X_test,y_train,y_test = data_prepare.split_sample(test_size=0.2)\n",
    "groups = data_prepare.train_sample[group]\n",
    "\n",
    "# Split the train sample into K folds (K=10) for cross-validation\n",
    "sgkf = model_selection.StratifiedGroupKFold(n_splits=10,shuffle=True,random_state=2023)\n",
    "cv = list(sgkf.split(X=X_train,y=y_train,groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset['person_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([   72,    73,    74, ..., 12248, 12249, 12250])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([   21,    22,    23, ..., 12168, 12169, 12170])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([  629,   630,   631, ..., 12297, 12298, 12299])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([  176,   177,   178, ..., 12187, 12188, 12189])),\n",
       "                 (array([    0,     1...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([   72,    73,    74, ..., 12248, 12249, 12250])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([   21,    22,    23, ..., 12168, 12169, 12170])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([  629,   630,   631, ..., 12297, 12298, 12299])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([  176,   177,   178, ..., 12187, 12188, 12189])),\n",
       "                 (array([    0,     1...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=[(array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([   72,    73,    74, ..., 12248, 12249, 12250])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([   21,    22,    23, ..., 12168, 12169, 12170])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([  629,   630,   631, ..., 12297, 12298, 12299])),\n",
       "                 (array([    0,     1,     2, ..., 12330, 12331, 12332]),\n",
       "                  array([  176,   177,   178, ..., 12187, 12188, 12189])),\n",
       "                 (array([    0,     1...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [1.0], 'gamma': [0.3],\n",
       "                         'learning_rate': [0.1], 'max_depth': [3],\n",
       "                         'n_estimators': [40], 'reg_lambda': [0.7],\n",
       "                         'subsample': [0.55]},\n",
       "             refit='neg_log_loss',\n",
       "             scoring=['accuracy', 'neg_log_loss', 'neg_mean_absolute_error',\n",
       "                      'neg_mean_squared_error'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost to fit the data\n",
    "# Tune the hyer-parameters by grid search \n",
    "# The following dictionary directly shows the tuning results \n",
    "param_grid = {'n_estimators': [40],\n",
    "              'max_depth': [3],\n",
    "              'learning_rate': [.1],\n",
    "              'gamma': [.3],\n",
    "              'reg_lambda': [.7],\n",
    "              'subsample': [.55],\n",
    "              'colsample_bytree': [1.0]\n",
    "            }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(model, param_grid, \n",
    "                                           cv=cv, \n",
    "                                           scoring=[\"accuracy\",\"neg_log_loss\",'neg_mean_absolute_error','neg_mean_squared_error'], \n",
    "                                           refit=\"neg_log_loss\",\n",
    "                                           n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search.fit(X=X_train,y=y_train,groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the XGBoost model and check the feature importance\n",
    "bst_model = grid_search.best_estimator_\n",
    "\n",
    "with open('my_model_followup.pkl', 'wb') as f:\n",
    "    pickle.dump(bst_model, f)\n",
    "\n",
    "\n",
    "heuristic_kf_dict = {'dstyle': 'heuristic',\n",
    "            'ustyle': '--',\n",
    "            'params': None,\n",
    "            'accuracy': grid_search.cv_results_['mean_test_accuracy'][0],\n",
    "            'log_loss': -grid_search.cv_results_['mean_test_neg_log_loss'][0],\n",
    "            'mse':-grid_search.cv_results_['mean_test_neg_mean_squared_error'][0],\n",
    "            'mae':-grid_search.cv_results_['mean_test_neg_mean_absolute_error'][0]\n",
    "            }\n",
    "\n",
    "xgb.plot_importance(bst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a decision tree\n",
    "# To check structure of different trees, change num_trees \n",
    "#xgb.to_graphviz(bst_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [51:31<00:00, 14.05s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Fit data by distounted utility model and trade-off model\n",
    "style_list = cross_valid.estimation.gen_style_list()\n",
    "train_sample = data_prepare.train_sample\n",
    "\n",
    "kf = cross_valid.KFvalidation(style=style_list,data=train_sample,cv=cv,n_jobs=4)\n",
    "kf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if some of the fits fail to converge \n",
    "np.where(kf.success==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>params</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heuristic</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>0.270513</td>\n",
       "      <td>0.270513</td>\n",
       "      <td>0.557676</td>\n",
       "      <td>0.729487</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.524, 1.231, 7.45, 0.608, 0.114, 0.112]</td>\n",
       "      <td>0.192958</td>\n",
       "      <td>0.385622</td>\n",
       "      <td>0.572563</td>\n",
       "      <td>0.722129</td>\n",
       "      <td>0.200266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>[8.931, 0.129, 0.148]</td>\n",
       "      <td>0.195510</td>\n",
       "      <td>0.391986</td>\n",
       "      <td>0.579438</td>\n",
       "      <td>0.723987</td>\n",
       "      <td>0.210993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.997, 0.011, 0.007]</td>\n",
       "      <td>0.196137</td>\n",
       "      <td>0.392524</td>\n",
       "      <td>0.580285</td>\n",
       "      <td>0.722592</td>\n",
       "      <td>0.224947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.997, 0.961, 0.011, 0.007]</td>\n",
       "      <td>0.196274</td>\n",
       "      <td>0.392667</td>\n",
       "      <td>0.580611</td>\n",
       "      <td>0.722592</td>\n",
       "      <td>0.224947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.218, 0.017, 0.011]</td>\n",
       "      <td>0.196212</td>\n",
       "      <td>0.393323</td>\n",
       "      <td>0.580823</td>\n",
       "      <td>0.725026</td>\n",
       "      <td>0.214443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.824, 0.905, 0.357, 0.012, 0.008]</td>\n",
       "      <td>0.196287</td>\n",
       "      <td>0.393447</td>\n",
       "      <td>0.580837</td>\n",
       "      <td>0.723149</td>\n",
       "      <td>0.219764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.002, 0.007, 0.004]</td>\n",
       "      <td>0.197862</td>\n",
       "      <td>0.396756</td>\n",
       "      <td>0.584151</td>\n",
       "      <td>0.718838</td>\n",
       "      <td>0.230490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 2.207, 0.006, 0.006]</td>\n",
       "      <td>0.197913</td>\n",
       "      <td>0.396547</td>\n",
       "      <td>0.584309</td>\n",
       "      <td>0.720067</td>\n",
       "      <td>0.232134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.007, 0.005]</td>\n",
       "      <td>0.197962</td>\n",
       "      <td>0.395719</td>\n",
       "      <td>0.584534</td>\n",
       "      <td>0.717927</td>\n",
       "      <td>0.229382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.001, 4.728, 0.019, 0.013]</td>\n",
       "      <td>0.198053</td>\n",
       "      <td>0.396975</td>\n",
       "      <td>0.584842</td>\n",
       "      <td>0.720379</td>\n",
       "      <td>0.232877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.993, 6.033, 0.319, 1.234]</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>0.413111</td>\n",
       "      <td>0.601887</td>\n",
       "      <td>0.704769</td>\n",
       "      <td>0.182056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.507, 2.653, 96.626, 65.193, 2.254, 2.222]</td>\n",
       "      <td>0.224519</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>0.640892</td>\n",
       "      <td>0.647890</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.399, 0.263, 14.494, 0.04]</td>\n",
       "      <td>0.225129</td>\n",
       "      <td>0.450042</td>\n",
       "      <td>0.642226</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.953, 0.874, 1.622, 2.421, 0.331]</td>\n",
       "      <td>0.225130</td>\n",
       "      <td>0.450342</td>\n",
       "      <td>0.642226</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.539, 3.026, 0.293]</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>0.450056</td>\n",
       "      <td>0.642248</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>[6.438, 3.273, 0.293]</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>0.450056</td>\n",
       "      <td>0.642248</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.156, 3.368, 0.293]</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>0.450056</td>\n",
       "      <td>0.642248</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>[1.0, 0.539, 2.616, 0.293]</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>0.450056</td>\n",
       "      <td>0.642248</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.641, 0.665, 0.496, 2.273, 0.02]</td>\n",
       "      <td>0.225139</td>\n",
       "      <td>0.449976</td>\n",
       "      <td>0.642251</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.954, 0.886, 2.263, 0.309]</td>\n",
       "      <td>0.225160</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.791, 3.076, 0.466]</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.450104</td>\n",
       "      <td>0.642302</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.791, 2.171, 3.467, 0.466]</td>\n",
       "      <td>0.225166</td>\n",
       "      <td>0.450104</td>\n",
       "      <td>0.642302</td>\n",
       "      <td>0.646822</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle                                        params   \n",
       "99      heuristic     --                                          None  \\\n",
       "21          trade  power     [0.524, 1.231, 7.45, 0.608, 0.114, 0.112]   \n",
       "13           hbmd  power                         [8.931, 0.129, 0.148]   \n",
       "17        quasihb  power                  [0.997, 0.997, 0.011, 0.007]   \n",
       "19     quasihb_fc  power           [0.997, 0.997, 0.961, 0.011, 0.007]   \n",
       "3   attention_uni  power                         [0.218, 0.017, 0.011]   \n",
       "7           expo2  power           [0.824, 0.905, 0.357, 0.012, 0.008]   \n",
       "9              hb  power                         [0.002, 0.007, 0.004]   \n",
       "15            hce  power                  [0.997, 2.207, 0.006, 0.006]   \n",
       "5            expo  power                         [0.997, 0.007, 0.005]   \n",
       "11            hb2  power                  [0.001, 4.728, 0.019, 0.013]   \n",
       "1       attention  power                  [0.993, 6.033, 0.319, 1.234]   \n",
       "20          trade   cara  [0.507, 2.653, 96.626, 65.193, 2.254, 2.222]   \n",
       "10            hb2   cara                  [0.399, 0.263, 14.494, 0.04]   \n",
       "18     quasihb_fc   cara           [0.953, 0.874, 1.622, 2.421, 0.331]   \n",
       "2   attention_uni   cara                         [0.539, 3.026, 0.293]   \n",
       "12           hbmd   cara                         [6.438, 3.273, 0.293]   \n",
       "8              hb   cara                         [0.156, 3.368, 0.293]   \n",
       "0       attention   cara                    [1.0, 0.539, 2.616, 0.293]   \n",
       "6           expo2   cara            [0.641, 0.665, 0.496, 2.273, 0.02]   \n",
       "16        quasihb   cara                  [0.954, 0.886, 2.263, 0.309]   \n",
       "4            expo   cara                         [0.791, 3.076, 0.466]   \n",
       "14            hce   cara                  [0.791, 2.171, 3.467, 0.466]   \n",
       "\n",
       "         mse       mae  log_loss  accuracy   pred_ll  \n",
       "99  0.270513  0.270513  0.557676  0.729487       NaN  \n",
       "21  0.192958  0.385622  0.572563  0.722129  0.200266  \n",
       "13  0.195510  0.391986  0.579438  0.723987  0.210993  \n",
       "17  0.196137  0.392524  0.580285  0.722592  0.224947  \n",
       "19  0.196274  0.392667  0.580611  0.722592  0.224947  \n",
       "3   0.196212  0.393323  0.580823  0.725026  0.214443  \n",
       "7   0.196287  0.393447  0.580837  0.723149  0.219764  \n",
       "9   0.197862  0.396756  0.584151  0.718838  0.230490  \n",
       "15  0.197913  0.396547  0.584309  0.720067  0.232134  \n",
       "5   0.197962  0.395719  0.584534  0.717927  0.229382  \n",
       "11  0.198053  0.396975  0.584842  0.720379  0.232877  \n",
       "1   0.205600  0.413111  0.601887  0.704769  0.182056  \n",
       "20  0.224519  0.448645  0.640892  0.647890  0.002627  \n",
       "10  0.225129  0.450042  0.642226  0.646822  0.000000  \n",
       "18  0.225130  0.450342  0.642226  0.646822  0.000000  \n",
       "2   0.225140  0.450056  0.642248  0.646822  0.000000  \n",
       "12  0.225140  0.450056  0.642248  0.646822  0.000000  \n",
       "8   0.225140  0.450056  0.642248  0.646822  0.000000  \n",
       "0   0.225140  0.450056  0.642248  0.646822  0.000000  \n",
       "6   0.225139  0.449976  0.642251  0.646822  0.000000  \n",
       "16  0.225160  0.450011  0.642300  0.646822  0.000000  \n",
       "4   0.225166  0.450104  0.642302  0.646822  0.000000  \n",
       "14  0.225166  0.450104  0.642302  0.646822  0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Cross-validation result\n",
    "kf_result_df = kf.summary()\n",
    "kf_result = kf_result_df.drop('style',axis=1)\n",
    "kf_result = pd.concat([kf_result,pd.DataFrame(heuristic_kf_dict,index=[99])]).sort_values('log_loss')\n",
    "kf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.183912</td>\n",
       "      <td>0.372364</td>\n",
       "      <td>0.549802</td>\n",
       "      <td>0.731238</td>\n",
       "      <td>0.232842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.192847</td>\n",
       "      <td>0.396727</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>0.728352</td>\n",
       "      <td>0.221616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.192847</td>\n",
       "      <td>0.396727</td>\n",
       "      <td>0.571953</td>\n",
       "      <td>0.728352</td>\n",
       "      <td>0.221616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.192796</td>\n",
       "      <td>0.387969</td>\n",
       "      <td>0.572272</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>0.206543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.199746</td>\n",
       "      <td>0.416136</td>\n",
       "      <td>0.588620</td>\n",
       "      <td>0.726106</td>\n",
       "      <td>0.242463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.196555</td>\n",
       "      <td>0.402264</td>\n",
       "      <td>0.580551</td>\n",
       "      <td>0.726106</td>\n",
       "      <td>0.242463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.195908</td>\n",
       "      <td>0.399463</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.726106</td>\n",
       "      <td>0.242463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.193756</td>\n",
       "      <td>0.387356</td>\n",
       "      <td>0.574105</td>\n",
       "      <td>0.724182</td>\n",
       "      <td>0.203335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.189050</td>\n",
       "      <td>0.379458</td>\n",
       "      <td>0.562208</td>\n",
       "      <td>0.720654</td>\n",
       "      <td>0.192110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.199147</td>\n",
       "      <td>0.393335</td>\n",
       "      <td>0.586756</td>\n",
       "      <td>0.707826</td>\n",
       "      <td>0.157473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.204465</td>\n",
       "      <td>0.409420</td>\n",
       "      <td>0.598401</td>\n",
       "      <td>0.703656</td>\n",
       "      <td>0.160359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226936</td>\n",
       "      <td>0.450830</td>\n",
       "      <td>0.645827</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226869</td>\n",
       "      <td>0.450624</td>\n",
       "      <td>0.645689</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226388</td>\n",
       "      <td>0.449133</td>\n",
       "      <td>0.644706</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226869</td>\n",
       "      <td>0.450624</td>\n",
       "      <td>0.645689</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226734</td>\n",
       "      <td>0.450093</td>\n",
       "      <td>0.645419</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226864</td>\n",
       "      <td>0.450809</td>\n",
       "      <td>0.645677</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226740</td>\n",
       "      <td>0.450351</td>\n",
       "      <td>0.645434</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226936</td>\n",
       "      <td>0.450830</td>\n",
       "      <td>0.645827</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.362346</td>\n",
       "      <td>0.362411</td>\n",
       "      <td>6.400379</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.297857</td>\n",
       "      <td>0.377563</td>\n",
       "      <td>0.994155</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.226867</td>\n",
       "      <td>0.450694</td>\n",
       "      <td>0.645684</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.362411</td>\n",
       "      <td>0.362412</td>\n",
       "      <td>8.579613</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy   pred_ll\n",
       "99       heurstic     --  0.183912  0.372364  0.549802  0.731238  0.232842\n",
       "17        quasihb  power  0.192847  0.396727  0.571953  0.728352  0.221616\n",
       "19     quasihb_fc  power  0.192847  0.396727  0.571953  0.728352  0.221616\n",
       "13           hbmd  power  0.192796  0.387969  0.572272  0.726748  0.206543\n",
       "11            hb2  power  0.199746  0.416136  0.588620  0.726106  0.242463\n",
       "15            hce  power  0.196555  0.402264  0.580551  0.726106  0.242463\n",
       "9              hb  power  0.195908  0.399463  0.579710  0.726106  0.242463\n",
       "3   attention_uni  power  0.193756  0.387356  0.574105  0.724182  0.203335\n",
       "21          trade  power  0.189050  0.379458  0.562208  0.720654  0.192110\n",
       "5            expo  power  0.199147  0.393335  0.586756  0.707826  0.157473\n",
       "1       attention  power  0.204465  0.409420  0.598401  0.703656  0.160359\n",
       "4            expo   cara  0.226936  0.450830  0.645827  0.637588  0.000000\n",
       "0       attention   cara  0.226869  0.450624  0.645689  0.637588  0.000000\n",
       "20          trade   cara  0.226388  0.449133  0.644706  0.637588  0.000000\n",
       "2   attention_uni   cara  0.226869  0.450624  0.645689  0.637588  0.000000\n",
       "18     quasihb_fc   cara  0.226734  0.450093  0.645419  0.637588  0.000000\n",
       "12           hbmd   cara  0.226864  0.450809  0.645677  0.637588  0.000000\n",
       "16        quasihb   cara  0.226740  0.450351  0.645434  0.637588  0.000000\n",
       "14            hce   cara  0.226936  0.450830  0.645827  0.637588  0.000000\n",
       "6           expo2   cara  0.362346  0.362411  6.400379  0.637588  0.000000\n",
       "10            hb2   cara  0.297857  0.377563  0.994155  0.637588  0.000000\n",
       "8              hb   cara  0.226867  0.450694  0.645684  0.637588  0.000000\n",
       "7           expo2  power  0.362411  0.362412  8.579613  0.637588  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Out-of-sample performance\n",
    "test_sample = data_prepare.test_sample\n",
    "test_result = cross_valid.get_result_tab(kf_result_df,test_sample)\n",
    "\n",
    "with open('my_model_followup.pkl', 'rb') as f:\n",
    "    heuristic_model = pickle.load(f)\n",
    "\n",
    "heuristic_test_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,X_test=X_test,y_test=y_test)\n",
    "\n",
    "test_result = pd.concat([test_result,pd.DataFrame(heuristic_test_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.120041</td>\n",
       "      <td>0.327930</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.110355</td>\n",
       "      <td>0.307411</td>\n",
       "      <td>0.385840</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.112203</td>\n",
       "      <td>0.313654</td>\n",
       "      <td>0.392895</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.127589</td>\n",
       "      <td>0.335988</td>\n",
       "      <td>0.428471</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.127589</td>\n",
       "      <td>0.335988</td>\n",
       "      <td>0.428471</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.121370</td>\n",
       "      <td>0.324216</td>\n",
       "      <td>0.411763</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.339685</td>\n",
       "      <td>0.441643</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.131047</td>\n",
       "      <td>0.341909</td>\n",
       "      <td>0.436958</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.152766</td>\n",
       "      <td>0.369628</td>\n",
       "      <td>0.485782</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.160337</td>\n",
       "      <td>0.378738</td>\n",
       "      <td>0.497720</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185836</td>\n",
       "      <td>0.411853</td>\n",
       "      <td>0.559520</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186433</td>\n",
       "      <td>0.412519</td>\n",
       "      <td>0.560786</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185982</td>\n",
       "      <td>0.412172</td>\n",
       "      <td>0.559855</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187931</td>\n",
       "      <td>0.414575</td>\n",
       "      <td>0.564117</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.188125</td>\n",
       "      <td>0.414789</td>\n",
       "      <td>0.564519</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.189661</td>\n",
       "      <td>0.416781</td>\n",
       "      <td>0.567655</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.235095</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>3.369777</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187611</td>\n",
       "      <td>0.413729</td>\n",
       "      <td>0.563289</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.189642</td>\n",
       "      <td>0.416822</td>\n",
       "      <td>0.567622</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.202285</td>\n",
       "      <td>0.285044</td>\n",
       "      <td>0.659362</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.190847</td>\n",
       "      <td>0.415194</td>\n",
       "      <td>0.569364</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.276997</td>\n",
       "      <td>0.276999</td>\n",
       "      <td>5.535498</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "13           hbmd  power  0.120041  0.327930  0.411733     0.941    0.234\n",
       "3   attention_uni  power  0.110355  0.307411  0.385840     0.935    0.248\n",
       "21          trade  power  0.112203  0.313654  0.392895     0.909    0.196\n",
       "19     quasihb_fc  power  0.127589  0.335988  0.428471     0.905    0.338\n",
       "17        quasihb  power  0.127589  0.335988  0.428471     0.905    0.338\n",
       "5            expo  power  0.121370  0.324216  0.411763     0.899    0.242\n",
       "9              hb  power  0.134200  0.339685  0.441643     0.891    0.366\n",
       "15            hce  power  0.131047  0.341909  0.436958     0.891    0.366\n",
       "11            hb2  power  0.152766  0.369628  0.485782     0.891    0.366\n",
       "1       attention  power  0.160337  0.378738  0.497720     0.838    0.135\n",
       "2   attention_uni   cara  0.185836  0.411853  0.559520     0.767    0.096\n",
       "12           hbmd   cara  0.186433  0.412519  0.560786     0.766    0.097\n",
       "0       attention   cara  0.185982  0.412172  0.559855     0.765    0.102\n",
       "18     quasihb_fc   cara  0.187931  0.414575  0.564117     0.764    0.101\n",
       "16        quasihb   cara  0.188125  0.414789  0.564519     0.763    0.108\n",
       "14            hce   cara  0.189661  0.416781  0.567655     0.760    0.087\n",
       "6           expo2   cara  0.235095  0.244869  3.369777     0.760    0.043\n",
       "8              hb   cara  0.187611  0.413729  0.563289     0.757    0.094\n",
       "4            expo   cara  0.189642  0.416822  0.567622     0.752    0.067\n",
       "10            hb2   cara  0.202285  0.285044  0.659362     0.742    0.043\n",
       "20          trade   cara  0.190847  0.415194  0.569364     0.730    0.007\n",
       "7           expo2  power  0.276997  0.276999  5.535498     0.723    0.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly draw 1000 questions from the dataset \n",
    "# Use the prediction value by XGBoost as the label\n",
    "# Examine which model can explain the XGBoost's prediction the best\n",
    "rda_sample = itch_dt[itch_dt.index.isin(np.random.choice(itch_dt.index,size=1000,replace=False))][['ss_x','ss_t','ll_x','ll_t']]\n",
    "rda_prepare = cross_valid.data_prepare(data=rda_sample)\n",
    "rda_prepare.generate_features()\n",
    "rda_sample = rda_prepare._data[features]\n",
    "rda_sample[label] = heuristic_model.predict(rda_sample[features])\n",
    "\n",
    "rda_result = cross_valid.get_result_tab(kf_result_df,rda_sample)\n",
    "rda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.119458</td>\n",
       "      <td>0.327347</td>\n",
       "      <td>0.410545</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.112254</td>\n",
       "      <td>0.309309</td>\n",
       "      <td>0.389609</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.111276</td>\n",
       "      <td>0.308639</td>\n",
       "      <td>0.388806</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.157249</td>\n",
       "      <td>0.375650</td>\n",
       "      <td>0.491466</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.129902</td>\n",
       "      <td>0.332749</td>\n",
       "      <td>0.429847</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.148456</td>\n",
       "      <td>0.356855</td>\n",
       "      <td>0.473410</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.148456</td>\n",
       "      <td>0.356855</td>\n",
       "      <td>0.473410</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.159738</td>\n",
       "      <td>0.365224</td>\n",
       "      <td>0.498280</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.147526</td>\n",
       "      <td>0.358389</td>\n",
       "      <td>0.472122</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.177643</td>\n",
       "      <td>0.394505</td>\n",
       "      <td>0.539656</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.179782</td>\n",
       "      <td>0.189557</td>\n",
       "      <td>2.740821</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.173941</td>\n",
       "      <td>0.398287</td>\n",
       "      <td>0.534684</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.195997</td>\n",
       "      <td>0.195999</td>\n",
       "      <td>3.990340</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.174471</td>\n",
       "      <td>0.257229</td>\n",
       "      <td>0.653724</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.181215</td>\n",
       "      <td>0.408396</td>\n",
       "      <td>0.550351</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.182250</td>\n",
       "      <td>0.409370</td>\n",
       "      <td>0.552425</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.409518</td>\n",
       "      <td>0.554755</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.183969</td>\n",
       "      <td>0.410055</td>\n",
       "      <td>0.555748</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.411049</td>\n",
       "      <td>0.557805</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.184493</td>\n",
       "      <td>0.410683</td>\n",
       "      <td>0.556853</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.184966</td>\n",
       "      <td>0.411610</td>\n",
       "      <td>0.557922</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186753</td>\n",
       "      <td>0.413418</td>\n",
       "      <td>0.561646</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "13           hbmd  power  0.119458  0.327347  0.410545     0.942    0.234\n",
       "3   attention_uni  power  0.112254  0.309309  0.389609     0.924    0.248\n",
       "99       heurstic     --  0.111276  0.308639  0.388806     0.909    0.277\n",
       "1       attention  power  0.157249  0.375650  0.491466     0.905    0.135\n",
       "5            expo  power  0.129902  0.332749  0.429847     0.886    0.242\n",
       "19     quasihb_fc  power  0.148456  0.356855  0.473410     0.850    0.338\n",
       "17        quasihb  power  0.148456  0.356855  0.473410     0.850    0.338\n",
       "9              hb  power  0.159738  0.365224  0.498280     0.822    0.366\n",
       "15            hce  power  0.147526  0.358389  0.472122     0.822    0.366\n",
       "11            hb2  power  0.177643  0.394505  0.539656     0.822    0.366\n",
       "6           expo2   cara  0.179782  0.189557  2.740821     0.813    0.043\n",
       "20          trade   cara  0.173941  0.398287  0.534684     0.811    0.007\n",
       "7           expo2  power  0.195997  0.195999  3.990340     0.804    0.000\n",
       "10            hb2   cara  0.174471  0.257229  0.653724     0.791    0.043\n",
       "4            expo   cara  0.181215  0.408396  0.550351     0.789    0.067\n",
       "14            hce   cara  0.182250  0.409370  0.552425     0.779    0.087\n",
       "2   attention_uni   cara  0.183500  0.409518  0.554755     0.774    0.096\n",
       "12           hbmd   cara  0.183969  0.410055  0.555748     0.773    0.097\n",
       "8              hb   cara  0.184932  0.411049  0.557805     0.772    0.094\n",
       "0       attention   cara  0.184493  0.410683  0.556853     0.772    0.102\n",
       "18     quasihb_fc   cara  0.184966  0.411610  0.557922     0.771    0.101\n",
       "16        quasihb   cara  0.186753  0.413418  0.561646     0.770    0.108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the prediction value by magnitude-dependent hyperbolic (hbmd) with power utillity as the label\n",
    "# Examine which model can explain the hbmd's prediction the best\n",
    "target_kf_row = kf_result_df[(kf_result_df['dstyle']=='trade') & (kf_result_df['ustyle']=='power')]\n",
    "target_style = target_kf_row['style'].values[0]\n",
    "target_params = target_kf_row['params'].values[0]\n",
    "\n",
    "choice_prob = cross_valid.test_model(style=target_style,params=target_params,test_sample=rda_sample,output='predict_proba')\n",
    "rda_sample[label] = (choice_prob >.5)\n",
    "\n",
    "rda_result_2 = cross_valid.get_result_tab(kf_result_df,rda_sample).iloc[1:,:]\n",
    "heuristic_rda_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,test_sample=rda_sample)\n",
    "rda_result_2 = pd.concat([rda_result_2,pd.DataFrame(heuristic_rda_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "rda_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "kf_result.to_csv(\"itch_followup_kf.csv\",index=False)\n",
    "test_result.to_csv(\"itch_followup_test.csv\",index=False)\n",
    "rda_result.to_csv(\"itch_followup_rda.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

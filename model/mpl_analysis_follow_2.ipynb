{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "from mel import cross_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "itch_dt = pd.read_csv('data/ericson_data.csv')\n",
    "itch_dt = itch_dt.rename(columns={\"Subject\":\"person_id\",\n",
    "                                \"Condition\":\"condition\",\n",
    "                                \"Question\":\"question_id\",\n",
    "                                \"X1\":\"ss_x\",\n",
    "                                \"T1\":\"ss_t\",\n",
    "                                \"X2\":\"ll_x\",\n",
    "                                \"T2\":\"ll_t\",\n",
    "                                \"LaterOptionChosen\": \"choice\"}).\\\n",
    "                drop(['R','G','D'],axis=1)\n",
    "\n",
    "\n",
    "# Define features, label, and group variable\n",
    "features = ['ss_x', 'ss_t', 'll_x', 'll_t',\n",
    "            'abs_diff_x', 'abs_diff_t', 'rel_diff_x','rel_diff_t',\n",
    "            'growth_x']\n",
    "label = 'choice'\n",
    "group = 'person_id'\n",
    "\n",
    "# Omit the choice questions of which ss_x <= 5\n",
    "# After omission, 9 persons that answers less than 10 questions (maximum is 23 questions)\n",
    "# Removew these persons from the dataset\n",
    "# Retain 65.7% of the obs.\n",
    "dataset = itch_dt[itch_dt['ss_x'] > 5]\n",
    "count_indvd_choice = dataset.groupby('person_id').choice.count()\n",
    "person_id_omit = list(count_indvd_choice[count_indvd_choice <= 10].index)\n",
    "dataset = dataset[~dataset['person_id'].isin(person_id_omit)]\n",
    "\n",
    "data_prepare = cross_valid.data_prepare(data=dataset,feature=features,label=label,group=group)\n",
    "data_prepare.generate_features()\n",
    "dataset = data_prepare._data\n",
    "\n",
    "# Split the data into train sample and test sample\n",
    "# Train sample containts 80% of the participants, test sample contains the rest \n",
    "X_train,X_test,y_train,y_test = data_prepare.split_sample(test_size=0.2)\n",
    "groups = data_prepare.train_sample[group]\n",
    "\n",
    "# Split the train sample into K folds (K=10) for cross-validation\n",
    "sgkf = model_selection.StratifiedGroupKFold(n_splits=10,shuffle=True,random_state=2023)\n",
    "cv = list(sgkf.split(X=X_train,y=y_train,groups=groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6574893617021277"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)/len(itch_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([   14,    15,    16, ..., 12242, 12243, 12244])),\n",
       "                 (array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([   88,    89,    90, ..., 12227, 12228, 12229])),\n",
       "                 (array([   14,    15,    16, ..., 12328, 12329, 12330]),\n",
       "                  array([    0,     1,     2, ..., 11933, 11934, 11935])),\n",
       "                 (array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([  103,   104,   105, ..., 12154, 12155, 12156])),\n",
       "                 (array([    0,     1,     2,...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.6],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [35], &#x27;reg_lambda&#x27;: [0.6],\n",
       "                         &#x27;subsample&#x27;: [0.7]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([   14,    15,    16, ..., 12242, 12243, 12244])),\n",
       "                 (array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([   88,    89,    90, ..., 12227, 12228, 12229])),\n",
       "                 (array([   14,    15,    16, ..., 12328, 12329, 12330]),\n",
       "                  array([    0,     1,     2, ..., 11933, 11934, 11935])),\n",
       "                 (array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([  103,   104,   105, ..., 12154, 12155, 12156])),\n",
       "                 (array([    0,     1,     2,...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.6],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [35], &#x27;reg_lambda&#x27;: [0.6],\n",
       "                         &#x27;subsample&#x27;: [0.7]},\n",
       "             refit=&#x27;neg_log_loss&#x27;,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;, &#x27;neg_mean_absolute_error&#x27;,\n",
       "                      &#x27;neg_mean_squared_error&#x27;],\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=[(array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([   14,    15,    16, ..., 12242, 12243, 12244])),\n",
       "                 (array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([   88,    89,    90, ..., 12227, 12228, 12229])),\n",
       "                 (array([   14,    15,    16, ..., 12328, 12329, 12330]),\n",
       "                  array([    0,     1,     2, ..., 11933, 11934, 11935])),\n",
       "                 (array([    0,     1,     2, ..., 12328, 12329, 12330]),\n",
       "                  array([  103,   104,   105, ..., 12154, 12155, 12156])),\n",
       "                 (array([    0,     1,     2,...\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [1.0], 'gamma': [0.6],\n",
       "                         'learning_rate': [0.1], 'max_depth': [3],\n",
       "                         'n_estimators': [35], 'reg_lambda': [0.6],\n",
       "                         'subsample': [0.7]},\n",
       "             refit='neg_log_loss',\n",
       "             scoring=['accuracy', 'neg_log_loss', 'neg_mean_absolute_error',\n",
       "                      'neg_mean_squared_error'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost to fit the data\n",
    "# Tune the hyer-parameters by grid search \n",
    "# The following dictionary directly shows the tuning results \n",
    "param_grid = {'n_estimators': [35],\n",
    "              'max_depth': [3],\n",
    "              'learning_rate': [.1],\n",
    "              'gamma': [.6],\n",
    "              'reg_lambda': [.6],\n",
    "              'subsample': [.7],\n",
    "              'colsample_bytree': [1.0]\n",
    "            }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(model, param_grid, \n",
    "                                           cv=cv, \n",
    "                                           scoring=[\"accuracy\",\"neg_log_loss\",'neg_mean_absolute_error','neg_mean_squared_error'], \n",
    "                                           refit=\"neg_log_loss\",\n",
    "                                           n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search.fit(X=X_train,y=y_train,groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the XGBoost model and check the feature importance\n",
    "bst_model = grid_search.best_estimator_\n",
    "\n",
    "with open('my_model_follow_2.pkl', 'wb') as f:\n",
    "    pickle.dump(bst_model, f)\n",
    "\n",
    "\n",
    "heuristic_kf_dict = {'dstyle': 'heuristic',\n",
    "            'ustyle': '--',\n",
    "            'params': None,\n",
    "            'accuracy': grid_search.cv_results_['mean_test_accuracy'][0],\n",
    "            'log_loss': -grid_search.cv_results_['mean_test_neg_log_loss'][0],\n",
    "            'mse':-grid_search.cv_results_['mean_test_neg_mean_squared_error'][0],\n",
    "            'mae':-grid_search.cv_results_['mean_test_neg_mean_absolute_error'][0]\n",
    "            }\n",
    "\n",
    "xgb.plot_importance(bst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a decision tree\n",
    "# To check structure of different trees, change num_trees \n",
    "#xgb.to_graphviz(bst_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [28:02<00:00,  7.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# Fit data by distounted utility model and trade-off model\n",
    "style_list = cross_valid.estimation.gen_style_list()\n",
    "train_sample = data_prepare.train_sample\n",
    "\n",
    "kf = cross_valid.KFvalidation(style=style_list,data=train_sample,cv=cv,n_jobs=4)\n",
    "kf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if some of the fits fail to converge \n",
    "np.where(kf.success==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>params</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heuristic</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>0.274946</td>\n",
       "      <td>0.274946</td>\n",
       "      <td>0.561789</td>\n",
       "      <td>0.725054</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.632, 1.274, 17.074, 0.85, 0.106, 0.1]</td>\n",
       "      <td>0.194450</td>\n",
       "      <td>0.388525</td>\n",
       "      <td>0.575550</td>\n",
       "      <td>0.715991</td>\n",
       "      <td>0.210756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>[9.485, 0.127, 0.144]</td>\n",
       "      <td>0.197199</td>\n",
       "      <td>0.395245</td>\n",
       "      <td>0.582793</td>\n",
       "      <td>0.721651</td>\n",
       "      <td>0.219777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.998, 0.998, 0.008, 0.005]</td>\n",
       "      <td>0.197443</td>\n",
       "      <td>0.394667</td>\n",
       "      <td>0.582813</td>\n",
       "      <td>0.717033</td>\n",
       "      <td>0.227863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.998, 0.997, 1.066, 0.009, 0.005]</td>\n",
       "      <td>0.197470</td>\n",
       "      <td>0.394102</td>\n",
       "      <td>0.582907</td>\n",
       "      <td>0.717033</td>\n",
       "      <td>0.227863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.802, 0.838, 0.451, 0.012, 0.008]</td>\n",
       "      <td>0.197826</td>\n",
       "      <td>0.395610</td>\n",
       "      <td>0.583598</td>\n",
       "      <td>0.713896</td>\n",
       "      <td>0.232013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.221, 0.018, 0.012]</td>\n",
       "      <td>0.197736</td>\n",
       "      <td>0.396185</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.720242</td>\n",
       "      <td>0.221804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.129, 2.271, 0.015, 0.01]</td>\n",
       "      <td>0.198813</td>\n",
       "      <td>0.398776</td>\n",
       "      <td>0.585876</td>\n",
       "      <td>0.714245</td>\n",
       "      <td>0.238172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 2.067, 0.005, 0.005]</td>\n",
       "      <td>0.199363</td>\n",
       "      <td>0.399334</td>\n",
       "      <td>0.587255</td>\n",
       "      <td>0.716431</td>\n",
       "      <td>0.244497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.002, 0.006, 0.004]</td>\n",
       "      <td>0.199359</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>0.587294</td>\n",
       "      <td>0.714816</td>\n",
       "      <td>0.251120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.009, 0.005]</td>\n",
       "      <td>0.199438</td>\n",
       "      <td>0.399357</td>\n",
       "      <td>0.587483</td>\n",
       "      <td>0.716400</td>\n",
       "      <td>0.245258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 5.982, 0.322, 1.275]</td>\n",
       "      <td>0.207144</td>\n",
       "      <td>0.416850</td>\n",
       "      <td>0.604885</td>\n",
       "      <td>0.696075</td>\n",
       "      <td>0.194369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.988, 0.579, 2.334, 0.331]</td>\n",
       "      <td>0.226570</td>\n",
       "      <td>0.453056</td>\n",
       "      <td>0.645177</td>\n",
       "      <td>0.642029</td>\n",
       "      <td>0.011159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.578, 2.578, 93.576, 59.948, 2.533, 2.271]</td>\n",
       "      <td>0.226860</td>\n",
       "      <td>0.453562</td>\n",
       "      <td>0.645789</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.402, 0.73, 0.313, 2.306, 0.06]</td>\n",
       "      <td>0.226999</td>\n",
       "      <td>0.453842</td>\n",
       "      <td>0.646077</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.943, 0.923, 1.082, 2.53, 0.242]</td>\n",
       "      <td>0.227012</td>\n",
       "      <td>0.453862</td>\n",
       "      <td>0.646108</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.943, 0.923, 2.614, 0.242]</td>\n",
       "      <td>0.227012</td>\n",
       "      <td>0.453863</td>\n",
       "      <td>0.646108</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.514, 0.349, 13.729, 0.051]</td>\n",
       "      <td>0.227058</td>\n",
       "      <td>0.454021</td>\n",
       "      <td>0.646196</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.19, 3.902, 0.345]</td>\n",
       "      <td>0.227097</td>\n",
       "      <td>0.454079</td>\n",
       "      <td>0.646280</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>[5.292, 3.513, 0.345]</td>\n",
       "      <td>0.227097</td>\n",
       "      <td>0.454079</td>\n",
       "      <td>0.646280</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.602, 4.024, 0.345]</td>\n",
       "      <td>0.227097</td>\n",
       "      <td>0.454079</td>\n",
       "      <td>0.646280</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.764, 3.243, 0.529]</td>\n",
       "      <td>0.227141</td>\n",
       "      <td>0.454164</td>\n",
       "      <td>0.646373</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.764, 2.771, 3.607, 0.529]</td>\n",
       "      <td>0.227141</td>\n",
       "      <td>0.454164</td>\n",
       "      <td>0.646373</td>\n",
       "      <td>0.639566</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle                                        params   \n",
       "99      heuristic     --                                          None  \\\n",
       "21          trade  power      [0.632, 1.274, 17.074, 0.85, 0.106, 0.1]   \n",
       "13           hbmd  power                         [9.485, 0.127, 0.144]   \n",
       "17        quasihb  power                  [0.998, 0.998, 0.008, 0.005]   \n",
       "19     quasihb_fc  power           [0.998, 0.997, 1.066, 0.009, 0.005]   \n",
       "7           expo2  power           [0.802, 0.838, 0.451, 0.012, 0.008]   \n",
       "3   attention_uni  power                         [0.221, 0.018, 0.012]   \n",
       "11            hb2  power                   [0.129, 2.271, 0.015, 0.01]   \n",
       "15            hce  power                  [0.997, 2.067, 0.005, 0.005]   \n",
       "9              hb  power                         [0.002, 0.006, 0.004]   \n",
       "5            expo  power                         [0.997, 0.009, 0.005]   \n",
       "1       attention  power                  [0.997, 5.982, 0.322, 1.275]   \n",
       "0       attention   cara                  [0.988, 0.579, 2.334, 0.331]   \n",
       "20          trade   cara  [0.578, 2.578, 93.576, 59.948, 2.533, 2.271]   \n",
       "6           expo2   cara             [0.402, 0.73, 0.313, 2.306, 0.06]   \n",
       "18     quasihb_fc   cara            [0.943, 0.923, 1.082, 2.53, 0.242]   \n",
       "16        quasihb   cara                  [0.943, 0.923, 2.614, 0.242]   \n",
       "10            hb2   cara                 [0.514, 0.349, 13.729, 0.051]   \n",
       "8              hb   cara                          [0.19, 3.902, 0.345]   \n",
       "12           hbmd   cara                         [5.292, 3.513, 0.345]   \n",
       "2   attention_uni   cara                         [0.602, 4.024, 0.345]   \n",
       "4            expo   cara                         [0.764, 3.243, 0.529]   \n",
       "14            hce   cara                  [0.764, 2.771, 3.607, 0.529]   \n",
       "\n",
       "         mse       mae  log_loss  accuracy   pred_ll  \n",
       "99  0.274946  0.274946  0.561789  0.725054       NaN  \n",
       "21  0.194450  0.388525  0.575550  0.715991  0.210756  \n",
       "13  0.197199  0.395245  0.582793  0.721651  0.219777  \n",
       "17  0.197443  0.394667  0.582813  0.717033  0.227863  \n",
       "19  0.197470  0.394102  0.582907  0.717033  0.227863  \n",
       "7   0.197826  0.395610  0.583598  0.713896  0.232013  \n",
       "3   0.197736  0.396185  0.583675  0.720242  0.221804  \n",
       "11  0.198813  0.398776  0.585876  0.714245  0.238172  \n",
       "15  0.199363  0.399334  0.587255  0.716431  0.244497  \n",
       "9   0.199359  0.398990  0.587294  0.714816  0.251120  \n",
       "5   0.199438  0.399357  0.587483  0.716400  0.245258  \n",
       "1   0.207144  0.416850  0.604885  0.696075  0.194369  \n",
       "0   0.226570  0.453056  0.645177  0.642029  0.011159  \n",
       "20  0.226860  0.453562  0.645789  0.639566  0.000000  \n",
       "6   0.226999  0.453842  0.646077  0.639566  0.000000  \n",
       "18  0.227012  0.453862  0.646108  0.639566  0.000000  \n",
       "16  0.227012  0.453863  0.646108  0.639566  0.000000  \n",
       "10  0.227058  0.454021  0.646196  0.639566  0.000000  \n",
       "8   0.227097  0.454079  0.646280  0.639566  0.000000  \n",
       "12  0.227097  0.454079  0.646280  0.639566  0.000000  \n",
       "2   0.227097  0.454079  0.646280  0.639566  0.000000  \n",
       "4   0.227141  0.454164  0.646373  0.639566  0.000000  \n",
       "14  0.227141  0.454164  0.646373  0.639566  0.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Cross-validation result\n",
    "kf_result_df = kf.summary()\n",
    "kf_result = kf_result_df.drop('style',axis=1)\n",
    "kf_result = pd.concat([kf_result,pd.DataFrame(heuristic_kf_dict,index=[99])]).sort_values('log_loss')\n",
    "kf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.176796</td>\n",
       "      <td>0.367969</td>\n",
       "      <td>0.534657</td>\n",
       "      <td>0.748718</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>0.384197</td>\n",
       "      <td>0.556465</td>\n",
       "      <td>0.748077</td>\n",
       "      <td>0.213462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.190544</td>\n",
       "      <td>0.400370</td>\n",
       "      <td>0.568042</td>\n",
       "      <td>0.747756</td>\n",
       "      <td>0.233654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.186772</td>\n",
       "      <td>0.380031</td>\n",
       "      <td>0.559683</td>\n",
       "      <td>0.746795</td>\n",
       "      <td>0.255769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.189295</td>\n",
       "      <td>0.397578</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.746795</td>\n",
       "      <td>0.255769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.184735</td>\n",
       "      <td>0.383520</td>\n",
       "      <td>0.555043</td>\n",
       "      <td>0.746474</td>\n",
       "      <td>0.216987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.182404</td>\n",
       "      <td>0.382389</td>\n",
       "      <td>0.549437</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.216346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.185075</td>\n",
       "      <td>0.371469</td>\n",
       "      <td>0.555654</td>\n",
       "      <td>0.744551</td>\n",
       "      <td>0.225321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.187368</td>\n",
       "      <td>0.383461</td>\n",
       "      <td>0.560497</td>\n",
       "      <td>0.744551</td>\n",
       "      <td>0.200962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.197302</td>\n",
       "      <td>0.406231</td>\n",
       "      <td>0.582334</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.178205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219193</td>\n",
       "      <td>0.446241</td>\n",
       "      <td>0.629964</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>8.476693</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219195</td>\n",
       "      <td>0.446252</td>\n",
       "      <td>0.629967</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219164</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.316170</td>\n",
       "      <td>0.334768</td>\n",
       "      <td>1.875326</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>9.230828</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219164</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.279942</td>\n",
       "      <td>0.350901</td>\n",
       "      <td>0.995010</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219211</td>\n",
       "      <td>0.446381</td>\n",
       "      <td>0.630003</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.218963</td>\n",
       "      <td>0.445005</td>\n",
       "      <td>0.629461</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219120</td>\n",
       "      <td>0.445259</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219148</td>\n",
       "      <td>0.446827</td>\n",
       "      <td>0.629813</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.219120</td>\n",
       "      <td>0.445259</td>\n",
       "      <td>0.629809</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy   pred_ll\n",
       "99       heurstic     --  0.176796  0.367969  0.534657  0.748718  0.250000\n",
       "3   attention_uni  power  0.185467  0.384197  0.556465  0.748077  0.213462\n",
       "17        quasihb  power  0.190544  0.400370  0.568042  0.747756  0.233654\n",
       "5            expo  power  0.186772  0.380031  0.559683  0.746795  0.255769\n",
       "9              hb  power  0.189295  0.397578  0.565045  0.746795  0.255769\n",
       "13           hbmd  power  0.184735  0.383520  0.555043  0.746474  0.216987\n",
       "21          trade  power  0.182404  0.382389  0.549437  0.745833  0.216346\n",
       "19     quasihb_fc  power  0.185075  0.371469  0.555654  0.744551  0.225321\n",
       "15            hce  power  0.187368  0.383461  0.560497  0.744551  0.200962\n",
       "1       attention  power  0.197302  0.406231  0.582334  0.730769  0.178205\n",
       "8              hb   cara  0.219193  0.446241  0.629964  0.669231  0.000000\n",
       "11            hb2  power  0.330769  0.330769  8.476693  0.669231  0.000000\n",
       "2   attention_uni   cara  0.219195  0.446252  0.629967  0.669231  0.000000\n",
       "4            expo   cara  0.219164  0.446209  0.629900  0.669231  0.000000\n",
       "6           expo2   cara  0.316170  0.334768  1.875326  0.669231  0.000000\n",
       "7           expo2  power  0.330769  0.330769  9.230828  0.669231  0.000000\n",
       "14            hce   cara  0.219164  0.446209  0.629900  0.669231  0.000000\n",
       "10            hb2   cara  0.279942  0.350901  0.995010  0.669231  0.000000\n",
       "12           hbmd   cara  0.219211  0.446381  0.630003  0.669231  0.000000\n",
       "0       attention   cara  0.218963  0.445005  0.629461  0.669231  0.000000\n",
       "18     quasihb_fc   cara  0.219120  0.445259  0.629809  0.669231  0.000000\n",
       "20          trade   cara  0.219148  0.446827  0.629813  0.669231  0.000000\n",
       "16        quasihb   cara  0.219120  0.445259  0.629809  0.669231  0.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Out-of-sample performance\n",
    "test_sample = data_prepare.test_sample\n",
    "test_result = cross_valid.get_result_tab(kf_result_df,test_sample)\n",
    "\n",
    "with open('my_model_follow_2.pkl', 'rb') as f:\n",
    "    heuristic_model = pickle.load(f)\n",
    "\n",
    "heuristic_test_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,X_test=X_test,y_test=y_test)\n",
    "\n",
    "test_result = pd.concat([test_result,pd.DataFrame(heuristic_test_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.103491</td>\n",
       "      <td>0.296747</td>\n",
       "      <td>0.369440</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.128997</td>\n",
       "      <td>0.341328</td>\n",
       "      <td>0.433729</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.120985</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.413773</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.128770</td>\n",
       "      <td>0.340777</td>\n",
       "      <td>0.433060</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.114959</td>\n",
       "      <td>0.313462</td>\n",
       "      <td>0.396802</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.113885</td>\n",
       "      <td>0.311436</td>\n",
       "      <td>0.393214</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.118282</td>\n",
       "      <td>0.320562</td>\n",
       "      <td>0.405107</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.118102</td>\n",
       "      <td>0.326195</td>\n",
       "      <td>0.409369</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.158633</td>\n",
       "      <td>0.380190</td>\n",
       "      <td>0.496204</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185441</td>\n",
       "      <td>0.414630</td>\n",
       "      <td>0.558921</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187325</td>\n",
       "      <td>0.417081</td>\n",
       "      <td>0.562896</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185834</td>\n",
       "      <td>0.413732</td>\n",
       "      <td>0.559545</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.187247</td>\n",
       "      <td>0.416815</td>\n",
       "      <td>0.562685</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.188424</td>\n",
       "      <td>0.417932</td>\n",
       "      <td>0.565078</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.185848</td>\n",
       "      <td>0.413772</td>\n",
       "      <td>0.559584</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.190528</td>\n",
       "      <td>0.420463</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.218905</td>\n",
       "      <td>0.257904</td>\n",
       "      <td>1.000895</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.190546</td>\n",
       "      <td>0.420447</td>\n",
       "      <td>0.569466</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.202181</td>\n",
       "      <td>0.277145</td>\n",
       "      <td>0.655189</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.192656</td>\n",
       "      <td>0.421513</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>6.895342</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.277999</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>6.033632</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "19     quasihb_fc  power  0.103491  0.296747  0.369440     0.942    0.304\n",
       "17        quasihb  power  0.128997  0.341328  0.433729     0.933    0.315\n",
       "13           hbmd  power  0.120985  0.328800  0.413773     0.916    0.206\n",
       "9              hb  power  0.128770  0.340777  0.433060     0.914    0.346\n",
       "5            expo  power  0.114959  0.313462  0.396802     0.914    0.346\n",
       "3   attention_uni  power  0.113885  0.311436  0.393214     0.911    0.217\n",
       "15            hce  power  0.118282  0.320562  0.405107     0.911    0.265\n",
       "21          trade  power  0.118102  0.326195  0.409369     0.898    0.202\n",
       "1       attention  power  0.158633  0.380190  0.496204     0.820    0.128\n",
       "0       attention   cara  0.185441  0.414630  0.558921     0.777    0.099\n",
       "12           hbmd   cara  0.187325  0.417081  0.562896     0.764    0.086\n",
       "16        quasihb   cara  0.185834  0.413732  0.559545     0.761    0.111\n",
       "2   attention_uni   cara  0.187247  0.416815  0.562685     0.761    0.079\n",
       "8              hb   cara  0.188424  0.417932  0.565078     0.759    0.077\n",
       "18     quasihb_fc   cara  0.185848  0.413772  0.559584     0.758    0.118\n",
       "14            hce   cara  0.190528  0.420463  0.569432     0.756    0.060\n",
       "6           expo2   cara  0.218905  0.257904  1.000895     0.748    0.032\n",
       "4            expo   cara  0.190546  0.420447  0.569466     0.747    0.043\n",
       "10            hb2   cara  0.202181  0.277145  0.655189     0.743    0.037\n",
       "20          trade   cara  0.192656  0.421513  0.573620     0.724    0.002\n",
       "7           expo2  power  0.278000  0.278000  6.895342     0.722    0.000\n",
       "11            hb2  power  0.277999  0.278000  6.033632     0.722    0.000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly draw 1000 questions from the dataset \n",
    "# Use the prediction value by XGBoost as the label\n",
    "# Examine which model can explain the XGBoost's prediction the best\n",
    "rda_sample = itch_dt[itch_dt.index.isin(np.random.choice(itch_dt.index,size=1000,replace=False))][['ss_x','ss_t','ll_x','ll_t']]\n",
    "rda_prepare = cross_valid.data_prepare(data=rda_sample)\n",
    "rda_prepare.generate_features()\n",
    "rda_sample = rda_prepare._data[features]\n",
    "rda_sample[label] = heuristic_model.predict(rda_sample[features])\n",
    "\n",
    "rda_result = cross_valid.get_result_tab(kf_result_df,rda_sample)\n",
    "rda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>0.327422</td>\n",
       "      <td>0.411002</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.111013</td>\n",
       "      <td>0.308564</td>\n",
       "      <td>0.387047</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>heurstic</td>\n",
       "      <td>--</td>\n",
       "      <td>0.112153</td>\n",
       "      <td>0.310668</td>\n",
       "      <td>0.391218</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.117233</td>\n",
       "      <td>0.310490</td>\n",
       "      <td>0.398531</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.159513</td>\n",
       "      <td>0.381070</td>\n",
       "      <td>0.498119</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>0.359584</td>\n",
       "      <td>0.472495</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.124629</td>\n",
       "      <td>0.326909</td>\n",
       "      <td>0.418469</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.128175</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.425121</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.140222</td>\n",
       "      <td>0.352229</td>\n",
       "      <td>0.457141</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.184218</td>\n",
       "      <td>0.413075</td>\n",
       "      <td>0.557075</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.201999</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>4.818545</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>5.370829</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186040</td>\n",
       "      <td>0.225039</td>\n",
       "      <td>0.974521</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.188494</td>\n",
       "      <td>0.418396</td>\n",
       "      <td>0.565994</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.186435</td>\n",
       "      <td>0.261398</td>\n",
       "      <td>0.676761</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.189274</td>\n",
       "      <td>0.419208</td>\n",
       "      <td>0.567558</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.189334</td>\n",
       "      <td>0.418523</td>\n",
       "      <td>0.567468</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.191041</td>\n",
       "      <td>0.420549</td>\n",
       "      <td>0.571084</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.189613</td>\n",
       "      <td>0.419181</td>\n",
       "      <td>0.568147</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.190456</td>\n",
       "      <td>0.420212</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.195927</td>\n",
       "      <td>0.423826</td>\n",
       "      <td>0.581147</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.196015</td>\n",
       "      <td>0.423939</td>\n",
       "      <td>0.581338</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "13           hbmd  power  0.119608  0.327422  0.411002     0.934    0.206\n",
       "3   attention_uni  power  0.111013  0.308564  0.387047     0.915    0.217\n",
       "99       heurstic     --  0.112153  0.310668  0.391218     0.898    0.278\n",
       "19     quasihb_fc  power  0.117233  0.310490  0.398531     0.880    0.304\n",
       "1       attention  power  0.159513  0.381070  0.498119     0.880    0.128\n",
       "17        quasihb  power  0.147253  0.359584  0.472495     0.873    0.315\n",
       "15            hce  power  0.124629  0.326909  0.418469     0.869    0.265\n",
       "5            expo  power  0.128175  0.326679  0.425121     0.850    0.346\n",
       "9              hb  power  0.140222  0.352229  0.457141     0.850    0.346\n",
       "20          trade   cara  0.184218  0.413075  0.557075     0.800    0.002\n",
       "11            hb2  power  0.201999  0.202000  4.818545     0.798    0.000\n",
       "7           expo2  power  0.202000  0.202000  5.370829     0.798    0.000\n",
       "6           expo2   cara  0.186040  0.225039  0.974521     0.796    0.032\n",
       "4            expo   cara  0.188494  0.418396  0.565994     0.785    0.043\n",
       "10            hb2   cara  0.186435  0.261398  0.676761     0.781    0.037\n",
       "14            hce   cara  0.189274  0.419208  0.567558     0.772    0.060\n",
       "0       attention   cara  0.189334  0.418523  0.567468     0.765    0.099\n",
       "8              hb   cara  0.191041  0.420549  0.571084     0.763    0.077\n",
       "2   attention_uni   cara  0.189613  0.419181  0.568147     0.763    0.079\n",
       "12           hbmd   cara  0.190456  0.420212  0.569892     0.762    0.086\n",
       "16        quasihb   cara  0.195927  0.423826  0.581147     0.751    0.111\n",
       "18     quasihb_fc   cara  0.196015  0.423939  0.581338     0.748    0.118"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the predicted choices by the tradeoff model (trade) with power utillity as label\n",
    "# Examine which model can explain the hbmd's prediction the best\n",
    "target_kf_row = kf_result_df[(kf_result_df['dstyle']=='trade') & (kf_result_df['ustyle']=='power')]\n",
    "target_style = target_kf_row['style'].values[0]\n",
    "target_params = target_kf_row['params'].values[0]\n",
    "\n",
    "choice_prob = cross_valid.test_model(style=target_style,params=target_params,test_sample=rda_sample,output='predict_proba')\n",
    "rda_sample[label] = (choice_prob >.5)\n",
    "\n",
    "rda_result_2 = cross_valid.get_result_tab(kf_result_df,rda_sample).iloc[1:,:]\n",
    "heuristic_rda_dict = cross_valid.test_model(style='heuristic',model=heuristic_model,test_sample=rda_sample)\n",
    "rda_result_2 = pd.concat([rda_result_2,pd.DataFrame(heuristic_rda_dict,index=[99])]).sort_values('accuracy',ascending=False)\n",
    "rda_result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "kf_result.to_csv(\"table/itch_follow_2_kf.csv\",index=False)\n",
    "test_result.to_csv(\"table/itch_follow_2_test.csv\",index=False)\n",
    "rda_result.to_csv(\"table/itch_follow_2__rda.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

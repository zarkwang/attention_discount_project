{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from mpl import cross_valid\n",
    "from mpl import estimation\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "itch_dt = pd.read_csv('data/ericson_data.csv')\n",
    "itch_dt = itch_dt.rename(columns={\"Subject\":\"person_id\",\n",
    "                        \"Condition\":\"condition\",\n",
    "                        \"Question\":\"question_id\",\n",
    "                        \"X1\":\"ss_x\",\n",
    "                        \"T1\":\"ss_t\",\n",
    "                        \"X2\":\"ll_x\",\n",
    "                        \"T2\":\"ll_t\",\n",
    "                        \"LaterOptionChosen\": \"choice\"}).drop(['R','G','D'],axis=1)\n",
    "\n",
    "\n",
    "dataset = cross_valid.generate_sample(itch_dt)\n",
    "\n",
    "\n",
    "features = ['ss_x', 'ss_t', 'll_x', 'll_t','abs_diff_x', 'abs_diff_t', \n",
    "                   'rel_diff_x','rel_diff_t','growth_x']\n",
    "label = ['choice']\n",
    "\n",
    "\n",
    "X = dataset[features]\n",
    "y = dataset[label]\n",
    "groups = dataset['person_id']\n",
    "\n",
    "train_index,test_index = list(model_selection.GroupShuffleSplit(n_splits=1,train_size=.8,random_state=2023).\n",
    "                              split(X,y,groups))[0]\n",
    "\n",
    "train_sample = dataset[dataset.index.isin(train_index)]\n",
    "test_sample = dataset[dataset.index.isin(test_index)]\n",
    "\n",
    "sgkf = model_selection.StratifiedGroupKFold(n_splits=5,shuffle=True,random_state=2023)\n",
    "\n",
    "cv = list(sgkf.split(X=train_sample[features],\n",
    "                y=train_sample[label],\n",
    "                groups=train_sample['person_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   25,    26,    27, ..., 18127, 18128, 18129])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   99,   100,   101, ..., 18151, 18152, 18153])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  167,   168,   169, ..., 18029, 18030, 18031])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  117,   118,   119, ..., 18176, 18177, 18178])),\n",
       "                 (array([   2...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;, scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   25,    26,    27, ..., 18127, 18128, 18129])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   99,   100,   101, ..., 18151, 18152, 18153])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  167,   168,   169, ..., 18029, 18030, 18031])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  117,   118,   119, ..., 18176, 18177, 18178])),\n",
       "                 (array([   2...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;, scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=[(array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   25,    26,    27, ..., 18127, 18128, 18129])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   99,   100,   101, ..., 18151, 18152, 18153])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  167,   168,   169, ..., 18029, 18030, 18031])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  117,   118,   119, ..., 18176, 18177, 18178])),\n",
       "                 (array([   2...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [1.0], 'gamma': [0.3],\n",
       "                         'learning_rate': [0.1], 'max_depth': [3],\n",
       "                         'n_estimators': [40], 'reg_lambda': [0.7],\n",
       "                         'subsample': [0.55]},\n",
       "             refit='neg_log_loss', scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [40],\n",
    "              'max_depth': [3],\n",
    "              'learning_rate': [.1],\n",
    "              'gamma': [.3],\n",
    "              'reg_lambda': [.7],\n",
    "              'subsample': [.55],\n",
    "              'colsample_bytree': [1.0]\n",
    "            }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(model, param_grid, cv=cv, \n",
    "                                           scoring=\"neg_log_loss\", refit=\"neg_log_loss\",\n",
    "                                           n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search.fit(X=train_sample[features], \n",
    "                y=train_sample[label], \n",
    "                groups=train_sample['person_id'])\n",
    "\n",
    "# model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "#                           max_depth=3,\n",
    "#                           learning_rate=.1,\n",
    "#                           gamma=.3,\n",
    "#                           reg_lambda=.7,\n",
    "#                           subsample=.6,\n",
    "#                           colsample_bytree=1.0,\n",
    "#                           eval_metric=['error','logloss'],\n",
    "#                           early_stopping_rounds=30)\n",
    "# eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "# bst = model.fit(X=X_train,\n",
    "#                 y=y_train,\n",
    "#                 eval_set=eval_set,\n",
    "#                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 1.0, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 40, 'reg_lambda': 0.7, 'subsample': 0.55}\n",
      "Best score: -0.5810776914186546\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "bst_model = grid_search.best_estimator_\n",
    "xgb.plot_importance(bst_model)\n",
    "with open('my_model.pkl', 'wb') as f:\n",
    "    pickle.dump(bst_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.1 (20230327.1645)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1411pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 1411.39 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-301 1407.39,-301 1407.39,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"650.99\" cy=\"-279\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"650.99\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.288811326</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"469.99\" cy=\"-192\" rx=\"101.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.99\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.0615856722</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M616.52,-261.81C587.55,-248.21 545.96,-228.67 514.48,-213.89\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"516.18,-210.35 505.64,-209.27 513.21,-216.69 516.18,-210.35\"/>\n",
       "<text text-anchor=\"middle\" x=\"606.49\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"863.99\" cy=\"-192\" rx=\"71.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"863.99\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ll_x&lt;48.3349991</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M690.56,-262.21C726.45,-247.89 779.4,-226.76 817.34,-211.62\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"818.14,-214.67 826.13,-207.71 815.55,-208.16 818.14,-214.67\"/>\n",
       "<text text-anchor=\"middle\" x=\"778.49\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"256.99\" cy=\"-105\" rx=\"68.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">abs_diff_x&lt;300</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M429.93,-175.01C393.98,-160.66 341.21,-139.61 303.42,-124.53\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"305.26,-121.09 294.68,-120.64 302.67,-127.6 305.26,-121.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"469.99\" cy=\"-105\" rx=\"64.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">abs_diff_x&lt;75</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M469.99,-173.8C469.99,-162.47 469.99,-147.36 469.99,-134.29\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"473.49,-134.47 469.99,-124.47 466.49,-134.47 473.49,-134.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"477.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"863.99\" cy=\"-105\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"863.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.693334818</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M863.99,-173.8C863.99,-162.47 863.99,-147.36 863.99,-134.29\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"867.49,-134.47 863.99,-124.47 860.49,-134.47 867.49,-134.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"898.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1154.99\" cy=\"-105\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1154.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.693167806</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M909.46,-177.72C959.17,-163.2 1039.07,-139.86 1094.15,-123.77\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1094.85,-126.92 1103.47,-120.76 1092.89,-120.2 1094.85,-126.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"1034.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"77.99\" cy=\"-18\" rx=\"77.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.120960131</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M224.99,-88.8C195.83,-74.96 152.54,-54.4 120.49,-39.18\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"122.46,-35.77 111.93,-34.64 119.46,-42.09 122.46,-35.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"256.99\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0813586041</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M256.99,-86.8C256.99,-75.47 256.99,-60.36 256.99,-47.29\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"260.49,-47.47 256.99,-37.47 253.49,-47.47 260.49,-47.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"435.99\" cy=\"-18\" rx=\"77.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"435.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.077405028</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M463.11,-86.8C458.46,-75.16 452.21,-59.55 446.89,-46.24\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"449.83,-45.16 442.86,-37.18 443.33,-47.76 449.83,-45.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"490.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"614.99\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0362361036</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;10 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M496.93,-88.21C519.73,-74.84 552.65,-55.55 577.94,-40.72\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"579.36,-43.36 586.22,-35.28 575.82,-37.32 579.36,-43.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"559.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"797.99\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"797.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0131770419</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M850.64,-86.8C841.24,-74.7 828.51,-58.3 817.92,-44.67\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"820.23,-42.93 811.33,-37.18 814.7,-47.22 820.23,-42.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"869.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"977.99\" cy=\"-18\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"977.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.0390020758</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M886.52,-87.21C903.88,-74.26 928.09,-56.21 947.23,-41.93\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"948.98,-44.25 954.91,-35.47 944.8,-38.64 948.98,-44.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"935.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1154.99\" cy=\"-18\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1154.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.0448279642</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1154.99,-86.8C1154.99,-75.47 1154.99,-60.36 1154.99,-47.29\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1158.49,-47.47 1154.99,-37.47 1151.49,-47.47 1158.49,-47.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"1189.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1327.99\" cy=\"-18\" rx=\"75.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1327.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.102014445</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1189.22,-87.74C1201.47,-81.87 1215.37,-75.18 1227.99,-69 1247.56,-59.42 1269.18,-48.63 1287.31,-39.53\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1288.62,-42.29 1295.98,-34.67 1285.47,-36.04 1288.62,-42.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"1265.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x27ef3f4de70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.to_graphviz(bst_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>search_strategy</th>\n",
       "      <th>choice</th>\n",
       "      <th>total_time_ms</th>\n",
       "      <th>looktime_index</th>\n",
       "      <th>mean_payne</th>\n",
       "      <th>payne_ind</th>\n",
       "      <th>ll_t</th>\n",
       "      <th>ss_t</th>\n",
       "      <th>ll_x</th>\n",
       "      <th>ss_x</th>\n",
       "      <th>question_id</th>\n",
       "      <th>ratio_x</th>\n",
       "      <th>abs_diff_x</th>\n",
       "      <th>abs_diff_t</th>\n",
       "      <th>rel_diff_x</th>\n",
       "      <th>rel_diff_t</th>\n",
       "      <th>growth_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128912</td>\n",
       "      <td>accel</td>\n",
       "      <td>Comparative</td>\n",
       "      <td>0</td>\n",
       "      <td>5646</td>\n",
       "      <td>-0.106924</td>\n",
       "      <td>-0.165693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>53.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.050847</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.024798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128912</td>\n",
       "      <td>accel</td>\n",
       "      <td>Comparative</td>\n",
       "      <td>0</td>\n",
       "      <td>5078</td>\n",
       "      <td>0.020807</td>\n",
       "      <td>-0.165693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128912</td>\n",
       "      <td>accel</td>\n",
       "      <td>Comparative</td>\n",
       "      <td>1</td>\n",
       "      <td>7813</td>\n",
       "      <td>0.051847</td>\n",
       "      <td>-0.165693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.7</td>\n",
       "      <td>43.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.349425</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.297456</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.149839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128912</td>\n",
       "      <td>accel</td>\n",
       "      <td>Comparative</td>\n",
       "      <td>0</td>\n",
       "      <td>5386</td>\n",
       "      <td>-0.064586</td>\n",
       "      <td>-0.165693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.101215</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.096339</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.024103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128912</td>\n",
       "      <td>accel</td>\n",
       "      <td>Comparative</td>\n",
       "      <td>0</td>\n",
       "      <td>6528</td>\n",
       "      <td>0.099613</td>\n",
       "      <td>-0.165693</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.1</td>\n",
       "      <td>57.7</td>\n",
       "      <td>5</td>\n",
       "      <td>1.249567</td>\n",
       "      <td>14.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.221880</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.055699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895</th>\n",
       "      <td>132143</td>\n",
       "      <td>delay</td>\n",
       "      <td>Integrative</td>\n",
       "      <td>0</td>\n",
       "      <td>2993</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>1.055501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>13</td>\n",
       "      <td>1.030030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>132143</td>\n",
       "      <td>delay</td>\n",
       "      <td>Integrative</td>\n",
       "      <td>0</td>\n",
       "      <td>6702</td>\n",
       "      <td>0.182088</td>\n",
       "      <td>1.055501</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>42.5</td>\n",
       "      <td>15</td>\n",
       "      <td>1.009412</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>132143</td>\n",
       "      <td>delay</td>\n",
       "      <td>Integrative</td>\n",
       "      <td>1</td>\n",
       "      <td>11494</td>\n",
       "      <td>0.094057</td>\n",
       "      <td>1.055501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>51.9</td>\n",
       "      <td>16</td>\n",
       "      <td>1.100193</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.095413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6898</th>\n",
       "      <td>132143</td>\n",
       "      <td>delay</td>\n",
       "      <td>Integrative</td>\n",
       "      <td>1</td>\n",
       "      <td>4732</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>1.055501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.9</td>\n",
       "      <td>56.2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.350534</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.298259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>132143</td>\n",
       "      <td>delay</td>\n",
       "      <td>Integrative</td>\n",
       "      <td>0</td>\n",
       "      <td>3472</td>\n",
       "      <td>0.100478</td>\n",
       "      <td>1.055501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>53.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.050847</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.024798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6845 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_id condition search_strategy  choice  total_time_ms  \\\n",
       "0        128912     accel     Comparative       0           5646   \n",
       "1        128912     accel     Comparative       0           5078   \n",
       "2        128912     accel     Comparative       1           7813   \n",
       "3        128912     accel     Comparative       0           5386   \n",
       "4        128912     accel     Comparative       0           6528   \n",
       "...         ...       ...             ...     ...            ...   \n",
       "6895     132143     delay     Integrative       0           2993   \n",
       "6896     132143     delay     Integrative       0           6702   \n",
       "6897     132143     delay     Integrative       1          11494   \n",
       "6898     132143     delay     Integrative       1           4732   \n",
       "6899     132143     delay     Integrative       0           3472   \n",
       "\n",
       "      looktime_index  mean_payne  payne_ind  ll_t  ss_t  ll_x  ss_x  \\\n",
       "0          -0.106924   -0.165693   1.000000   4.0   2.0  55.8  53.1   \n",
       "1           0.020807   -0.165693   1.000000   6.0   2.0  22.2  18.5   \n",
       "2           0.051847   -0.165693   1.000000   2.0   0.0  58.7  43.5   \n",
       "3          -0.064586   -0.165693   1.000000   4.0   0.0  27.2  24.7   \n",
       "4           0.099613   -0.165693   0.500000   4.0   0.0  72.1  57.7   \n",
       "...              ...         ...        ...   ...   ...   ...   ...   \n",
       "6895        0.082418    1.055501   1.000000   6.0   2.0  34.3  33.3   \n",
       "6896        0.182088    1.055501   0.714286   2.0   0.0  42.9  42.5   \n",
       "6897        0.094057    1.055501   1.000000   6.0   2.0  57.1  51.9   \n",
       "6898        0.066445    1.055501   1.000000   6.0   2.0  75.9  56.2   \n",
       "6899        0.100478    1.055501   1.000000   4.0   2.0  55.8  53.1   \n",
       "\n",
       "      question_id   ratio_x  abs_diff_x  abs_diff_t  rel_diff_x  rel_diff_t  \\\n",
       "0               1  1.050847         2.7         2.0    0.049587    0.666667   \n",
       "1               2  1.200000         3.7         4.0    0.181818    1.000000   \n",
       "2               3  1.349425        15.2         2.0    0.297456    2.000000   \n",
       "3               4  1.101215         2.5         4.0    0.096339    2.000000   \n",
       "4               5  1.249567        14.4         4.0    0.221880    2.000000   \n",
       "...           ...       ...         ...         ...         ...         ...   \n",
       "6895           13  1.030030         1.0         4.0    0.029586    1.000000   \n",
       "6896           15  1.009412         0.4         2.0    0.009368    2.000000   \n",
       "6897           16  1.100193         5.2         4.0    0.095413    1.000000   \n",
       "6898           10  1.350534        19.7         4.0    0.298259    1.000000   \n",
       "6899            1  1.050847         2.7         2.0    0.049587    0.666667   \n",
       "\n",
       "      growth_x  \n",
       "0     0.024798  \n",
       "1     0.045580  \n",
       "2     0.149839  \n",
       "3     0.024103  \n",
       "4     0.055699  \n",
       "...        ...  \n",
       "6895  0.007397  \n",
       "6896  0.004684  \n",
       "6897  0.023871  \n",
       "6898  0.075125  \n",
       "6899  0.024798  \n",
       "\n",
       "[6845 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_dt = pd.read_csv('data/reeck_data.csv')\n",
    "mouse_dt['choice'] = mouse_dt['choice'].replace({'ll':1,'ss':0})\n",
    "mouse_dt = mouse_dt.rename(columns={\"serial\":\"person_id\",\n",
    "                        \"itc_no\":\"question_id\",\n",
    "                        \"accel_delay\":\"condition\",\n",
    "                        \"Cluster\":\"search_strategy\",\n",
    "                        \"ss_amt_val\":\"ss_x\",\n",
    "                        \"ss_time\":\"ss_t\",\n",
    "                        \"ll_amt_val\":\"ll_x\",\n",
    "                        \"ll_time\":\"ll_t\"}).\\\n",
    "                    drop(['unique_itc','ss_delay_type'],axis=1)\n",
    "\n",
    "\n",
    "mouse_dt['ss_t'] = mouse_dt['ss_t'].str[0]\n",
    "mouse_dt['ll_t'] = mouse_dt['ll_t'].str[0]\n",
    "mouse_dt[['ss_x','ss_t','ll_x','ll_t']] = mouse_dt[['ss_x','ss_t','ll_x','ll_t']].astype(float)\n",
    "\n",
    "cross_valid.generate_sample(mouse_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.29965080750763856\n",
      "MAE:0.29965080750763856\n",
      "log_loss:10.349644658041443\n",
      "accuracy:0.7003491924923614\n",
      "pred_ll:0.26473155827149714\n"
     ]
    }
   ],
   "source": [
    "with open('my_model.pkl', 'rb') as f:\n",
    "    heuristic_model = pickle.load(f)\n",
    "\n",
    "preds = heuristic_model.predict(test_sample[features])\n",
    "trues = test_sample[label]\n",
    "\n",
    "pred_binary = (preds > .5)\n",
    "\n",
    "print(f\"MSE: {metrics.mean_squared_error(trues, preds)}\")\n",
    "print(f\"MAE:{metrics.mean_absolute_error(trues, preds)}\")\n",
    "print(f\"log_loss:{metrics.log_loss(trues, preds)}\")\n",
    "print(f\"accuracy:{metrics.accuracy_score(trues, pred_binary)}\")\n",
    "print(f\"pred_ll:{sum(pred_binary)/len(pred_binary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'dstyle':\"trade\",'ustyle':'power','method':\"logit\",'intercept':False}\n",
    "train_result = estimation.mle(style=style,data=train_sample,disp_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.356, 0.874, 0.005, 2.893, 0.43 , 4.257])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_result['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.2167653625171046,\n",
       " 'mae': 0.4319054882444174,\n",
       " 'log_loss': 0.6240517594595668,\n",
       " 'accuracy': 0.6628109995635094,\n",
       " 'pred_ll': 0.11938018332605849}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_valid.test_model(style=style,test_sample=test_sample,params=train_result[\"params\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_sample = itch_dt[itch_dt.index.isin(np.random.choice(itch_dt.index,size=1000,replace=False))][['ss_x','ss_t','ll_x','ll_t']]\n",
    "aux_sample = cross_valid.generate_sample(aux_sample)\n",
    "aux_sample['choice'] = heuristic_model.predict(aux_sample[features])\n",
    "cross_valid.test_model(style=style,test_sample=aux_sample,params=train_result[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [12:43<00:00,  6.94s/it]\n",
      "e:\\Attention_discounting\\attention_discount_project\\model\\mpl\\cross_valid.py:103: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.fails = (np.array(self.val_params) == estimation.config_param['msg']['fail_converge'])\n",
      "d:\\Python\\lib\\site-packages\\numpy\\core\\_methods.py:164: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asanyarray(a)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1423\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[0;32m   1424\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m     \u001b[39m# gh-20949\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m     \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m     \u001b[39m# on a string grouper column\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1464\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39mApply function f in python space\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[39m    data after applying f\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1464\u001b[0m values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[0;32m   1466\u001b[0m \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:761\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    760\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[1;32m--> 761\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n",
      "File \u001b[1;32me:\\Attention_discounting\\attention_discount_project\\model\\mpl\\cross_valid.py:201\u001b[0m, in \u001b[0;36mKFvalidation.summary.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    200\u001b[0m df_group \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m sum_tab \u001b[39m=\u001b[39m df_group\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39;49mmean(x\u001b[39m.\u001b[39;49mtolist(),axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m    202\u001b[0m sum_tab[score_list] \u001b[39m=\u001b[39m df_group[score_list]\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3430\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 3432\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3433\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\numpy\\core\\_methods.py:180\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    178\u001b[0m         is_float16_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m ret \u001b[39m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Attention_discounting\\attention_discount_project\\model\\heuristic.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m style_list \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mdstyle\u001b[39m\u001b[39m\"\u001b[39m:dstyle_list[i],\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mustyle\u001b[39m\u001b[39m\"\u001b[39m:ustyle_list[j],\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mlogit\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mintercept\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m} \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m               \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dstyle_list)) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ustyle_list))]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m kf \u001b[39m=\u001b[39m cross_valid\u001b[39m.\u001b[39mKFvalidation(style\u001b[39m=\u001b[39mstyle_list,data\u001b[39m=\u001b[39mtrain_sample,cv\u001b[39m=\u001b[39mcv,n_jobs\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Attention_discounting/attention_discount_project/model/heuristic.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m kf\u001b[39m.\u001b[39;49msummary()\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mkf_result_logit.csv\u001b[39m\u001b[39m\"\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Attention_discounting\\attention_discount_project\\model\\mpl\\cross_valid.py:201\u001b[0m, in \u001b[0;36mKFvalidation.summary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m df[score_list] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mscores\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:pd\u001b[39m.\u001b[39mSeries(x))\n\u001b[0;32m    200\u001b[0m df_group \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m sum_tab \u001b[39m=\u001b[39m df_group\u001b[39m.\u001b[39;49mparams\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: np\u001b[39m.\u001b[39;49mmean(x\u001b[39m.\u001b[39;49mtolist(),axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m    202\u001b[0m sum_tab[score_list] \u001b[39m=\u001b[39m df_group[score_list]\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m sum_tab\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:244\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[0;32m    239\u001b[0m     _apply_docs[\u001b[39m\"\u001b[39m\u001b[39mtemplate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    240\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, examples\u001b[39m=\u001b[39m_apply_docs[\u001b[39m\"\u001b[39m\u001b[39mseries_examples\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    241\u001b[0m     )\n\u001b[0;32m    242\u001b[0m )\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mapply(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1434\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1430\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[0;32m   1433\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group_selection_context():\n\u001b[1;32m-> 1434\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[0;32m   1436\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1464\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1439\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[0;32m   1440\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1443\u001b[0m     not_indexed_same: \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1444\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   1445\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1462\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1464\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[0;32m   1466\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1467\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:761\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[0;32m    760\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[1;32m--> 761\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[0;32m    763\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\Attention_discounting\\attention_discount_project\\model\\mpl\\cross_valid.py:201\u001b[0m, in \u001b[0;36mKFvalidation.summary.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    198\u001b[0m df[score_list] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mscores\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:pd\u001b[39m.\u001b[39mSeries(x))\n\u001b[0;32m    200\u001b[0m df_group \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m sum_tab \u001b[39m=\u001b[39m df_group\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39;49mmean(x\u001b[39m.\u001b[39;49mtolist(),axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m    202\u001b[0m sum_tab[score_list] \u001b[39m=\u001b[39m df_group[score_list]\u001b[39m.\u001b[39mmean()\n\u001b[0;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m sum_tab\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3429\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3430\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 3432\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3433\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\lib\\site-packages\\numpy\\core\\_methods.py:180\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    177\u001b[0m         dtype \u001b[39m=\u001b[39m mu\u001b[39m.\u001b[39mdtype(\u001b[39m'\u001b[39m\u001b[39mf4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m         is_float16_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m ret \u001b[39m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[39m=\u001b[39;49mwhere)\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    182\u001b[0m     ret \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39mtrue_divide(\n\u001b[0;32m    183\u001b[0m             ret, rcount, out\u001b[39m=\u001b[39mret, casting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m'\u001b[39m, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "dstyle_list = list(estimation.config_param['discount_func'].keys())\n",
    "ustyle_list = list(estimation.config_param['utility_func'].keys())\n",
    "style_list = [{\"dstyle\":dstyle_list[i],\n",
    "               \"ustyle\":ustyle_list[j],\n",
    "               \"method\":'logit',\n",
    "               \"intercept\":False} \n",
    "              for i in range(len(dstyle_list)) for j in range(len(ustyle_list))]\n",
    "\n",
    "kf = cross_valid.KFvalidation(style=style_list,data=train_sample,cv=cv,n_jobs=4)\n",
    "\n",
    "kf.summary().to_csv(\"kf_result_logit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56, 59, 66], dtype=int64),)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(kf.fails==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dstyle': 'quasihb_fc',\n",
       " 'ustyle': 'cara',\n",
       " 'method': 'logit',\n",
       " 'intercept': False}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.val_styles[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 4)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "n_style = len(style_list)\n",
    "n_cv = len(cv)\n",
    "\n",
    "fit_list = list(itertools.product(np.arange(n_style), np.arange(n_cv)))\n",
    "fit_list[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dstyle': 'quasihb', 'ustyle': 'cara', 'method': 'logit', 'intercept': False}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_list[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'quasihb-cara',\n",
       " 'params': [0.999, 0.589, 4.807, 0.716],\n",
       " 'se': [0.011, 0.02, 0.009, 0.011],\n",
       " 'gradient': [-0.004, -0.01, 0.0, 0.002],\n",
       " 'log_loss': 0.651,\n",
       " 'aic': 15308.988,\n",
       " 'bic': 15375.961}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_sample[train_sample.index.isin(cv[4][0])]\n",
    "estimation.mle(style=style_list[11],data=train_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47febc5ef3103743ffe554ef26604df7fc0e56c4a1892b2f8bd68368c7fcdbd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

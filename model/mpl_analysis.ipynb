{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from mpl import cross_valid\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "itch_dt = pd.read_csv('data/ericson_data.csv')\n",
    "itch_dt = itch_dt.rename(columns={\"Subject\":\"person_id\",\n",
    "                        \"Condition\":\"condition\",\n",
    "                        \"Question\":\"question_id\",\n",
    "                        \"X1\":\"ss_x\",\n",
    "                        \"T1\":\"ss_t\",\n",
    "                        \"X2\":\"ll_x\",\n",
    "                        \"T2\":\"ll_t\",\n",
    "                        \"LaterOptionChosen\": \"choice\"}).drop(['R','G','D'],axis=1)\n",
    "\n",
    "dataset = cross_valid.generate_sample(itch_dt)\n",
    "\n",
    "# Define features and label\n",
    "features = ['ss_x', 'ss_t', 'll_x', 'll_t',\n",
    "            'abs_diff_x', 'abs_diff_t', 'rel_diff_x','rel_diff_t','growth_x']\n",
    "label = 'choice'\n",
    "X = dataset[features]\n",
    "y = dataset[label]\n",
    "\n",
    "# Split the data into train sample and test sample \n",
    "# Train sample containts 80% of the participants, test sample contains the rest \n",
    "groups = dataset['person_id']\n",
    "train_index,test_index = list(model_selection.GroupShuffleSplit(n_splits=1,train_size=.8,random_state=2023).\n",
    "                              split(X,y,groups))[0]\n",
    "train_sample = dataset[dataset.index.isin(train_index)]\n",
    "test_sample = dataset[dataset.index.isin(test_index)]\n",
    "\n",
    "# Split the train sample into K folds (K=10) for cross-validation\n",
    "sgkf = model_selection.StratifiedGroupKFold(n_splits=10,shuffle=True,random_state=2023)\n",
    "cv = list(sgkf.split(X=train_sample[features],\n",
    "                y=train_sample[label],\n",
    "                groups=train_sample['person_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   50,    51,    52, ..., 18085, 18086, 18087])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  167,   168,   169, ..., 17828, 17829, 17830])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  192,   193,   194, ..., 18127, 18128, 18129])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   74,    75,    76, ..., 17729, 17730, 17731])),\n",
       "                 (array([    0,     1...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;, scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=[(array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   50,    51,    52, ..., 18085, 18086, 18087])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  167,   168,   169, ..., 17828, 17829, 17830])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  192,   193,   194, ..., 18127, 18128, 18129])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   74,    75,    76, ..., 17729, 17730, 17731])),\n",
       "                 (array([    0,     1...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [1.0], &#x27;gamma&#x27;: [0.3],\n",
       "                         &#x27;learning_rate&#x27;: [0.1], &#x27;max_depth&#x27;: [3],\n",
       "                         &#x27;n_estimators&#x27;: [40], &#x27;reg_lambda&#x27;: [0.7],\n",
       "                         &#x27;subsample&#x27;: [0.55]},\n",
       "             refit=&#x27;neg_log_loss&#x27;, scoring=&#x27;neg_log_loss&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=[(array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   50,    51,    52, ..., 18085, 18086, 18087])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  167,   168,   169, ..., 17828, 17829, 17830])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([  192,   193,   194, ..., 18127, 18128, 18129])),\n",
       "                 (array([    0,     1,     2, ..., 18182, 18183, 18184]),\n",
       "                  array([   74,    75,    76, ..., 17729, 17730, 17731])),\n",
       "                 (array([    0,     1...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [1.0], 'gamma': [0.3],\n",
       "                         'learning_rate': [0.1], 'max_depth': [3],\n",
       "                         'n_estimators': [40], 'reg_lambda': [0.7],\n",
       "                         'subsample': [0.55]},\n",
       "             refit='neg_log_loss', scoring='neg_log_loss', verbose=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use XGBoost to fit the data\n",
    "# Tune the hyer-parameters by grid search \n",
    "param_grid = {'n_estimators': [40],\n",
    "              'max_depth': [3],\n",
    "              'learning_rate': [.1],\n",
    "              'gamma': [.3],\n",
    "              'reg_lambda': [.7],\n",
    "              'subsample': [.55],\n",
    "              'colsample_bytree': [1.0]\n",
    "            }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "grid_search = model_selection.GridSearchCV(model, param_grid, cv=cv, \n",
    "                                           scoring=\"neg_log_loss\", refit=\"neg_log_loss\",\n",
    "                                           n_jobs=-1,verbose=3)\n",
    "\n",
    "grid_search.fit(X=train_sample[features], \n",
    "                y=train_sample[label], \n",
    "                groups=train_sample['person_id'])\n",
    "\n",
    "# model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "#                           max_depth=3,\n",
    "#                           learning_rate=.1,\n",
    "#                           gamma=.3,\n",
    "#                           reg_lambda=.7,\n",
    "#                           subsample=.6,\n",
    "#                           colsample_bytree=1.0,\n",
    "#                           eval_metric=['error','logloss'],\n",
    "#                           early_stopping_rounds=30)\n",
    "# eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "# bst = model.fit(X=X_train,\n",
    "#                 y=y_train,\n",
    "#                 eval_set=eval_set,\n",
    "#                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 1.0, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 40, 'reg_lambda': 0.7, 'subsample': 0.55}\n",
      "Best score: -0.581191102981182\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the XGBoost model and check the feature importance\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "bst_model = grid_search.best_estimator_\n",
    "xgb.plot_importance(bst_model)\n",
    "with open('my_model.pkl', 'wb') as f:\n",
    "    pickle.dump(bst_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.0.1 (20230327.1645)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1411pt\" height=\"305pt\"\n",
       " viewBox=\"0.00 0.00 1411.39 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-301 1407.39,-301 1407.39,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"650.99\" cy=\"-279\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"650.99\" y=\"-275.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.288811326</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"469.99\" cy=\"-192\" rx=\"101.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.99\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.0615856722</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M616.52,-261.81C587.55,-248.21 545.96,-228.67 514.48,-213.89\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"516.18,-210.35 505.64,-209.27 513.21,-216.69 516.18,-210.35\"/>\n",
       "<text text-anchor=\"middle\" x=\"606.49\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"863.99\" cy=\"-192\" rx=\"71.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"863.99\" y=\"-188.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ll_x&lt;48.3349991</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M690.56,-262.21C726.45,-247.89 779.4,-226.76 817.34,-211.62\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"818.14,-214.67 826.13,-207.71 815.55,-208.16 818.14,-214.67\"/>\n",
       "<text text-anchor=\"middle\" x=\"778.49\" y=\"-231.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"256.99\" cy=\"-105\" rx=\"68.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">abs_diff_x&lt;300</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M429.93,-175.01C393.98,-160.66 341.21,-139.61 303.42,-124.53\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"305.26,-121.09 294.68,-120.64 302.67,-127.6 305.26,-121.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"469.99\" cy=\"-105\" rx=\"64.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">abs_diff_x&lt;75</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M469.99,-173.8C469.99,-162.47 469.99,-147.36 469.99,-134.29\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"473.49,-134.47 469.99,-124.47 466.49,-134.47 473.49,-134.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"477.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"863.99\" cy=\"-105\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"863.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.693334818</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M863.99,-173.8C863.99,-162.47 863.99,-147.36 863.99,-134.29\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"867.49,-134.47 863.99,-124.47 860.49,-134.47 867.49,-134.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"898.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1154.99\" cy=\"-105\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1154.99\" y=\"-101.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">growth_x&lt;0.693167806</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M909.46,-177.72C959.17,-163.2 1039.07,-139.86 1094.15,-123.77\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1094.85,-126.92 1103.47,-120.76 1092.89,-120.2 1094.85,-126.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"1034.49\" y=\"-144.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"77.99\" cy=\"-18\" rx=\"77.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.120960131</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M224.99,-88.8C195.83,-74.96 152.54,-54.4 120.49,-39.18\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"122.46,-35.77 111.93,-34.64 119.46,-42.09 122.46,-35.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"256.99\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0813586041</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;8 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M256.99,-86.8C256.99,-75.47 256.99,-60.36 256.99,-47.29\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"260.49,-47.47 256.99,-37.47 253.49,-47.47 260.49,-47.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"435.99\" cy=\"-18\" rx=\"77.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"435.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.077405028</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M463.11,-86.8C458.46,-75.16 452.21,-59.55 446.89,-46.24\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"449.83,-45.16 442.86,-37.18 443.33,-47.76 449.83,-45.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"490.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"614.99\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0362361036</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;10 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M496.93,-88.21C519.73,-74.84 552.65,-55.55 577.94,-40.72\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"579.36,-43.36 586.22,-35.28 575.82,-37.32 579.36,-43.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"559.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"797.99\" cy=\"-18\" rx=\"82.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"797.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=&#45;0.0131770419</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M850.64,-86.8C841.24,-74.7 828.51,-58.3 817.92,-44.67\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"820.23,-42.93 811.33,-37.18 814.7,-47.22 820.23,-42.93\"/>\n",
       "<text text-anchor=\"middle\" x=\"869.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"977.99\" cy=\"-18\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"977.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.0390020758</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M886.52,-87.21C903.88,-74.26 928.09,-56.21 947.23,-41.93\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"948.98,-44.25 954.91,-35.47 944.8,-38.64 948.98,-44.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"935.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1154.99\" cy=\"-18\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1154.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.0448279642</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#0000ff\" d=\"M1154.99,-86.8C1154.99,-75.47 1154.99,-60.36 1154.99,-47.29\"/>\n",
       "<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1158.49,-47.47 1154.99,-37.47 1151.49,-47.47 1158.49,-47.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"1189.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">yes, missing</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1327.99\" cy=\"-18\" rx=\"75.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1327.99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">leaf=0.102014445</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#ff0000\" d=\"M1189.22,-87.74C1201.47,-81.87 1215.37,-75.18 1227.99,-69 1247.56,-59.42 1269.18,-48.63 1287.31,-39.53\"/>\n",
       "<polygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1288.62,-42.29 1295.98,-34.67 1285.47,-36.04 1288.62,-42.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"1265.49\" y=\"-57.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">no</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x13a70263a30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot a decision tree\n",
    "# Change num_trees from 0 to 39, check different trees\n",
    "xgb.to_graphviz(bst_model, num_trees=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.29965080750763856,\n",
       " 'mae': 0.29965080750763856,\n",
       " 'log_loss': 10.349644658041443,\n",
       " 'accuracy': 0.7003491924923614,\n",
       " 'pred_ll': 0.26473155827149714}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The out-of-sample performance of XGBoost model\n",
    "with open('my_model.pkl', 'rb') as f:\n",
    "    heuristic_model = pickle.load(f)\n",
    "\n",
    "preds = heuristic_model.predict(test_sample[features])\n",
    "trues = test_sample[label]\n",
    "\n",
    "pred_binary = (preds > .5)\n",
    "\n",
    "test_heuristic_dict = {'mse': metrics.mean_squared_error(trues, preds),\n",
    "                       'mae': metrics.mean_absolute_error(trues, preds),\n",
    "                       'log_loss': metrics.log_loss(trues, preds),\n",
    "                       'accuracy': metrics.accuracy_score(trues, pred_binary),\n",
    "                       'pred_ll':sum(pred_binary)/len(pred_binary)\n",
    "                       }\n",
    "test_heuristic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [1:07:17<00:00, 18.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Fit data by distounted utility model and trade-off model\n",
    "dstyle_list = list(cross_valid.estimation.config_param['discount_func'].keys())\n",
    "ustyle_list = list(cross_valid.estimation.config_param['utility_func'].keys())\n",
    "style_list = [{\"dstyle\":dstyle_list[i],\n",
    "               \"ustyle\":ustyle_list[j],\n",
    "               \"method\":'logit',\n",
    "               \"intercept\":False} \n",
    "              for i in range(len(dstyle_list)) for j in range(len(ustyle_list))]\n",
    "\n",
    "kf = cross_valid.KFvalidation(style=style_list,data=train_sample,cv=cv,n_jobs=4)\n",
    "kf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>params</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>[4.783, 1.275, 39.186, 2.194, 0.159, 0.926]</td>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.4088</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>0.6937</td>\n",
       "      <td>0.2074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>[6.751, 0.149, 0.182]</td>\n",
       "      <td>0.2042</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.5978</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>[1.298, 0.176, 0.326]</td>\n",
       "      <td>0.2088</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.939, 0.786, 0.599, 0.016, 0.014]</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.2437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.992, 0.018, 0.015]</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>0.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.012, 0.027, 0.024]</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>0.6097</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.993, 4.22, 0.01, 0.013]</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.003, 3.939, 0.021, 0.019]</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.922, 0.861, 9.834, 0.086, 1.253]</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.4362</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.996, 7.781, 0.341, 1.582]</td>\n",
       "      <td>0.2157</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.1715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>[3.615, 1.63, 36.216, 5.63, 0.4, 1.205]</td>\n",
       "      <td>0.2248</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.0687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>[0.997, 0.834, 0.121, 1.875]</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.4438</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.793, 2.886, 0.395]</td>\n",
       "      <td>0.2277</td>\n",
       "      <td>0.4554</td>\n",
       "      <td>0.6476</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.725, 2.516, 0.544]</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.6480</td>\n",
       "      <td>0.6326</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.079, 4.857, 2.677, 0.502]</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.445, 0.604, 0.419, 2.853, 0.508]</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.725, 98.968, 2.537, 0.545]</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6326</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.317, 3.258, 0.419]</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.885, 1.159, 3.091, 0.481]</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.6487</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>[3.75, 2.583, 0.383]</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>0.1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.995, 0.491, 19.741, 18.769, 2.305]</td>\n",
       "      <td>0.2366</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>0.6658</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>[0.971, 0.488, 13.833, 2.652]</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.0082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle                                       params     mse  \\\n",
       "21          trade  power  [4.783, 1.275, 39.186, 2.194, 0.159, 0.926]  0.2036   \n",
       "13           hbmd  power                        [6.751, 0.149, 0.182]  0.2042   \n",
       "3   attention_uni  power                        [1.298, 0.176, 0.326]  0.2088   \n",
       "7           expo2  power          [0.939, 0.786, 0.599, 0.016, 0.014]  0.2094   \n",
       "5            expo  power                        [0.992, 0.018, 0.015]  0.2099   \n",
       "9              hb  power                        [0.012, 0.027, 0.024]  0.2099   \n",
       "15            hce  power                   [0.993, 4.22, 0.01, 0.013]  0.2102   \n",
       "11            hb2  power                 [0.003, 3.939, 0.021, 0.019]  0.2105   \n",
       "19     quasihb_fc  power          [0.922, 0.861, 9.834, 0.086, 1.253]  0.2160   \n",
       "1       attention  power                 [0.996, 7.781, 0.341, 1.582]  0.2157   \n",
       "20          trade   cara      [3.615, 1.63, 36.216, 5.63, 0.4, 1.205]  0.2248   \n",
       "17        quasihb  power                 [0.997, 0.834, 0.121, 1.875]  0.2251   \n",
       "2   attention_uni   cara                        [0.793, 2.886, 0.395]  0.2277   \n",
       "4            expo   cara                        [0.725, 2.516, 0.544]  0.2279   \n",
       "10            hb2   cara                 [0.079, 4.857, 2.677, 0.502]  0.2281   \n",
       "6           expo2   cara          [0.445, 0.604, 0.419, 2.853, 0.508]  0.2280   \n",
       "14            hce   cara                [0.725, 98.968, 2.537, 0.545]  0.2279   \n",
       "8              hb   cara                        [0.317, 3.258, 0.419]  0.2282   \n",
       "0       attention   cara                 [0.885, 1.159, 3.091, 0.481]  0.2281   \n",
       "12           hbmd   cara                         [3.75, 2.583, 0.383]  0.2281   \n",
       "18     quasihb_fc   cara        [0.995, 0.491, 19.741, 18.769, 2.305]  0.2366   \n",
       "16        quasihb   cara                [0.971, 0.488, 13.833, 2.652]  0.2372   \n",
       "\n",
       "       mae  log_loss  accuracy  pred_ll  \n",
       "21  0.4088    0.5947    0.6937   0.2074  \n",
       "13  0.4094    0.5978    0.6942   0.2282  \n",
       "3   0.4185    0.6071    0.6840   0.1526  \n",
       "7   0.4165    0.6087    0.6845   0.2437  \n",
       "5   0.4205    0.6093    0.6827   0.2405  \n",
       "9   0.4204    0.6097    0.6820   0.2472  \n",
       "15  0.4211    0.6098    0.6805   0.2351  \n",
       "11  0.4194    0.6113    0.6824   0.2453  \n",
       "19  0.4362    0.6222    0.6725   0.1628  \n",
       "1   0.4358    0.6232    0.6787   0.1715  \n",
       "20  0.4499    0.6415    0.6485   0.0687  \n",
       "17  0.4438    0.6440    0.6571   0.1035  \n",
       "2   0.4554    0.6476    0.6339   0.0817  \n",
       "4   0.4558    0.6480    0.6326   0.0500  \n",
       "10  0.4558    0.6481    0.6324   0.0632  \n",
       "6   0.4556    0.6481    0.6325   0.0576  \n",
       "14  0.4558    0.6481    0.6326   0.0500  \n",
       "8   0.4560    0.6484    0.6324   0.0736  \n",
       "0   0.4560    0.6487    0.6318   0.0665  \n",
       "12  0.4559    0.6489    0.6363   0.1021  \n",
       "18  0.4780    0.6658    0.6325   0.0084  \n",
       "16  0.4790    0.6670    0.6330   0.0082  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Cross-validation result\n",
    "kf_result_df = kf.summary()\n",
    "kf_result_df['dstyle'] = kf_result_df['style'].apply(lambda x:x['dstyle'])\n",
    "kf_result_df['ustyle'] = kf_result_df['style'].apply(lambda x:x['ustyle'])\n",
    "df_cols = kf_result_df.columns.tolist()\n",
    "df_cols = df_cols[-2:] + df_cols[:-2]\n",
    "kf_result = kf_result_df.reindex(columns=df_cols).drop('style',axis=1)\n",
    "kf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.204391</td>\n",
       "      <td>0.407377</td>\n",
       "      <td>0.598332</td>\n",
       "      <td>0.700786</td>\n",
       "      <td>0.213226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.208359</td>\n",
       "      <td>0.418450</td>\n",
       "      <td>0.606683</td>\n",
       "      <td>0.690310</td>\n",
       "      <td>0.245089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.208574</td>\n",
       "      <td>0.414926</td>\n",
       "      <td>0.607375</td>\n",
       "      <td>0.690310</td>\n",
       "      <td>0.245089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.210806</td>\n",
       "      <td>0.419025</td>\n",
       "      <td>0.611358</td>\n",
       "      <td>0.679834</td>\n",
       "      <td>0.149062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.211875</td>\n",
       "      <td>0.419064</td>\n",
       "      <td>0.614426</td>\n",
       "      <td>0.674160</td>\n",
       "      <td>0.164775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.212656</td>\n",
       "      <td>0.408161</td>\n",
       "      <td>0.618448</td>\n",
       "      <td>0.674160</td>\n",
       "      <td>0.164775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.218415</td>\n",
       "      <td>0.439812</td>\n",
       "      <td>0.628652</td>\n",
       "      <td>0.666521</td>\n",
       "      <td>0.136622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230114</td>\n",
       "      <td>0.457115</td>\n",
       "      <td>0.652744</td>\n",
       "      <td>0.629419</td>\n",
       "      <td>0.082933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230261</td>\n",
       "      <td>0.457356</td>\n",
       "      <td>0.653074</td>\n",
       "      <td>0.630729</td>\n",
       "      <td>0.076386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231007</td>\n",
       "      <td>0.458274</td>\n",
       "      <td>0.654510</td>\n",
       "      <td>0.624182</td>\n",
       "      <td>0.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231010</td>\n",
       "      <td>0.458207</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.624182</td>\n",
       "      <td>0.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231016</td>\n",
       "      <td>0.458451</td>\n",
       "      <td>0.654648</td>\n",
       "      <td>0.627455</td>\n",
       "      <td>0.065692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231668</td>\n",
       "      <td>0.455921</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>0.629201</td>\n",
       "      <td>0.049542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.231776</td>\n",
       "      <td>0.455117</td>\n",
       "      <td>0.656467</td>\n",
       "      <td>0.624836</td>\n",
       "      <td>0.039939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.234117</td>\n",
       "      <td>0.479414</td>\n",
       "      <td>0.661031</td>\n",
       "      <td>0.616761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.235179</td>\n",
       "      <td>0.481398</td>\n",
       "      <td>0.663210</td>\n",
       "      <td>0.616761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.235941</td>\n",
       "      <td>0.449582</td>\n",
       "      <td>0.667638</td>\n",
       "      <td>0.622217</td>\n",
       "      <td>0.016368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.239745</td>\n",
       "      <td>0.487076</td>\n",
       "      <td>0.672517</td>\n",
       "      <td>0.618071</td>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.239974</td>\n",
       "      <td>0.488404</td>\n",
       "      <td>0.672965</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.459406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.240509</td>\n",
       "      <td>0.488883</td>\n",
       "      <td>0.674097</td>\n",
       "      <td>0.629419</td>\n",
       "      <td>0.134439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.240823</td>\n",
       "      <td>0.488810</td>\n",
       "      <td>0.674709</td>\n",
       "      <td>0.618071</td>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.382747</td>\n",
       "      <td>0.383161</td>\n",
       "      <td>4.860872</td>\n",
       "      <td>0.616761</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.299651</td>\n",
       "      <td>0.299651</td>\n",
       "      <td>10.349645</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.264732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae   log_loss  accuracy   pred_ll\n",
       "13           hbmd  power  0.204391  0.407377   0.598332  0.700786  0.213226\n",
       "9              hb  power  0.208359  0.418450   0.606683  0.690310  0.245089\n",
       "5            expo  power  0.208574  0.414926   0.607375  0.690310  0.245089\n",
       "3   attention_uni  power  0.210806  0.419025   0.611358  0.679834  0.149062\n",
       "15            hce  power  0.211875  0.419064   0.614426  0.674160  0.164775\n",
       "11            hb2  power  0.212656  0.408161   0.618448  0.674160  0.164775\n",
       "1       attention  power  0.218415  0.439812   0.628652  0.666521  0.136622\n",
       "12           hbmd   cara  0.230114  0.457115   0.652744  0.629419  0.082933\n",
       "2   attention_uni   cara  0.230261  0.457356   0.653074  0.630729  0.076386\n",
       "14            hce   cara  0.231007  0.458274   0.654510  0.624182  0.041030\n",
       "4            expo   cara  0.231010  0.458207   0.654517  0.624182  0.041030\n",
       "8              hb   cara  0.231016  0.458451   0.654648  0.627455  0.065692\n",
       "0       attention   cara  0.231668  0.455921   0.656350  0.629201  0.049542\n",
       "10            hb2   cara  0.231776  0.455117   0.656467  0.624836  0.039939\n",
       "19     quasihb_fc  power  0.234117  0.479414   0.661031  0.616761  0.000000\n",
       "17        quasihb  power  0.235179  0.481398   0.663210  0.616761  0.000000\n",
       "6           expo2   cara  0.235941  0.449582   0.667638  0.622217  0.016368\n",
       "18     quasihb_fc   cara  0.239745  0.487076   0.672517  0.618071  0.002182\n",
       "21          trade  power  0.239974  0.488404   0.672965  0.664557  0.459406\n",
       "20          trade   cara  0.240509  0.488883   0.674097  0.629419  0.134439\n",
       "16        quasihb   cara  0.240823  0.488810   0.674709  0.618071  0.002182\n",
       "7           expo2  power  0.382747  0.383161   4.860872  0.616761  0.000000\n",
       "99           gbdt   gbdt  0.299651  0.299651  10.349645  0.700349  0.264732"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models: Out-of-sample performance\n",
    "test_result = []\n",
    "\n",
    "for i in range(len(kf_result_df)):\n",
    "\n",
    "    test_style = kf_result_df['style'][i]\n",
    "    test_params = kf_result_df['params'][i]\n",
    "\n",
    "    test_scores = cross_valid.test_model(test_sample=test_sample,style=test_style,params=test_params)\n",
    "    test_scores['dstyle'] = test_style['dstyle'] \n",
    "    test_scores['ustyle'] = test_style['ustyle']\n",
    "    test_result.append(test_scores)\n",
    "\n",
    "test_result = pd.DataFrame(test_result)\n",
    "test_result = test_result.reindex(columns=df_cols).sort_values('log_loss').drop(['style','params'],axis=1)\n",
    "\n",
    "test_heuristic_dict['dstyle'] = 'gbdt'\n",
    "test_heuristic_dict['ustyle'] = 'gbdt'\n",
    "\n",
    "test_result = pd.concat([test_result,pd.DataFrame(test_heuristic_dict,index=[99])])\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>power</td>\n",
       "      <td>0.116873</td>\n",
       "      <td>0.321717</td>\n",
       "      <td>0.403314</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.133040</td>\n",
       "      <td>0.331299</td>\n",
       "      <td>0.433513</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.133517</td>\n",
       "      <td>0.343413</td>\n",
       "      <td>0.440199</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.135749</td>\n",
       "      <td>0.343999</td>\n",
       "      <td>0.445010</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.138816</td>\n",
       "      <td>0.350770</td>\n",
       "      <td>0.453273</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.142033</td>\n",
       "      <td>0.351444</td>\n",
       "      <td>0.458364</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.170381</td>\n",
       "      <td>0.393932</td>\n",
       "      <td>0.521401</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.199039</td>\n",
       "      <td>0.414823</td>\n",
       "      <td>0.585759</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.199729</td>\n",
       "      <td>0.424612</td>\n",
       "      <td>0.588087</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.199831</td>\n",
       "      <td>0.425581</td>\n",
       "      <td>0.588497</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.200301</td>\n",
       "      <td>0.428441</td>\n",
       "      <td>0.589887</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.200349</td>\n",
       "      <td>0.428625</td>\n",
       "      <td>0.589992</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.201336</td>\n",
       "      <td>0.429824</td>\n",
       "      <td>0.591969</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.201389</td>\n",
       "      <td>0.429943</td>\n",
       "      <td>0.592089</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.202166</td>\n",
       "      <td>0.430872</td>\n",
       "      <td>0.593744</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.218729</td>\n",
       "      <td>0.464418</td>\n",
       "      <td>0.629898</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.221376</td>\n",
       "      <td>0.467930</td>\n",
       "      <td>0.635284</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.228413</td>\n",
       "      <td>0.476596</td>\n",
       "      <td>0.649605</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.229490</td>\n",
       "      <td>0.477003</td>\n",
       "      <td>0.651873</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.232129</td>\n",
       "      <td>0.480255</td>\n",
       "      <td>0.657234</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.232469</td>\n",
       "      <td>0.480951</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.288259</td>\n",
       "      <td>0.288753</td>\n",
       "      <td>2.982422</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "13           hbmd  power  0.116873  0.321717  0.403314     0.919    0.238\n",
       "11            hb2  power  0.133040  0.331299  0.433513     0.832    0.177\n",
       "3   attention_uni  power  0.133517  0.343413  0.440199     0.875    0.170\n",
       "5            expo  power  0.135749  0.343999  0.445010     0.864    0.257\n",
       "9              hb  power  0.138816  0.350770  0.453273     0.864    0.257\n",
       "15            hce  power  0.142033  0.351444  0.458364     0.832    0.177\n",
       "1       attention  power  0.170381  0.393932  0.521401     0.847    0.150\n",
       "6           expo2   cara  0.199039  0.414823  0.585759     0.713    0.018\n",
       "10            hb2   cara  0.199729  0.424612  0.588087     0.716    0.045\n",
       "0       attention   cara  0.199831  0.425581  0.588497     0.733    0.054\n",
       "12           hbmd   cara  0.200301  0.428441  0.589887     0.724    0.079\n",
       "2   attention_uni   cara  0.200349  0.428625  0.589992     0.725    0.078\n",
       "4            expo   cara  0.201336  0.429824  0.591969     0.715    0.046\n",
       "14            hce   cara  0.201389  0.429943  0.592089     0.715    0.046\n",
       "8              hb   cara  0.202166  0.430872  0.593744     0.722    0.069\n",
       "19     quasihb_fc  power  0.218729  0.464418  0.629898     0.711    0.000\n",
       "17        quasihb  power  0.221376  0.467930  0.635284     0.711    0.000\n",
       "21          trade  power  0.228413  0.476596  0.649605     0.794    0.495\n",
       "18     quasihb_fc   cara  0.229490  0.477003  0.651873     0.713    0.004\n",
       "16        quasihb   cara  0.232129  0.480255  0.657234     0.713    0.004\n",
       "20          trade   cara  0.232469  0.480951  0.657969     0.744    0.119\n",
       "7           expo2  power  0.288259  0.288753  2.982422     0.711    0.000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly draw 1000 questions from the dataset \n",
    "# Use the prediction value by XGBoost as the label\n",
    "# Examine which model can explain the XGBoost's prediction the best\n",
    "rda_sample = itch_dt[itch_dt.index.isin(np.random.choice(itch_dt.index,size=1000,replace=False))][['ss_x','ss_t','ll_x','ll_t']]\n",
    "rda_sample = cross_valid.generate_sample(rda_sample)\n",
    "rda_sample['choice'] = heuristic_model.predict(rda_sample[features])\n",
    "\n",
    "rda_result = []\n",
    "\n",
    "for i in range(len(kf_result_df)):\n",
    "\n",
    "    rda_style = kf_result_df['style'][i]\n",
    "    rda_params = kf_result_df['params'][i]\n",
    "\n",
    "    rda_scores = cross_valid.test_model(test_sample=rda_sample,style=rda_style,params=rda_params)\n",
    "    rda_scores['dstyle'] = rda_style['dstyle'] \n",
    "    rda_scores['ustyle'] = rda_style['ustyle']\n",
    "    rda_result.append(rda_scores)\n",
    "\n",
    "rda_result = pd.DataFrame(rda_result)\n",
    "rda_result = rda_result.reindex(columns=df_cols).sort_values('log_loss').drop(['style','params'],axis=1)\n",
    "rda_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dstyle</th>\n",
       "      <th>ustyle</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_ll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hb2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.119803</td>\n",
       "      <td>0.319621</td>\n",
       "      <td>0.406065</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expo</td>\n",
       "      <td>power</td>\n",
       "      <td>0.127764</td>\n",
       "      <td>0.337258</td>\n",
       "      <td>0.428544</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hce</td>\n",
       "      <td>power</td>\n",
       "      <td>0.130530</td>\n",
       "      <td>0.341162</td>\n",
       "      <td>0.434809</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.132035</td>\n",
       "      <td>0.345079</td>\n",
       "      <td>0.439360</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>power</td>\n",
       "      <td>0.133509</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.440036</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention</td>\n",
       "      <td>power</td>\n",
       "      <td>0.168739</td>\n",
       "      <td>0.392427</td>\n",
       "      <td>0.517595</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>expo2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.190935</td>\n",
       "      <td>0.405711</td>\n",
       "      <td>0.568615</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hb2</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.191683</td>\n",
       "      <td>0.416229</td>\n",
       "      <td>0.571144</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.193003</td>\n",
       "      <td>0.418248</td>\n",
       "      <td>0.574098</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expo</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.193354</td>\n",
       "      <td>0.421716</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hce</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.193428</td>\n",
       "      <td>0.421856</td>\n",
       "      <td>0.575412</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attention_uni</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.194405</td>\n",
       "      <td>0.422475</td>\n",
       "      <td>0.577398</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hbmd</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.194680</td>\n",
       "      <td>0.422651</td>\n",
       "      <td>0.577930</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.195713</td>\n",
       "      <td>0.424130</td>\n",
       "      <td>0.580148</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>power</td>\n",
       "      <td>0.214532</td>\n",
       "      <td>0.460184</td>\n",
       "      <td>0.621415</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>power</td>\n",
       "      <td>0.217816</td>\n",
       "      <td>0.464444</td>\n",
       "      <td>0.628135</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>quasihb_fc</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.474622</td>\n",
       "      <td>0.647327</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>quasihb</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>0.478220</td>\n",
       "      <td>0.653334</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trade</td>\n",
       "      <td>cara</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.479220</td>\n",
       "      <td>0.654620</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>trade</td>\n",
       "      <td>power</td>\n",
       "      <td>0.231525</td>\n",
       "      <td>0.479883</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expo2</td>\n",
       "      <td>power</td>\n",
       "      <td>0.247413</td>\n",
       "      <td>0.247863</td>\n",
       "      <td>2.460266</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dstyle ustyle       mse       mae  log_loss  accuracy  pred_ll\n",
       "11            hb2  power  0.119803  0.319621  0.406065     0.897    0.177\n",
       "5            expo  power  0.127764  0.337258  0.428544     0.890    0.276\n",
       "15            hce  power  0.130530  0.341162  0.434809     0.897    0.177\n",
       "9              hb  power  0.132035  0.345079  0.439360     0.890    0.276\n",
       "3   attention_uni  power  0.133509  0.343434  0.440036     0.887    0.153\n",
       "1       attention  power  0.168739  0.392427  0.517595     0.879    0.147\n",
       "6           expo2   cara  0.190935  0.405711  0.568615     0.762    0.014\n",
       "10            hb2   cara  0.191683  0.416229  0.571144     0.754    0.046\n",
       "0       attention   cara  0.193003  0.418248  0.574098     0.749    0.053\n",
       "4            expo   cara  0.193354  0.421716  0.575248     0.753    0.047\n",
       "14            hce   cara  0.193428  0.421856  0.575412     0.753    0.047\n",
       "2   attention_uni   cara  0.194405  0.422475  0.577398     0.735    0.085\n",
       "12           hbmd   cara  0.194680  0.422651  0.577930     0.732    0.088\n",
       "8              hb   cara  0.195713  0.424130  0.580148     0.737    0.077\n",
       "19     quasihb_fc  power  0.214532  0.460184  0.621415     0.752    0.000\n",
       "17        quasihb  power  0.217816  0.464444  0.628135     0.752    0.000\n",
       "18     quasihb_fc   cara  0.227232  0.474622  0.647327     0.756    0.004\n",
       "16        quasihb   cara  0.230189  0.478220  0.653334     0.756    0.004\n",
       "20          trade   cara  0.230800  0.479220  0.654620     0.773    0.137\n",
       "21          trade  power  0.231525  0.479883  0.655900     0.763    0.485\n",
       "7           expo2  power  0.247413  0.247863  2.460266     0.752    0.000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the prediction value by magnitude-dependent hyperbolic (hbmd) with power utillity as the label\n",
    "# Examine which model can explain the hbmd's prediction the best\n",
    "ss_t = rda_sample['ss_t'].values\n",
    "ss_x = rda_sample['ss_x'].values\n",
    "ll_t = rda_sample['ll_t'].values\n",
    "ll_x = rda_sample['ll_x'].values\n",
    "kf_init_row = kf_result_df[(kf_result_df['dstyle']=='hbmd') & (kf_result_df['ustyle']=='power')]\n",
    "init_style = kf_init_row['style'].values[0]\n",
    "init_params = kf_init_row['params'].values[0]\n",
    "\n",
    "rda_sample['init_choice'] = cross_valid.choice_rule.choice_prob(ss_x, ss_t, ll_x, ll_t, \n",
    "                                                            dstyle = init_style['dstyle'], \n",
    "                                                            ustyle = init_style['ustyle'], \n",
    "                                                            method = init_style['method'],\n",
    "                                                            intercept= init_style['intercept'],\n",
    "                                                            params = init_params[:-1], \n",
    "                                                            temper = init_params[-1]) \n",
    "\n",
    "rda_sample['choice'] = (rda_sample['init_choice']>.5)\n",
    "\n",
    "rda_result = []\n",
    "\n",
    "for i in range(len(kf_result_df)):\n",
    "\n",
    "    rda_style = kf_result_df['style'][i]\n",
    "    rda_params = kf_result_df['params'][i]\n",
    "\n",
    "    rda_scores = cross_valid.test_model(test_sample=rda_sample,style=rda_style,params=rda_params)\n",
    "    rda_scores['dstyle'] = rda_style['dstyle'] \n",
    "    rda_scores['ustyle'] = rda_style['ustyle']\n",
    "    rda_result.append(rda_scores)\n",
    "\n",
    "rda_result = pd.DataFrame(rda_result)\n",
    "rda_result = rda_result.reindex(columns=df_cols).sort_values('log_loss').drop(['style','params'],axis=1)\n",
    "rda_result.iloc[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "kf_result.to_csv(\"itch_result_kf.csv\",index=False)\n",
    "test_result.to_csv(\"itch_result_test.csv\",index=False)\n",
    "rda_result.to_csv(\"itch_result_rda.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47febc5ef3103743ffe554ef26604df7fc0e56c4a1892b2f8bd68368c7fcdbd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
